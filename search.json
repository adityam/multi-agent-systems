[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multi-Agent Systems",
    "section": "",
    "text": "About the course",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#general-information",
    "href": "index.html#general-information",
    "title": "Multi-Agent Systems",
    "section": "General Information (Winter 2025)",
    "text": "General Information (Winter 2025)\n\nInstructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nTBD\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2120)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nYou are expected to know the following concepts from basic undergraduate probability: Probability of events, independence, random variables, probability distributions (PDFs and CDFs), expectation, conditional probability, and conditional expectation.\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "Multi-Agent Systems",
    "section": "Course Content",
    "text": "Course Content\n\nRational decision making; Strategic games and Bayesian games; Solution concepts: iterated elimination of dominated strategies, Nash equilibrium, Correlated equilibrium, Bayesian equilibrium; Common knowledge.\nExtensive form games with perfect information, sub-game perfect equilibrium, Markov perfect equilibrium.\nGames with imperfect information, sequential equilibrium, common information based refinements of sequential equilibrium.\nMechanism design, market equilibrium, pricing, resource allocation; Application to communication networks and power systems\n\nIn the event of extraordinary circumstances beyond the University’s control, the content and/or evaluation scheme in this course is subject to change.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Multi-Agent Systems",
    "section": "Course Material",
    "text": "Course Material\n\nReference books\nI will loosely follow the following two books, though I present the material in a different order/style than the books.\n\nZamir, Maschler, Solan, Game Theory, Cambridge University Press, 2013.\nOsborne and Rubinstein, A Course in Game Theory, MIT Press, 1994\n\n\n\nOnline Course Notes\nThis semesmter, I will be attempting to type my notes and make them available on this website. Most definitely, I will fall behind and the notes for the material covered during the end of the term will not be avaiable. Even for the earlier material, the notes are not meant to be exhaustive; rather my focus is to convey the key ideas in their simplest form. For a more exhaustive treatment of the subject, please refer to the reference books mentioned above.\nIf you find any typos/mistakes in the notes, please let me know. Pull requests are welcome.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "Multi-Agent Systems",
    "section": "Evaluation",
    "text": "Evaluation\n\nAssignments (40%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader.\nMid Term (40%) Closed book in-class exam. March 12 (during class time)\nTerm Project (20%) A month long term project to be done in groups of two. Present one paper on any topic of your interest related to the material covered in the class.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#marking-policy",
    "href": "index.html#marking-policy",
    "title": "Multi-Agent Systems",
    "section": "Marking policy",
    "text": "Marking policy\n\nAssignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-delivery",
    "href": "index.html#course-delivery",
    "title": "Multi-Agent Systems",
    "section": "Course delivery",
    "text": "Course delivery\nThe course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#additional-notes",
    "href": "index.html#additional-notes",
    "title": "Multi-Agent Systems",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nAs the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html",
    "href": "static-games/strategic-games.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Examples\nMulti-agent decision problems are conceptually different from single agent decision problems. In a single agent decision problem, a decision maker has to choose a strategy \\(s \\in \\ALPHABET S\\) and receives a payoff or utility \\(u(s)\\) (or, equivalently, incurs a cost \\(c(s)\\)). In multi-agent decision problems, the utility received by an agent may depend on the strategies of other agents. Such settings are called games. We start with the simplest setting of two player games.\nConsider a decision problem where there are two players. Player 1 (\\(P_1\\) from now on) chooses an strategy \\(s_1 \\in \\ALPHABET S_1\\) and player 2 (\\(P_2\\) from now on) chooses an strategy \\(s_2 \\in \\ALPHABET S_2\\). Once both players have chosen their strategies, \\(P_1\\) receives a payoff of \\(u_1(s_1, s_2)\\) and \\(P_2\\) receives a payoff of \\(u_2(s_1,s_2)\\). How should the players behave?\nWe start with a few examples.\nThis example can be modeled as a two player game as follow. The strategy sets of both players are \\(\\ALPHABET S_1 = \\ALPHABET S_2 = \\{ \\mathsf{A}, \\mathsf{R} \\}\\), where \\(\\mathsf{A}\\) means that the player accepts the bargain and \\(\\mathsf{R}\\) means that the player rejects the bargain. The utility functions can be represented compactly as follows, which is called the bimatrix representation of the game.\nIn the games described above, there is a conflict between the players. We cannot simply assert that the players should take an strategy which maximizes their utility because the utility of a player depends on the strategies of other players, who have different incentives. The objective of game theory is to understand how to make decisions in such scenarios.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#examples",
    "href": "static-games/strategic-games.html#examples",
    "title": "1  Introduction",
    "section": "",
    "text": "Prisoner’s dilemma.\n\n\n\nTwo criminals are arrested for a crime but the prosecutors have evidence to only charge them for a lesser crime but not enough to charge them for the main crime. The prisoners are kept in separate cells with no means to communicate. The prosecutors simultaneously offer the following bargain to both prisoners: serve as a witness that the other criminal committed the crime and walk free; unless the other also confesses in which case both get sentenced. If both criminals confess, both get a reduced sentenced for the main crime (2 years in prison). If only one confesses, the criminal who confessed walks free while the other gets a full sentence for the main crime (10 years in prison). If neither prisoner takes the bargain, then both get charged for the lesser crime (1 year in prison).\n\n\n\n\n\nBimatrix representation of Prisoner’s dilemma game\n\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(-2\\)\n\n\n\\(-2\\)\n\n\n\\(0\\)\n\n\n\\(-3\\)\n\n\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(-3\\)\n\n\n\\(0\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\n\n\n\n\n\n\nBattle of sexes\n\n\n\nA couple wants to go out for the evening and there are two events taking place: a football game and an opera. One person (player 1) prefers to go to the football game while the other player (player 2) prefers to go the opera. But they want to go together and are miserable if they go to separate events.\n\n\nBattle of Sexes Game\n\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(\\mathsf{O}\\)\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{O}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\n\n\n\n\n\n\nChicken (also called Hawk-Dove)\n\n\n\nTwo drivers are headed for a single lane bridge from opposite directions. The first to swerve away yields the bridge to the other and is called ‘chicken’ (i.e., a coward). If neither swerve, both are involved in a head-on collision.\n\n\nBattle of Hawk-Dove Game\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\\(1\\)\n\n\n\\(10\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(10\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\n\n\n\n\n\n\nMatching pennies\n\n\n\nConsider a parlour game among two players. Each player has a penny and must secretly turn the penny to heads or tails. The players reveal their choices simultaneously. If the pennies match (both heads or both tails), player 1 wins. If they don’t player 2 wins.\n\n\nBattle of matching pennies game\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#modeling-strategic-games",
    "href": "static-games/strategic-games.html#modeling-strategic-games",
    "title": "1  Introduction",
    "section": "1.2 Modeling Strategic Games",
    "text": "1.2 Modeling Strategic Games\nThe above examples described games between two players. General \\(n\\)-player games can be modeled as follows.\n\nDefinition 1.1 (Strategic game) A strategic game is described by a tuple \\(\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle\\), where\n\n\\(N\\) is a (finite) set of players\n\\(\\ALPHABET S_i\\) is a non-empty set of strategies for player \\(i\\), \\(i \\in N\\). Define \\(\\ALPHABET S = \\prod_{i \\in N} \\ALPHABET S_i\\) as the strategy space of the game \\(\\mathscr{G}\\).\n\\(u_i \\colon \\ALPHABET S \\to \\reals\\) is the utility function of player \\(i\\), \\(i \\in N\\).\n\n\n\nRemarks\n\n\nThe utlity of player \\(i\\) depends on the strategies of all players and not just the strategy of player \\(i\\). This is the defining feature of a game.\nWhen all \\(\\ALPHABET S_i\\) are finite, the game is called a finite game. Such games are also sometimes called matrix games because they can be described by a matrix, as seen in the above examples.\nTo play the game, each player chooses a (pure) strategy \\(s_i \\in\n\\ALPHABET S_i\\).\nThe collection \\(s = (s_i)_{i \\in N}\\) is called the strategy profile.\nGiven a profile \\(x = (x_i)_{i \\in N}\\) (not necessarily strategy profile, but any list of elements, one for each player), \\(x_{-i}\\) denotes the list \\((x_j)_{j \\in N \\setminus \\{i\\}}\\). We will write \\(x = (x_i, x_{-i})\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominated-strategies",
    "href": "static-games/strategic-games.html#dominated-strategies",
    "title": "1  Introduction",
    "section": "1.3 Dominated strategies",
    "text": "1.3 Dominated strategies\nWe now define the notion of dominance, which can be used to provide a solution concept for some games.\n\nDefinition 1.2 (Dominance) Consider a game \\(\\mathscr{G}\\) with standard notation. Let \\(s_i, t_i \\in \\ALPHABET S_i\\) be two strategies of player \\(i\\). We say, strategy \\(s_i\\) strictly dominates \\(t_i\\) if \\[\n  u_i(s_i, s_{-i}) \\mathbin{\\color{red}&gt;} u_i(t_i, s_{-i}),\n  \\quad \\forall s_{-i} \\in \\ALPHABET S_{-i}.\n\\] We say that \\(s_i\\) weakly dominates \\(t_i\\) if \\[\n  u_i(s_i, s_{-i}) \\mathbin{\\color{red}\\ge} u_i(t_i, s_{-i}),\n  \\quad \\forall s_{-i} \\in \\ALPHABET S_{-i}\n\\] and the inequality is strict for at least one \\(s_{-i}\\).\nWe will also use the phrase “\\(t_i\\) is (strongly or weakly) dominated by \\(s_i\\)” to denote the same fact.\n\nA strategy \\(s_i \\in \\ALPHABET S_i\\) is called (strongly or weakly) dominant strategy if it (strongly or weakly) dominates all other strategies \\(t_i \\in \\ALPHABET S_i \\setminus \\{s_i\\}\\).\nWe now impose some assumptions on the players.\n\nAssumption. A rational player will not choose a strictly dominated strategy.\n\nNote that we have not formally defined rationality. That is more of a philosophical discussion, and for the purpose of this course, we will not present a formal definition but rather go with the colloquial meaning of the word.\n\nAssumption. All players in a game are rational.\n\nIrrespective of the definition of rationality, this assumption is often violated in practice. Human decision makers are almost never rational. Even when decisions are made by algorithms, the decisions may not be rational. There is a whole branch of decision theory which considers players with bounded rationality. However, in this course, we will make the simplifying assumption that the players are rational.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "href": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "title": "1  Introduction",
    "section": "1.4 Dominant strategy equilibrium",
    "text": "1.4 Dominant strategy equilibrium\nWe now present the simplest solution concept for a game.\n\n\n\n\n\n\nDominant strategy equilibrium\n\n\n\nDominant Strategy equilibrium is a strategy profile in which each player is playing a dominant strategy.\n\n\nFor example, consider the game of prisoner’s dilemma. Note that, for \\(P_1\\), \\[\\begin{align*}\n  u_1(\\mathsf{A}, \\cdot) &= \\begin{bmatrix} -2 & 0 \\end{bmatrix}, \\\\\n  u_1(\\mathsf{R}, \\cdot) &= \\begin{bmatrix} -3 & -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_1(\\mathsf{A}, ⋅) &gt; u_1(\\mathsf{R}, ⋅). \\] Thus \\(\\mathsf{A}\\) is a dominant strategy for \\(P_1\\).\nSimilarly, for \\(P_2\\), \\[\\begin{align*}\n  u_2(\\cdot, \\mathsf{A}) &= \\begin{bmatrix} -2 \\\\ 0 \\end{bmatrix},\n  &\n  u_2(\\cdot, \\mathsf{R}) &= \\begin{bmatrix} -3 \\\\ -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_2(⋅,\\mathsf{A}) &gt; u_2(⋅,\\mathsf{R}). \\] Thus, \\(\\mathsf{A}\\) is a dominant strategy for \\(P_2\\).\nTherefore, \\((\\mathsf{A}, \\mathsf{A})\\) is a dominant strategy equilibrium. Note that both players play \\(\\mathsf{A}\\) even though \\((\\mathsf{R}, \\mathsf{R})\\) gives a better outcome for both of them!\n\nA game may not have a dominant strategy equilibrium. For example, there are no dominant strategies in the battle of sexes and matching pennies. So, dominant strategy equilibrium is not a useful solution concept because it does not always exist. One option is to generalize the notion of dominance as explained next.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#rationalizable-equilibrium",
    "href": "static-games/strategic-games.html#rationalizable-equilibrium",
    "title": "1  Introduction",
    "section": "1.5 Rationalizable equilibrium",
    "text": "1.5 Rationalizable equilibrium\nFirst, we return to the assumptions imposed on the players. Consider the following game.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\nStrategy \\(\\mathsf{R}\\) is strictly dominated for player 2 (by strategy \\(\\mathsf{M}\\)). So, if \\(P_2\\) is rational, he will never choose \\(\\mathsf{R}\\). Can we eliminate strategy \\(\\mathsf{R}\\) from consideration?\nThe argument is not so simple. If \\(P_1\\) does not know that \\(P_2\\) is rational, he is liable to believe that \\(P_2\\) might choose strategy \\(\\mathsf{R}\\), in which case it would be in \\(P_1\\)’s interest to player strategy \\(\\mathsf{B}\\).\nHowever, if we postulate that\n\n\\(P_2\\) is rational, and\n\\(P_1\\) knows that \\(P_2\\) is rational.\n\nThen, \\(P_1\\) knows that \\(P_2\\) will not player strategy \\(\\mathsf{R}\\). However, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) is rational. Therefore, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) will not play strategy \\(\\mathsf{R}\\). Thus, we need to assume that\n\n\\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\n\nContinuing this way, we can argue that we we need to assume that\n\n\\(P_1\\) knows that \\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\nand so on.\n\nIf statements of this type hold for infinite depth, we say that the fact that \\(P_2\\) is rational is common knowledge. We will revisit common knowledge later in the course. For now, we assume the following.\n\nAssumption It is common knowledge that all players are rational.\n\nUnder the assumption of common knowledge of rationality, we can assume that the players will eliminate strictly dominated strategies. For example, in the previous example, both players can eliminate strategy \\(\\mathsf{R}\\) from consideration and simplify the original game \\(\\mathscr{G}\\) to game \\(\\mathscr{G}_1\\) shown below.\n\n\nOriginal game \\(\\mathscr{G}\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\n\n\nReduced game \\(\\mathscr{G}_1\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\nWe can continue this reasoning. In the reduced game \\(\\mathscr{G}_1\\), strategy \\(\\mathsf{B}\\) for \\(P_1\\) is dominated by strategy \\(\\mathsf{T}\\). So, we obtain the reduced game \\(\\mathscr{G}_2\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_2\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nFinally, we can eliminate strategy \\(\\mathsf{L}\\) for \\(P_1\\), which is strictly dominated by \\(\\mathsf{M}\\) to obtain game \\(\\mathscr{G}_3\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_3\\)\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nThis procedure is called IEDS (Iterative elimination of dominated strategies). If the procedure gives a unique strategy, that strategy is called a rationalizable strategy.\n\nRemarks\n\n\nIn general, IEDS may not lead to a solution (i.e., we may be left with a game which is not \\(1 × 1\\) where no strategy is dominated).\nAt each step, there may be more than one strictly dominated strategy. If so, we can simultaneously eliminate all of them.\nIrrespective of the order in which strategies are eliminated, IEDS gives the same simplified game.\n\n\n\nRationalizable equilibrium are derived under the assumption of common knowledge of rationality, which appears to be a benign assumption but is not. To see why common knowledge of rationality is a strong assumption, consider the following example, which is known as the beauty contest game.\n\n\n\n\n\n\nBeauty contest game\n\n\n\nEach player picks a real number between 0 and 100. The person who was closest to the average of the group wins a prize.\n\n\nHow will you play this game?",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "href": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "title": "1  Introduction",
    "section": "1.6 Iterative elimination of weakly dominated strategies",
    "text": "1.6 Iterative elimination of weakly dominated strategies\nWe can extend the notion of IEDS to IEWDS (Iterative elimination of weakly dominated strategies) if we make the following assumption.\n\nAssumption. A rational player never plays a weakly dominated strategy.\n\nThe assumption that a player never plays a weakly domainted strategy is less compelling than the assumption of never playing a strictly dominated strategy.\nOne way to justify the assumption of never playing a weakly dominated strategy is the concept of trembling hand principle, which is due to Selten (1975). The key idea of this principle is that the player may make mistakes when executing its strategy (hence the metaphor of trembling hand): thus all possible strategies may be used with positive probability. In such a scenario, it is never optimal to play weakly dominated strategies.\nSimilar to IEDS, we may consider an iterative procedure to eliminate weakly dominated strategies (abbreviated as IEWDS). IEWDS allows us to find solutions of games where IEDS doesn’t work (see the second price auction example below). If IEWDS gives us a unique solution, we call the resulting strategy as a rationalizable strategy\nHowever, unlike IEDS where the order of elimination of strategies does not matter, in IEWDS we can end up with different games depending on the order of elimination of strategies. For example, consider the following game:\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNote that both strategies \\(\\mathsf{L}\\) and \\(\\mathsf{R}\\) are weakly dominated by \\(\\mathsf{M}\\).\n\nCase 1: Eliminate \\(\\mathsf{L}\\)\nIf we eliminate \\(\\mathsf{L}\\), we obtain the following reduction.\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNow, for \\(P_1\\), strategy \\(\\mathsf{T}\\) is dominated by strategy \\(\\mathsf{B}\\). Eliminating \\(\\mathsf{T}\\) we get\n\n\nGame \\(\\mathscr{G}_L\\)\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\nCase 2: Eliminate \\(\\mathsf{R}\\)\nIf we eliminate \\(\\mathsf{R}\\) in the original game, we get the following reduction.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nHere, for \\(P_1\\), strategy \\(\\mathsf{B}\\) is weakly dominated by strategy \\(\\mathsf{T}\\). Eliminating \\(\\mathsf{B}\\), we get\n\n\nGame \\(\\mathscr{G}_R\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\nNote that games \\(\\mathscr{G}_L\\) and \\(\\mathscr{G}_R\\) cannot be reduced further. The resulting payoffs are also different.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#second-price-auction",
    "href": "static-games/strategic-games.html#second-price-auction",
    "title": "1  Introduction",
    "section": "1.7 Second price auction",
    "text": "1.7 Second price auction\nWe will study auctions in detail later in the course, but here we use the concept of dominance to identify a rationalizable strategy in what are knows as sealed bid, second price auctions. This is an example of a game with continuous strategy spaces.\n\n\n\n\n\n\nSealed bid auctions\n\n\n\nSealed bid second price auctions work as follows:\n\nAn indivisible object is for sale.\nThe set of buyers is known as \\(N\\). Each buyer \\(i\\) attaches a value \\(v_i\\) to the object, i.e., he is willing to pay at most \\(v_i\\) for the object. The value \\(v_i\\) is the buyer’s internal assessment.\nEach buyer \\(i\\) bids \\(b_i\\), presented to the auctioneer in a sealed envelop.\nThe buyer with the highest bid wins the object. If more than one buyer have the same highest bid, then the object goes to one of them at random.\nThe key feature of second price auction is that, unlike the standard auctions, the winner does not pay what he bid. Instead, he pays the second highest bid offered (and hence the name, second price auctions).\n\n\n\nHow should a rational player act in such an auction.\n\nProposition 1.1 : In sealed bid second price auctions, the bidding strategy \\(b_i = v_i\\) weakly dominates all other strategies.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider a buyer \\(i\\) with value \\(v_i\\). Given a bid profile \\(b = (b_j)_{j \\in\nN}\\), let\n\n\\(B_{-i}\\) be the highest bid by buyers other than \\(i\\).\n\\(N_{-i}\\) be the number of buyers (excluding \\(i\\)) who bid \\(B_{-i}\\)\n\nThen, the payoff to player \\(i\\) is \\[\nu_i(b) = \\begin{cases}\n  0, & \\text{if $b_i &lt; B_{-i}$} \\\\\n  \\dfrac{v_i - B_{-i}}{N_{-i} + 1}, & \\text{if $b_i = B_{-i}$} \\\\\n  v_i - B_{-i}, & \\text{if $b_i &gt; B_{-i}$}\n\\end{cases}\\]\n\n\n\n  \n  \n  \n    \n    \n      \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n    \n        \n          $v_i$\n        \n    \n\n    \n\n    \n        \n          $b_i$\n        \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \n        \n          $v_i$\n        \n  \n  \n  \n  \n    bid = \n  \n  \n  \n  Figure: The plot of $u_i(b_i, B_{-i})$ for a fixed value of bid $b_i$ and a function of $B_{-i}$. The blue tick represents $v_i$ and the red veritical line represents the current bid.\n  Move the bid point around to see how utility function changes with \nthe bid.\n\n\n\n\n\nDivide the set of strategies \\(\\ALPHABET S_i = [0, ∞)\\) into three sets:\n\nUnder bid, i.e., bid less than \\(v_i\\): i.e., the set \\([0, v_i)\\).\nBid truthfully, bid equal to \\(v_i\\): i.e., the set \\(\\{v_i\\}\\).\nOver bid, i.e., bid greater than \\(v_i\\), i.e., the set \\((v_i,∞)\\).\n\nSee the plot in the figure above to see utility (as a function of \\(B_{-i}\\) for different values of \\(b_i\\).\nNote that the curve for truthful bidding (i.e., \\(b_i = v_i\\)) weakly dominates the curves for under bidding as well as over bidding.\n\n\n\nThe rationalizability of truthful bidding holds in many situations. More on that later.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "href": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "title": "1  Introduction",
    "section": "1.8 Dominance by mixed strategies",
    "text": "1.8 Dominance by mixed strategies\nConsider a strategic game \\(\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N},\n(u_i)_{i \\in N} \\rangle\\) where \\(\\ALPHABET S_i = \\{s_{i1}, \\dots, s_{ik}\\}\\). Then a mixed strategy for player \\(i\\) is a probability distribution \\[\n  σ_i = (σ_{i1}, \\dots, σ_{ik}),\n  \\quad\n  σ_{i\\ell} \\in [0,1],\n  \\quad\n  \\sum_{\\ell=1}^k σ_{i\\ell} = 1\n\\] over the (pure) strategies of player \\(i\\).\nFor example, suppose \\(\\ALPHABET A = \\{1,2,3\\}\\) and \\(σ_i = (0.2, 0.3, 0.5)\\). This means that player \\(i\\) chooses strategy \\(1\\) with probability \\(0.2\\), strategy \\(2\\) with probability \\(0.3\\), and strategy \\(3\\) with probability \\(0.5\\).\nWhen other players are playing pure strategies \\(s_{-i}\\) and player \\(i\\) is playing a mixed strategy \\(σ_i\\), then the expected payoff to player \\(i\\) is \\[\n  U_i(σ_i, s_{-i}) = \\sum_{\\ell=1}^k σ_{i\\ell} u_i(s_{i\\ell}, s_{-i}).\n\\]\nFor example, consider the matching pennies game where \\(σ_1 = (p, 1-p)\\). Then,\n\\[\\begin{align*}\nU_1(σ_1, H) &= p - (1-p) = 2p - 1, \\\\\nU_1(σ_1, T) &= -q + (1-p) = 1 - 2p.\n\\end{align*}\\]\nWe can think of a mixed strategy as a virtual row or virtual column in the bimatrix representation of the game as follows:\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\n\n\\(σ_1\\)\n\n\n\\(2q-1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1-2q\\)\n\n\n\\(\\bullet\\)\n\n\n\nWe will revisit mixed strategies later in the course. For now, we will simply use the idea of mixed strategies to extend the notion of IEDS and IEWDS. For example consider the game shown below (where \\(\\bullet\\) means that the value is not specified because it is not important for the discussion)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\nNote that none of the strategies of \\(P_2\\) are dominated. However, if we consider the mixed strategy \\(σ_2 = (0.5, 0, 0.5)\\), then\n\\[ U_2(\\cdot, σ_2) = \\begin{bmatrix} 1.5 \\\\ 1.5 \\end{bmatrix} \\] which dominates \\(\\mathsf{M}\\). So we can eliminate strategy \\(\\mathsf{M}\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#cournot-competition",
    "href": "static-games/strategic-games.html#cournot-competition",
    "title": "1  Introduction",
    "section": "1.9 Cournot competition",
    "text": "1.9 Cournot competition\nThis is a model from economics and we will study it because of its simplicity. It is based on a model proposed by Cournot in 1839. The model describes the strategic interstrategy between firms in an oligopoly market (i.e., a market where a few sellers serve the entire market; both monopoly and duopoly are special cases of oligopoly).\nFormally, the Cournot competition model considers a homogeneous-goods market with \\(n\\) first. A homogeneous-goods market is a market where all firms produce a homogeneous product which are perfect substitutes (e.g., consider a commodities market such as metal or oil or electricity).\nEach firm decides how much to produce. Let \\(s_i \\in \\reals_{\\ge 0}\\) denote the production of firm \\(i\\) and \\(a = \\sum_{i = 1}^n s_i\\) denote aggregate production. The price of the product depends on the aggregate production. We capture this relationship using a generic function \\(p \\colon \\reals_{\\ge 0} \\to \\reals_{\\ge 0}\\), i.e., price of product is \\(p(a)\\) when the aggregate production is \\(a\\).\nFurthermore, there is a cost \\(c\\) to produce one unit of goods. For simplicity, we assume that the cost is the same for all firms, though it is possible to consider the model this cost depends on the firm. Thus, the utility of firm \\(i\\) is \\[\n  u_i(s_i, s_{-i}) = s_i \\cdot p(a) - s_i \\cdot c.\n\\] We will analyze this game in the special case when the price function is \\[\n  p(a) = \\max \\{ M - a, 0 \\}\n\\] where \\(M\\) is the market capacity. Thus, we are assuming that prices are proportional to marginal demand.\n\nCase \\(n = 1\\)\nTo fix ideas, we consider the special case of \\(n=1\\) (i.e., a monopoly). In this case, for \\(s_1 \\in [0, M]\\), \\[\n  u_1(s_1) = s_1(M - s_1) - c s_1 = M - c -s_1) s_1.\n\\] To find the optimal value of \\(s_1\\), note that \\(u_1(s_1)\\) is concave in \\(s_1\\). Thus, we pick \\(s_1\\) such that \\(∂u_1(s_1)/∂s_1 = 0\\), i.e., \\[\n  \\frac{∂u_1(s_1)}{∂s_1} = (M - c -s_1) - s_1 = 0.\n\\] Thus, \\[\n  s_1 = \\frac{M - c}{2}\n  \\quad\\text{and}\\quad\n  u_1(s_1) = \\frac{(M-c)^2}{4}.\n\\]\n\n\nCase \\(n = 2\\)\nNow, let’s consider the case when \\(n = 2\\) (a duopoly). In this case, \\[\n   u_i(s_1, s_2) = s_i( p(s_1 + s_2) - c).\n\\] Again, we can verify that for a fixed \\(s_2\\), \\(u_1(s_1, s_2)\\) is concave in \\(s_1\\) and for a fixed \\(s_1\\), \\(u_2(s_1, s_2)\\) is concave in \\(s_2\\). So, the BR can be obtained by the first order optimality condition \\(∂ u_i(s_1, s_2)/∂ s_i\n= 0\\).\nNote that \\[ p(s_1 + s_2) = \\begin{cases}\n    M - (s_1 + s_2), & \\text{if $s_1 + s_2 \\le M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] Therefore, (ignoring the non-differentiable point \\(s_1 + s_2 = M\\)), we have \\[ \\frac{∂p(s_1 + s_2)}{∂s_i} = \\begin{cases}\n    -1, & \\text{if $s_1 + s_2 &lt; M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] So, \\[\\begin{align*}\n\\frac{∂ u_i(s_1, s_2)}{∂ s_i}\n&= p(s_1 + s_2) - c + s_i \\frac{∂ p(s_1 + s_2)}{∂ s_i} \\\\\n&= \\begin{cases}\n    M - (s_1 + s_2) - c - s_i,  & \\text{if $s_1 + s_2 \\le M$} \\\\\n    0, & \\text{otherwise}.\n  \\end{cases}\n\\end{align*}\\] So, if \\(s_1 + s_2 &lt; M\\), the BR of firm 1 and firm 2 are: \\[\n  B_1(s_2) = \\frac{M - c -s_2}{2}\n  \\quad\\text{and}\\quad\n  B_2(s_1) = \\frac{M - c - s_1}{2}.\n\\] We plot the BR relationships below.\n\n\n\n\n\nThe best response curves\n\n\n\nNow we show that the game can be simplified using the elimination of never-best response strategies.\n\nAfter first round of elimination, we have \\(\\ALPHABET S_1 = \\ALPHABET S_2 =\n\\left[ 0, \\frac{M-c}{2} \\right]\\).\nAfter second round of elimination, we have \\(\\ALPHABET S_1 = \\ALPHABET S_2 =\n\\left[ \\frac{M-c}{4}, \\frac{M-c}{4} \\right]\\).\n…\n\nContinuing this way, we can show that the process converges to the intersection point \\(\\left( \\frac{M-c}{3}, \\frac{M-c}{3} \\right)\\) with payoff \\(\\left( \\frac{(M-c)^2}{9}, \\frac{(M-c)^2}{9}\\right)\\).\nThis example shows that we can find a rationalizable strategy for continuous strategy games as well.\n\n\n\n\n\n\nBeware of the model\n\n\n\nNote that if the firms collude and fix production to \\((M-c)/4\\) (which ensures that the total production is the same as the monopoly level), it will result in a higher price and increased profits. However, this feature depends on the assumptions of the model, some of which are unrealistic. For a more realistic market model, consider the later example of Bertrand competition, where players set prices rather than production levels.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#exercises",
    "href": "static-games/strategic-games.html#exercises",
    "title": "1  Introduction",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.1 Consider the following two player game: \\(\\ALPHABET S_1 = \\ALPHABET S_2 = \\{1, \\dots, 100 \\}\\) and \\[\n  u(s_1, s_2) = \\begin{cases}\n  (s_1, s_2), & \\text{if $s_1 + s_2 &lt; 100$} \\\\\n  (s_1, 100-s_1), & \\text{if $s_1 + s_2 &gt; 100$ and $s_1 &lt; s_2$}\\\\\n  (100-s_2, s_2), & \\text{if $s_1 + s_2 &gt; 100$ and $s_2 &lt; s_1$}\\\\\n  (50,50), & \\text{if $s_1 + s_2 &gt; 100$ and $s_1 = s_2$}\n\\end{cases}\\] Find the rationalizable strategies using IEWDS.\n\n\n\n\n\n\nSelten, R. 1975. Reexamination of the perfectness concept for equilibrium points in extensive games. International Journal of Game Theory 4, 1, 25–55. DOI: 10.1007/bf01766400.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html",
    "href": "static-games/correlated-equilibrium.html",
    "title": "2  Correlated equilibrium",
    "section": "",
    "text": "2.1 Correlated equilibrium\nCosider the following “traffic stop” game:\nThere are two pure strategy Nash equilibria: \\((\\mathsf{Stop}, \\mathsf{Go})\\) and \\((\\mathsf{Go}, \\mathsf{Stop})\\). In both equilibria, one player gets a payoff of \\(1\\) and the other gets a payoff of \\(0\\).\nIn addition, there is a mixed strategy Nash equilibrium \\((\\tfrac {100}{101}, \\tfrac{1}{101})\\). The mixed strategy equilibrium seems to be worse off for both players: on average both of them get a payoff of \\(0\\) but risk a huge negative penalty of \\(-100\\).\nThe mixed strategy Nash equilibrium induces the following probability distribution on the action profiles\nA better solution is to do a randomization between the pure Nash equilibrium strategies, i.e., use the following probability distribution on the action profiles:\nThis is consistent with how we resolve the conflict in real-life: by using a traffic light which tells which user should go and which should stop. Once a traffic light makes a joint recommendation to both players, it is in the best interest of the players to follow that recommendation.\nIt is not always possible to achieve such a “coordination” via mixed strategies. The reason is that, in mixed strategies, the players are randomizing independently: so the joint distribution of the form above cannot be achieved.\nOne way to interpret correlated equilibrium is as follows:\nNow consider a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i \\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\). Let \\(\\ALPHABET A = \\prod_{i \\in \\ALPHABET N} \\ALPHABET A_i\\) be the strategy space of all players. Consider a probability distribution \\(π\\) over \\(\\ALPHABET A\\). Define an extensive form game \\(Γ(π)\\) with imperfect information as follows:\nA correlated strategy \\(π\\) is a joint probability distribution on all the pure strategies of the game. For example, consider any \\(2×2\\) two-player game. Then, a correlated strategy is of the form \\[\n  π = \\begin{bmatrix} π_{11} & π_{12} \\\\ π_{21} & π_{22} \\end{bmatrix},\n  \\quad π_{ij} \\ge 0,\n  \\quad \\sum_{i,j} π_{ij} = 1.\n\\]\nTo understand this definition, we restrict attetion to two player games. Consider a correlated strategy \\(π\\). Then the conditional distribution of \\(A_2\\) given \\(A_1 = a_1\\) is \\[\n  \\PR(A_2 = a_2 \\mid A_1 = a_1) =\n  \\frac{π(a_1, a_2)}{\\sum_{b_2 \\in \\ALPHABET A_2} π(a_1, b_2)}.\n\\] Note that the denominator is the same for both sides of the expectation in \\eqref{eq:corr}. So, we can rewrite \\eqref{eq:corr} as \\[\\begin{equation}\\label{eq:corr2}\n  \\sum_{a_j \\in \\ALPHABET A_j} π(a_i, a_j)\n  \\bigl[ u_i(a_i, a_j) - u_i(b_i, a_j) \\bigr] \\ge 0,\n  \\quad \\forall a_i, b_i \\in \\ALPHABET A_i,\n  \\quad \\forall i \\in \\{1,2\\}.\n\\end{equation}\\]\nNote that \\eqref{eq:corr2} are a set of linear inequalities. Therefore, the set of all correlated equilibria is convex and can be obtained by identifying the feasibility region of a linear program.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "href": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "title": "2  Correlated equilibrium",
    "section": "",
    "text": "There is an omniscient observer (who may be viewed as an information designer) who recommends strategies to the players.\nThe observer randomizes to choose his recommendations based on a probability distribution that is known to the players.\nThe recommendations are private, with each player knows only the recommendation addressed to him.\nThe mechanism is common knowledge among the players: each plaoer knows that this mechanism is being used; each player knows that the other players know that this mechanism is being used, and so on.\n\n\n\nAn outside observer (i.e., the information designer) probabilistically chooses an action profile \\(a \\in \\ALPHABET A\\) according to \\(π\\).\nThe observer reveals the coordinate \\(a_i\\) (but not \\(a_{-i}\\)) to each player \\(i \\in \\ALPHABET N\\). We may interpret this as the observer recommending strategy \\(a_i\\) to player \\(i\\).\nThe recommendation of the observer is non-binding. Each player chooses an action \\(b_i \\in \\ALPHABET A_i\\), where \\(b_i\\) may be different from \\(a_i\\).\nThe payoff of each player \\(i\\) is \\(u_i(b_1, \\dots, b_n)\\).\n\n\nDefinition 2.1 A (pure) strategy of player \\(i\\) in game \\(Γ(π)\\) is a function \\(s_i \\colon \\ALPHABET A_i \\to \\ALPHABET A_i\\), mapping every recommendation \\(a_i\\) of the observer to an action \\(s_i(a_i)\\).\n\n\n\nDefinition 2.2 Given a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i\n\\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\), a correlated equilibrium is a is a correlated strategy \\(π\\) such that \\[\\begin{equation}\\label{eq:corr}\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = a_i ]\n   \\ge\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = b_i ]\n   , \\quad\n   \\forall b_i \\in \\ALPHABET A_i,\n   \\forall i \\in \\ALPHABET N.\n\\end{equation}\\]\n\n\n\n\n\n\n\nRemark\n\n\n\nNote that Nash equilibria are special case of correlated equilibria in which the mediator recommends actions via independent randomizations. So, correlated equilibria always exist.\nIt can also be shown that any convex combination of Nash equilibira is a correlated equilibirum.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#examples",
    "href": "static-games/correlated-equilibrium.html#examples",
    "title": "2  Correlated equilibrium",
    "section": "2.2 Examples",
    "text": "2.2 Examples\n\n2.2.1 A Hawk-Dove game\nConsider the following variation of “hawk-dove” game:\n\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(2\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(-10\\)\n\n\n\\(-10\\)\n\n\n\nWe can verify that this game has two pure strategies Nash equilibria \\((\\mathsf{D}, \\mathsf{H})\\) and \\((\\mathsf{H}, \\mathsf{D})\\). In addition, there is a symmetric mixed strategy Nash equilibrium \\((\\tfrac {10}{11},\n\\tfrac{1}{11})\\) which has a payoff of \\((\\tfrac{20}{11}, \\tfrac{20}{11})\\).\n\\[\n\\def\\D{\\mathsf{D}}\n\\def\\H{\\mathsf{H}}\n\\]\nWe claim that the following is a correlated equilibrium for the game: \\[\n  π = \\begin{bmatrix}\n    \\frac {10}{12} & \\frac{1}{12} \\\\ \\frac{1}{12} & 0\n  \\end{bmatrix}\n\\]\nWe first verify the conditions in \\eqref{eq:corr} and then verify the conditions in \\eqref{eq:corr2}.\n\n2.2.1.1 Verification of \\eqref{eq:corr}\nWe consider the analysis from the point of view of player 1. By symmetry, the argument is the same for player 1.\n\nSuppose the mediator recommends strategy \\(\\D\\) to player~\\(1\\). The conditional payoff if player 1 follows the recommendation is \\[\n  \\frac{2 π(\\D, \\D) + 0 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{2 \\frac{10}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] The player’s payoff if they deviate is \\[\n  \\frac{3 π(\\D, \\D) - 10 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{3 \\frac{10}{12} - 10\\frac{1}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] Thus, the player has no incentive to deviate.\nNow suppose the mediator recommends strategy \\(\\H\\) to player \\(1\\). Then the player knows that player \\(2\\) has received a recommendation of \\(\\D\\). Since \\((\\H, \\D)\\) is a Nash equilibrium, there is no incentive to deviate.\n\n\n\n2.2.1.2 Verification of \\eqref{eq:corr2}\nWe consider each case separately:\n\n\\(i = 1\\), \\(a_1 = \\D\\), \\(b_1 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_1(\\D,\\D) - u_1(\\H,\\D) ] +\n    π(\\D,\\H)[ u_1(\\D,\\H) - u_1(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 1\\), \\(a_1 = \\H\\), \\(b_1 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\H,\\D)[ u_1(\\H,\\D) - u_1(\\D,\\D) ] +\n    π(\\H,\\H)[ u_1(\\H,\\H) - u_1(\\D,\\H) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\D\\), \\(b_2 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_2(\\D,\\D) - u_2(\\D,\\H) ] +\n    π(\\H,\\D)[ u_2(\\H,\\D) - u_2(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\H\\), \\(b_2 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\H)[ u_2(\\D,\\H) - u_2(\\D,\\D) ] +\n    π(\\H,\\H)[ u_2(\\H,\\H) - u_2(\\H,\\D) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\nThus in all cases, neither player has an incentive to deviate.\nNote that the calculation for verifying \\eqref{eq:corr2} are the same as the calculations in the numerator of verifying \\eqref{eq:corr}.\n\n\n\n\n\n\nRemark\n\n\n\nThe social payoff of the correlated equilibrium strategy is \\[\n    4 \\frac{10}{12} + 3 \\frac{1}{12} + 3 \\frac{1}{12}\n    = \\frac{46}{12}\n\\] which is higher than the social welfare of \\(40/11\\) for the mixed strategy Nash equilibrium but is worse than the team optimal payoff of \\(4\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#notes",
    "href": "static-games/correlated-equilibrium.html#notes",
    "title": "2  Correlated equilibrium",
    "section": "Notes",
    "text": "Notes\nThe notion of correlated equilibrium is due to Aumann (1974). Also see Aumann (1987). See Amir et al. (2017) for discussion of correlated equilibrium from \\(2×2\\) games. Some of the discussion in this section is adapted from Maschler et al. (2020).\nSee Papadimitriou and Roughgarden (2008) for algorithmic aspects of computing correlated equilibrium.\n\n\n\n\nAmir, R., Belkov, S., and Evstigneev, I.V. 2017. Correlated equilibrium in a nutshell. Theory and Decision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and correlation in randomized strategies. Journal of Mathematical Economics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium as an expression of bayesian rationality. Econometrica 55, 1, 1. DOI: 10.2307/1911154.\n\n\nMaschler, M., Zamir, S., and Solan, E. 2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T. 2008. Computing correlated equilibria in multi-player games. Journal of the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amir, R., Belkov, S., and Evstigneev,\nI.V. 2017. Correlated equilibrium in a nutshell. Theory and\nDecision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and\ncorrelation in randomized strategies. Journal of Mathematical\nEconomics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium\nas an expression of bayesian rationality. Econometrica\n55, 1, 1. DOI: 10.2307/1911154.\n\n\nMaschler, M., Zamir, S., and Solan, E.\n2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T.\n2008. Computing correlated equilibria in multi-player games. Journal\nof the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.\n\n\nSelten, R. 1975. Reexamination of the\nperfectness concept for equilibrium points in extensive games.\nInternational Journal of Game Theory 4, 1, 25–55. DOI:\n10.1007/bf01766400.",
    "crumbs": [
      "References"
    ]
  }
]