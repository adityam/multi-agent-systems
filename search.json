[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multi-Agent Systems",
    "section": "",
    "text": "About the course\nThese are lecture notes for ECSE 508 (Multi-Agent Systems) that I teach in the Winter term of every odd year. These notes are not meant to be exhaustive; rather my focus is to convey the key ideas in their simplest form. For a more exhaustive treatment of the subject, please refer to the reference books mentioned below.\nIf you find any typos/mistakes in the notes, please let me know. Pull requests are welcome.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "index.html#reference-books",
    "href": "index.html#reference-books",
    "title": "Multi-Agent Systems",
    "section": "Reference books",
    "text": "Reference books\n\nOsborne and Rubinstein, A Course in Game Theory, MIT Press, 1994\nZamir, Maschler, Solan, Game Theory, Cambridge University Press, 2013.",
    "crumbs": [
      "About the course"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html",
    "href": "static-games/strategic-games.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Examples\nMulti-agent decision problems are conceptually different from single agent decision problems. In a single agent decision problem, a decision maker has to choose an action \\(a \\in \\ALPHABET A\\) to minimize a cost \\(c(a)\\) (or, equivalently, receives a payoff or a utility \\(u(a)\\)). In multi-agent decision problems, different players may have different utility functions. Such settings are called games. We start with the simplest setting of two player games.\nConsider a decision problem where there are two players. Player 1 (\\(P_1\\) from now on) chooses an action \\(a_1 \\in \\ALPHABET A_1\\) and player 2 (\\(P_2\\) from now on) chooses an action \\(a_2 \\in \\ALPHABET A_2\\). Once both players have chosen their actions, \\(P_1\\) receives a payoff of \\(u_1(a_1, a_2)\\) and \\(P_2\\) receives a payoff of \\(u_2(a_1,a_2)\\). How should the players behave?\nWe start with a few examples.\nThis example can be modeled as a two player game as follow. The action sets of both players are \\(\\ALPHABET A_1 = \\ALPHABET A_2 = \\{ \\mathsf{A}, \\mathsf{R} \\}\\), where \\(\\mathsf{A}\\) means that the player accepts the bargain and \\(\\mathsf{R}\\) means that the player rejects the bargain. The utility functions can be represented compactly as follows, which is called the bimatrix representation of the game.\nIn the games described above, there is a conflict between the players. We cannot simply assert that the players should take an action which maximizes their utility because the utility of a player depends on the actions of other players, who have different incentives. The objective of game theory is to understand how to make decisions in such scenarios.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#examples",
    "href": "static-games/strategic-games.html#examples",
    "title": "1  Introduction",
    "section": "",
    "text": "Prisoner’s dilemma.\n\n\n\nTwo criminals are arrested for a crime but the prosecutors have evidence to only charge them for a lesser crime but not enough to charge them for the main crime. The prisoners are kept in separate cells with no means to communicate. The prosecutors simultaneously offer the following bargain to both prisoners: serve as a witness that the other criminal committed the crime and walk free; unless the other also confesses in which case both get sentenced. If both criminals confess, both get a reduced sentenced for the main crime (2 years in prison). If only one confesses, the criminal who confessed walks free while the other gets a full sentence for the main crime (10 years in prison). If neither prisoner takes the bargain, then both get charged for the lesser crime (1 year in prison).\n\n\n\n\n\nBimatrix representation of Prisoner’s dilemma game\n\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(-2\\)\n\n\n\\(-2\\)\n\n\n\\(0\\)\n\n\n\\(-3\\)\n\n\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(-3\\)\n\n\n\\(0\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\n\n\n\n\n\n\nBattle of sexes\n\n\n\nA couple wants to go out for the evening and there are two events taking place: a football game and an opera. One person (player 1) prefers to go to the football game while the other player (player 2) prefers to go the opera. But they want to go together and are miserable if they go to separate events.\n\n\nBattle of Sexes Game\n\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(\\mathsf{O}\\)\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{O}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\n\n\n\n\n\n\nChicken (also called Hawk-Dove)\n\n\n\nTwo drivers are headed for a single lane bridge from opposite directions. The first to swerve away yields the bridge to the other and is called ‘chicken’ (i.e., a coward). If neither swerve, both are involved in a head-on collision.\n\n\nBattle of Hawk-Dove Game\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\\(1\\)\n\n\n\\(10\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(10\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\n\n\n\n\n\n\nMatching pennies\n\n\n\nConsider a parlour game among two players. Each player has a penny and must secretly turn the penny to heads or tails. The players reveal their choices simultaneously. If the pennies match (both heads or both tails), player 1 wins. If they don’t player 2 wins.\n\n\nBattle of matching pennies game\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#modeling-strategic-games",
    "href": "static-games/strategic-games.html#modeling-strategic-games",
    "title": "1  Introduction",
    "section": "1.2 Modeling Strategic Games",
    "text": "1.2 Modeling Strategic Games\nThe above examples described games between two players. General \\(n\\)-player games can be modeled as follows.\n\nDefinition 1.1 (Strategic game) A strategic game is described by a tuple \\(\\mathscr{G} = \\langle N, (\\ALPHABET A_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle\\), where\n\n\\(N\\) is a (finite) set of players\n\\(\\ALPHABET A_i\\) is a non-empty set of actions for player \\(i\\), \\(i \\in N\\). Define \\(\\ALPHABET A = \\prod_{i \\in N}\\) as the strategy space of the game \\(\\mathscr{G}\\).\n\\(u_i \\colon \\ALPHABET A \\to \\reals\\) is the utility function of player \\(i\\), \\(i \\in N\\).\n\n\n\nRemarks\n\n\nWhen all \\(\\ALPHABET A_i\\) are finite, the game is called a finite game.\nTo play the game, each player chooses a (pure) strategy \\(a_i \\in\n\\ALPHABET A_i\\).\nThe collection \\(a = (a_i)_{i \\in N}\\) is called the strategy profile.\nGiven a profile \\(x = (x_i)_{i \\in N}\\) (not necessarily strategy profile, but any list of elements, one for each player), \\(x_{-i}\\) denotes the list \\((x_j)_{j \\in N \\setminus \\{i\\}}\\). We will write \\(x = (x_i,\nx_{-i})\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominated-strategies",
    "href": "static-games/strategic-games.html#dominated-strategies",
    "title": "1  Introduction",
    "section": "1.3 Dominated strategies",
    "text": "1.3 Dominated strategies\nWe now define the notion of dominance, which can be used to provide a solution concept for some games.\n\nDefinition 1.2 (Dominance) Consider a game \\(\\mathscr{G}\\) with standard notation. Let \\(a_i, b_i \\in \\ALPHABET A_i\\) be two strategies of player \\(i\\). We say, strategy \\(a_i\\) strictly dominates \\(b_i\\) if \\[\n  u_i(a_i, a_{-i}) \\mathbin{\\color{red}&gt;} u_i(b_i, a_{-i}),\n  \\quad \\forall a_{-i} \\in \\ALPHABET A_{-i}.\n\\] We say that \\(a_i\\) weakly dominates \\(b_i\\) if \\[\n  u_i(a_i, a_{-i}) \\mathbin{\\color{red}\\ge} u_i(b_i, a_{-i}),\n  \\quad \\forall a_{-i} \\in \\ALPHABET A_{-i}.\n\\]\nWe will also use the phrase “\\(b_i\\) is (strongly or weakly) dominated by \\(a_i\\)” to denote the same fact.\n\nA strategy \\(a_i \\in \\ALPHABET A_i\\) is called (strongly or weakly) dominant strategy if it (strongly or weakly) dominates all other strategies \\(b_i \\in \\ALPHABET A_i \\setminus \\{a_i\\}\\).\nWe now impose some assumptions on the players.\n\nAssumption (Strict Rationality) A rational player will not choose a strictly dominated strategy.\n\nNote that we have not formally defined rationality. That is more of a philosophical discussion, and for the purpose of this course, we will not present a formal definition but rather go with the colloquial meaning of the word.\n\nAssumption (Rationality of Players) All players in a game are rational.\n\nIrrespective of the definition of rationality, this assumption is often violated in practice. Human decision makers are almost never rational. Even when decisions are made by algorithms, the decisions may not be rational. There is a whole branch of decision theory which considers players with bounded rationality. However, in this course, we will make the simplifying assumption that the players are rational.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "href": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "title": "1  Introduction",
    "section": "1.4 Dominant strategy equilibrium",
    "text": "1.4 Dominant strategy equilibrium\nWe now present the simplest solution concept for a game.\n\n\n\n\n\n\nDominant strategy equilibrium\n\n\n\nDominant Strategy equilibrium is a strategy profile in which each player is playing a dominant strategy.\n\n\nFor example, consider the game of prisoner’s dilemma. Note that, for \\(P_1\\), \\[\\begin{align*}\n  u_1(\\mathsf{A}, \\cdot) &= \\begin{bmatrix} -2 & 0 \\end{bmatrix}, \\\\\n  u_1(\\mathsf{R}, \\cdot) &= \\begin{bmatrix} -3 & -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_1(\\mathsf{A}, ⋅) &gt; u_1(\\mathsf{R}, ⋅). \\] Thus \\(\\mathsf{A}\\) is a dominant strategy for \\(P_1\\).\nSimilarly, for \\(P_2\\), \\[\\begin{align*}\n  u_2(\\cdot, \\mathsf{A}) &= \\begin{bmatrix} -2 \\\\ 0 \\end{bmatrix},\n  &\n  u_2(\\cdot, \\mathsf{R}) &= \\begin{bmatrix} -3 \\\\ -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_2(⋅,\\mathsf{A}) &gt; u_2(⋅,\\mathsf{R}). \\] Thus, \\(\\mathsf{A}\\) is a dominant strategy for \\(P_2\\).\nTherefore, \\((\\mathsf{A}, \\mathsf{A})\\) is a dominant strategy equilibrium. Note that both players play \\(\\mathsf{A}\\) even though \\((\\mathsf{R}, \\mathsf{R})\\) gives a better outcome for both of them!\n\nA game may not have a dominant strategy equilibrium. For example, there are no dominant strategies in the battle of sexes and matching pennies. So, dominant strategy equilibrium is not a useful solution concept because it does not always exist. One option is to generalize the notion of dominance as explained next.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#rationalizable-equilibrium",
    "href": "static-games/strategic-games.html#rationalizable-equilibrium",
    "title": "1  Introduction",
    "section": "1.5 Rationalizable equilibrium",
    "text": "1.5 Rationalizable equilibrium\nFirst, we return to the assumptions imposed on the players. Consider the following game.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\nStrategy \\(\\mathsf{R}\\) is strictly dominated for player 2 (by strategy \\(\\mathsf{M}\\)). So, if \\(P_2\\) is rational, he will never choose \\(\\mathsf{R}\\). Can we eliminate strategy \\(\\mathsf{R}\\) from consideration?\nThe argument is not so simple. If \\(P_1\\) does not know that \\(P_2\\) is rational, he is liable to believe that \\(P_2\\) might choose strategy \\(\\mathsf{R}\\), in which case it would be in \\(P_1\\)’s interest to player strategy \\(\\mathsf{B}\\).\nHowever, if we postulate that\n\n\\(P_2\\) is rational, and\n\\(P_1\\) knows that \\(P_2\\) is rational.\n\nThen, \\(P_1\\) knows that \\(P_2\\) will not player strategy \\(\\mathsf{R}\\). However, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) is rational. Therefore, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) will not play strategy \\(\\mathsf{R}\\). Thus, we need to assume that\n\n\\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\n\nContinuing this way, we can argue that we we need to assume that\n\n\\(P_1\\) knows that \\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\nand so on.\n\nIf statements of this type hold for infinite depth, we say that the fact that \\(P_2\\) is rational is common knowledge. We will revisit common knowledge later in the course. For now, we assume the following.\n\nAssumption (Common knowledge of rationality) It is common knowledge that all players are rational.\n\nUnder the assumption of common knowledge of rationality, we can assume that the players will eliminate strictly dominated strategies. For example, in the previous example, both players can eliminate strategy \\(\\mathsf{R}\\) from consideration and simplify the original game \\(\\mathscr{G}\\) to game \\(\\mathscr{G}_1\\) shown below.\n\n\nOriginal game \\(\\mathscr{G}\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\n\n\nReduced game \\(\\mathscr{G}_1\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\nWe can continue this reasoning. In the reduced game \\(\\mathscr{G}_1\\), strategy \\(\\mathsf{B}\\) for \\(P_1\\) is dominated by strategy \\(\\mathsf{T}\\). So, we obtain the reduced game \\(\\mathscr{G}_2\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_2\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nFinally, we can eliminate strategy \\(\\mathsf{L}\\) for \\(P_1\\), which is strictly dominated by \\(\\mathsf{M}\\) to obtain game \\(\\mathscr{G}_3\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_3\\)\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nThis procedure is called IEDS (Iterative elimination of dominated strategies). If the procedure gives a unique strategy, that strategy is called a rationalizable strategy.\n\nRemarks\n\n\nIn general, IEDS may not lead to a solution (i.e., we may be left with a game which is not \\(1 × 1\\) where no strategy is dominated).\nAt each step, there may be more than one strictly dominated strategy. If so, we can simultaneously eliminate all of them.\nIrrespective of the order in which strategies are eliminated, IEDS gives the same simplified game.\n\n\n\nRationalizable equilibrium are derived under the assumption of common knowledge of rationality, which appears to be a benign assumption but is not. To see why common knowledge of rationality is a strong assumption, consider the following example, which is known as the beauty contest game.\n\n\n\n\n\n\nBeauty contest game\n\n\n\nEach player picks a real number between 0 and 100. The person who was closest to the average of the group wins a prize.\n\n\nHow will you play this game?",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "href": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "title": "1  Introduction",
    "section": "1.6 Iterative elimination of weakly dominated strategies",
    "text": "1.6 Iterative elimination of weakly dominated strategies\nWe can extend the notion of IEDS to IEWDS (Iterative elimination of weakly dominated strategies) if we make the following assumption.\n\n**Assumption (Weak rationality) A rational player never plays a weakly dominated strategy.\n\nThe weak rationality assumption is less compelling than the strict rationality assumption. Nonetheless, it allows us to find solutions of games where IEDS doesn’t work (see the second price auction example below). If IEWDS gives us a unique solution, we call the resulting strategy as a rationalizable strategy\nHowever, unlike IEDS where the order of elimination of strategies does not matter, in IEWDS we can end up with different games depending on the order of elimination of strategies. For example, consider the following game:\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNote that both strategies \\(\\mathsf{L}\\) and \\(\\mathsf{R}\\) are weakly dominated by \\(\\mathsf{M}\\).\n\nCase 1: Eliminate \\(\\mathsf{L}\\)\nIf we eliminate \\(\\mathsf{L}\\), we obtain the following reduction.\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNow, for \\(P_1\\), strategy \\(\\mathsf{T}\\) is dominated by strategy \\(\\mathsf{B}\\). Eliminating \\(\\mathsf{T}\\) we get\n\n\nGame \\(\\mathscr{G}_L\\)\n\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\nCase 2: Eliminate \\(\\mathsf{R}\\)\nIf we eliminate \\(\\mathsf{R}\\) in the original game, we get the following reduction.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nHere, for \\(P_1\\), strategy \\(\\mathsf{B}\\) is weakly dominated by strategy \\(\\mathsf{T}\\). Eliminating \\(\\mathsf{B}\\), we get\n\n\nGame \\(\\mathscr{G}_R\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\nNote that games \\(\\mathscr{G}_L\\) and \\(\\mathscr{G}_R\\) cannot be reduced further. The resulting payoffs are also different.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#second-price-auction",
    "href": "static-games/strategic-games.html#second-price-auction",
    "title": "1  Introduction",
    "section": "1.7 Second price auction",
    "text": "1.7 Second price auction\nWe will study auctions in detail later in the course, but here we use the concept of dominance to identify a rationalizable strategy in what are knows as sealed bid, second price auctions. This is an example of a game with continuous action spaces.\n\n\n\n\n\n\nSealed bid auctions\n\n\n\nSealed bid second price auctions work as follows:\n\nAn indivisible object is for sale.\nThe set of buyers is known as \\(N\\). Each buyer \\(i\\) attaches a value \\(v_i\\) to the object, i.e., he is willing to pay at most \\(v_i\\) for the object. The value \\(v_i\\) is the buyer’s internal assessment.\nEach buyer \\(i\\) bids \\(b_i\\), presented to the auctioneer in a sealed envelop.\nThe buyer with the highest bid wins the object. If more than one buyer have the same highest bid, then the object goes to one of them at random.\nThe key feature of second price auction is that, unlike the standard auctions, the winner does not pay what he bid. Instead, he pays the second highest bid offered (and hence the name, second price auctions).\n\n\n\nHow should a rational player act in such an auction.\n\nProposition 1.1 : In sealed bid second price auctions, the bidding strategy \\(b_i = v_i\\) weakly dominates all other strategies.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider a buyer \\(i\\) with value \\(v_i\\). Given a bid profile \\(b = (b_j)_{j \\in\nN}\\), let\n\n\\(B_{-i}\\) be the highest bid by buyers other than \\(i\\).\n\\(N_{-i}\\) be the number of buyers (excluding \\(i\\)) who bid \\(B_{-i}\\)\n\nThen, the payoff to player \\(i\\) is \\[\nu_i(b) = \\begin{cases}\n  0, & \\text{if $b_i &lt; B_{-i}$} \\\\\n  \\dfrac{v_i - B_{-i}}{N_{-i} + 1}, & \\text{if $b_i = B_{-i}$} \\\\\n  v_i - B_{-i}, & \\text{if $b_i &gt; B_{-i}$}\n\\end{cases}\\]\n\n\n\n  \n  \n  \n    \n    \n      \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n    \n        \n          $v_i$\n        \n    \n\n    \n\n    \n        \n          $b_i$\n        \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \n        \n          $v_i$\n        \n  \n  \n  \n  \n    bid = \n  \n  \n  \n  Figure: The plot of $u_i(b_i, B_{-i})$ for a fixed value of bid $b_i$ and a function of $B_{-i}$. The blue tick represents $v_i$ and the red veritical line represents the current bid.\n  Move the bid point around to see how utility function changes with \nthe bid.\n\n\n\n\n\nDivide the set of strategies \\(\\ALPHABET A_i = [0, ∞)\\) into three sets:\n\nUnder bid, i.e., bid less than \\(v_i\\): i.e., the set \\([0, v_i)\\).\nBid truthfully, bid equal to \\(v_i\\): i.e., the set \\(\\{v_i\\}\\).\nOver bid, i.e., bid greater than \\(v_i\\), i.e., the set \\((v_i,∞)\\).\n\nSee the plot in the figure above to see utility (as a function of \\(B_{-i}\\) for different values of \\(b_i\\).\nNote that the curve for truthful bidding (i.e., \\(b_i = v_i\\)) weakly dominates the curves for under bidding as well as over bidding.\n\n\n\nThe rationalizability of truthful bidding holds in many situations. More on that later.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "href": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "title": "1  Introduction",
    "section": "1.8 Dominance by mixed strategies",
    "text": "1.8 Dominance by mixed strategies\nConsider a strategic game \\(\\mathscr{G} = \\langle N, (\\ALPHABET A_i)_{i \\in N},\n(u_i)_{i \\in N} \\rangle\\) where \\(\\ALPHABET A_i = \\{a_{i1}, \\dots, a_{ik}\\}\\). Then a mixed strategy for player \\(i\\) is a probability distribution \\[\n  α_i = (α_{i1}, \\dots, α_{ik}),\n  \\quad\n  α_{i\\ell} \\in [0,1],\n  \\quad\n  \\sum_{\\ell=1}^k α_{i\\ell} = 1\n\\] over the (pure) strategies of player \\(i\\).\nFor example, suppose \\(\\ALPHABET A = \\{1,2,3\\}\\) and \\(α_i = (0.2, 0.3, 0.5)\\). This means that player \\(i\\) chooses action \\(1\\) with probability \\(0.2\\), action \\(2\\) with probability \\(0.3\\), and action \\(3\\) with probability \\(0.5\\).\nWhen other players are playing pure strategies \\(a_{-i}\\) and player \\(i\\) is playing a mixed strategy \\(α_i\\), then the expected payoff to player \\(i\\) is \\[\n  U_i(α_i, a_{-i}) = \\sum_{\\ell=1}^k α_{i\\ell} u_i(a_{i\\ell}, a_{-i}).\n\\]\nFor example, consider the matching pennies game where \\(α_1 = (p, 1-p)\\). Then,\n\\[\\begin{align*}\nU_1(α_1, H) &= p - (1-p) = 2p - 1, \\\\\nU_1(α_1, T) &= -q + (1-p) = 1 - 2p.\n\\end{align*}\\]\nWe can think of a mixed strategy as a virtual row or virtual column in the bimatrix representation of the game as follows:\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\n\n\\(α_1\\)\n\n\n\\(2q-1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1-2q\\)\n\n\n\\(\\bullet\\)\n\n\n\nWe will revisit mixed strategies later in the course. For now, we will simply use the idea of mixed strategies to extend the notion of IEDS and IEWDS. For example consider the game shown below (where \\(\\bullet\\) means that the value is not specified because it is not important for the discussion)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\nNote that none of the strategies of \\(P_2\\) are dominated. However, if we consider the mixed strategy \\(α_2 = (0.5, 0, 0.5)\\), then\n\\[ U_2(\\cdot, α_2) = \\begin{bmatrix} 1.5 \\\\ 1.5 \\end{bmatrix} \\] which dominates \\(\\mathsf{M}\\). So we can eliminate strategy \\(\\mathsf{M}\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#never-best-response",
    "href": "static-games/strategic-games.html#never-best-response",
    "title": "1  Introduction",
    "section": "1.9 Never best response",
    "text": "1.9 Never best response\n\n\n\n\n\n\nBest Response\n\n\n\nThe best response (in pure strategies) of player \\(i\\) to strategy profile \\(a_{-i}\\) is a strategy \\(a_i\\) that yields the highest utility, i.e., \\[\n  u_i(a_i, a_{-i}) \\ge u_i(b_i, a_{-i}), \\quad \\forall b_i \\in \\ALPHABET\n  A_i.\n\\] We say that \\(a_i\\) is strongly best response if the inequality is strict for all \\(b_i \\neq a_i\\).\n\n\nAn idea related to dominance is never best response.\n\n\n\n\n\n\nNever best response\n\n\n\nA pure strategy \\(a_i\\) is never best response if for all mixed strategies \\(α_{-i}\\) of other players there exists a mixed strategy \\(α_i\\) such that \\[ U_i(α_i, α_{-i}) &gt; U_i(a_i, α_{-i}). \\]\n\n\nLet’s reconsider the game discussed above\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\nNow consider a mixed strategy \\(α_1 = (p, 1-p)\\) for player 1. Then, the payoff to player 2 is \\[ U_2(α_1, \\cdot) = \\begin{bmatrix} 3p & 1 & 3(1-p) \\end{bmatrix} \\]\nNote that \\(\\max\\{ 3p, 3(1-p) \\} \\ge \\frac 32\\). Thus, for all values of \\(p\\), either \\(\\mathsf{L}\\) or \\(\\mathsf{R}\\) is better than \\(M\\).\nWe can generalize IEDS to eliminate neverBR strategies to obtain rationalizable strategies (in some cases).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#relationship-between-dominated-strategies-and-never-br-strategies",
    "href": "static-games/strategic-games.html#relationship-between-dominated-strategies-and-never-br-strategies",
    "title": "1  Introduction",
    "section": "1.10 Relationship between dominated strategies and never BR strategies",
    "text": "1.10 Relationship between dominated strategies and never BR strategies\nBy definition, a strictly dominated strategy is never BR. In general, the converse is not true when there are more than 3 players. We illustrate this via an example.\nConsider the following three player game. Player one is the row player, player 2 is the column player, and player 3 chooses the game matrix. We only show the payoffs for player 3.\n\n\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(8\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(4\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(4\\)\n\n\n\n\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(8\\)\n\n\n\n\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\n\n\n\n\n\\(\\mathsf{W}\\)\n\n\n\\(\\mathsf{X}\\)\n\n\n\\(\\mathsf{Y}\\)\n\n\n\\(\\mathsf{Z}\\)\n\n\n\n\nA three player game. Player 1 chooses the row, player 2 chooses the column, and player 3 chooses \\(\\mathsf{W}\\), \\(\\mathsf{X}\\), \\(\\mathsf{Y}\\), \\(\\mathsf{Z}\\). Only the payoffs of player 3 are shown.\n\n\nProposition 1.2 Strategy \\(\\mathsf{X}\\) is never a best response and can therefore be eliminated.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet \\(α_1 = [p 1-p]\\) and \\(α_2 = [q 1-q]\\) be strategies for \\(P_1\\) and \\(P_2\\), respectively. Then, \\[\\begin{align*}\n  U_3(α_1, α_2, \\mathsf{W}) &= 8pq \\\\\n  U_3(α_1, α_2, \\mathsf{X}) &= 4pq + 4(1-p)(1-q) = 8pq + 4 - 4(p+q) \\\\\n  U_3(α_1, α_2, \\mathsf{Y}) &= 8(1-p)(1-q) = 8 + 8pq - 8(p+q) \\\\\n  U_3(α_1, α_2, \\mathsf{Z}) &= 3\n\\end{align*}\\]\nIf there is some \\(α_1\\) and \\(α_2\\) such that \\(\\mathsf{X}\\) is a BR to \\((α_1,\nα_2)\\), then, \\[\\begin{align}\n   u_3(α_1, α_2, \\mathsf{X}) \\ge U_3(α_1, α_2, \\mathsf{W})\n   &\\implies\n   8pq + 4 - 4(p+q) \\ge 8pq\n   \\label{eq:1}\n   \\\\\n   u_3(α_1, α_2, \\mathsf{X}) \\ge U_3(α_1, α_2, \\mathsf{Y})\n   &\\implies\n   8pq + 4 - 4(p+q) \\ge 8 + 8pq - 8 (p+q)\n   \\label{eq:2}\n   \\\\\n   u_3(α_1, α_2, \\mathsf{X}) \\ge U_3(α_1, α_2, \\mathsf{Z})\n   &\\implies\n   8pq + 4 - 4(p+q) \\ge 3\n   \\label{eq:3}\n\\end{align}\\]\nEq. \\eqref{eq:1} and \\eqref{eq:2} imply that \\(p+q = 1\\). From AM-GM inequality, we know that \\[\npq \\le \\left(\\frac{a+b}{2}\\right)^2 = \\frac 14.\n\\] Therefore, Eq. \\eqref{eq:3} cannot be satisfied.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#cournot-competition",
    "href": "static-games/strategic-games.html#cournot-competition",
    "title": "1  Introduction",
    "section": "1.11 Cournot competition",
    "text": "1.11 Cournot competition\nThis is a model from economics and we will study it because of its simplicity. It is based on a model proposed by Cournot in 1839. The model describes the strategic interaction between firms in an oligopoly market (i.e., a market where a few sellers serve the entire market; both monopoly and duopoly are special cases of oligopoly).\nFormally, the Cournot competition model considers a homogeneous-goods market with \\(n\\) first. A homogeneous-goods market is a market where all firms produce a homogeneous product which are perfect substitutes (e.g., consider a commodities market such as metal or oil or electricity).\nEach firm decides how much to produce. Let \\(a_i \\in \\reals_{\\ge 0}\\) denote the production of firm \\(i\\) and \\(a = \\sum_{i = 1}^n a_i\\) denote aggregate production. The price of the product depends on the aggregate production. We capture this relationship using a generic function \\(p \\colon \\reals_{\\ge 0}\n\\to \\reals_{\\ge 0}\\), i.e., price of product is \\(p(a)\\) when the aggregate production is \\(a\\).\nFurthermore, there is a cost \\(c\\) to produce one unit of goods. For simplicity, we assume that the cost is the same for all firms, though it is possible to consider the model this cost depends on the firm. Thus, the utility of firm \\(i\\) is \\[\n  u_i(a_i, a_{-i}) = a_i \\cdot p(a) - a_i \\cdot c.\n\\] We will analyze this game in the special case when the price function is \\[\n  p(a) = \\max \\{ M - a, 0 \\}\n\\] where \\(M\\) is the market capacity. Thus, we are assuming that prices are proportional to marginal demand.\n\nCase \\(n = 1\\)\nTo fix ideas, we consider the special case of \\(n=1\\) (i.e., a monopoly). In this case, for \\(a_1 \\in [0, M]\\), \\[\n  u_1(a_1) = a_1(M - a_1) - c a_1 = M - c -a_1) a_1.\n\\] To find the optimal value of \\(a_1\\), note that \\(u_1(a_1)\\) is concave in \\(a_1\\). Thus, we pick \\(a_1\\) such that \\(∂u_1(a_1)/∂a_1 = 0\\), i.e., \\[\n  \\frac{∂u_1(a_1)}{∂a_1} = (M - c -a_1) - a_1 = 0.\n\\] Thus, \\[\n  a_1 = \\frac{M - c}{2}\n  \\quad\\text{and}\\quad\n  u_1(a_1) = \\frac{(M-c)^2}{4}.\n\\]\n\n\nCase \\(n = 2\\)\nNow, let’s consider the case when \\(n = 2\\) (a duopoly). In this case, \\[\n   u_i(a_1, a_2) = a_i( p(a_1 + a_2) - c).\n\\] Again, we can verify that for a fixed \\(a_2\\), \\(u_1(a_1, a_2)\\) is concave in \\(a_1\\) and for a fixed \\(a_1\\), \\(u_2(a_1, a_2)\\) is concave in \\(a_2\\). So, the BR can be obtained by the first order optimality condition \\(∂ u_i(a_1, a_2)/∂ a_i\n= 0\\).\nNote that \\[ p(a_1 + a_2) = \\begin{cases}\n    M - (a_1 + a_2), & \\text{if $a_1 + a_2 \\le M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] Therefore, (ignoring the non-differentiable point \\(a_1 + a_2 = M\\)), we have \\[ \\frac{∂p(a_1 + a_2)}{∂a_i} = \\begin{cases}\n    -1, & \\text{if $a_1 + a_2 &lt; M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] So, \\[\\begin{align*}\n\\frac{∂ u_i(a_1, a_2)}{∂ a_i}\n&= p(a_1 + a_2) - c + a_i \\frac{∂ p(a_1 + a_2)}{∂ a_i} \\\\\n&= \\begin{cases}\n    M - (a_1 + a_2) - c - a_i,  & \\text{if $a_1 + a_2 \\le M$} \\\\\n    0, & \\text{otherwise}.\n  \\end{cases}\n\\end{align*}\\] So, if \\(a_1 + a_2 &lt; M\\), the BR of firm 1 and firm 2 are: \\[\n  B_1(a_2) = \\frac{M - c -a_2}{2}\n  \\quad\\text{and}\\quad\n  B_2(a_1) = \\frac{M - c - a_1}{2}.\n\\] We plot the BR relationships below.\n\n\n\n\n\nThe best response curves\n\n\n\nNow we show that the game can be simplified using the elimination of never-best response strategies.\n\nAfter first round of elimination, we have \\(\\ALPHABET A_1 = \\ALPHABET A_2 =\n\\left[ 0, \\frac{M-c}{2} \\right]\\).\nAfter second round of elimination, we have \\(\\ALPHABET A_1 = \\ALPHABET A_2 =\n\\left[ \\frac{M-c}{4}, \\frac{M-c}{4} \\right]\\).\n…\n\nContinuing this way, we can show that the process converges to the intersection point \\(\\left( \\frac{M-c}{3}, \\frac{M-c}{3} \\right)\\) with payoff \\(\\left( \\frac{(M-c)^2}{9}, \\frac{(M-c)^2}{9}\\right)\\).\nThis example shows that we can find a rationalizable strategy for continuous action games as well.\n\n\n\n\n\n\nBeware of the model\n\n\n\nNote that if the firms collude and fix production to \\((M-c)/4\\) (which ensures that the total production is the same as the monopoly level), it will result in a higher price and increased profits. However, this feature depends on the assumptions of the model, some of which are unrealistic. For a more realistic market model, consider the later example of Bertrand competition, where players set prices rather than production levels.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#exercises",
    "href": "static-games/strategic-games.html#exercises",
    "title": "1  Introduction",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.1 Consider the following two player game: \\(\\ALPHABET A_1 = \\ALPHABET A_2 = \\{1, \\dots, 100 \\}\\) and \\[\n  u(a_1, a_2) = \\begin{cases}\n  (a_1, a_2), & \\text{if $a_1 + a_2 &lt; 100$} \\\\\n  (a_1, 100-a_1), & \\text{if $a_1 + a_2 &gt; 100$ and $a_1 &lt; a_2$}\\\\\n  (100-a_2, a_2), & \\text{if $a_1 + a_2 &gt; 100$ and $a_2 &lt; a_1$}\\\\\n  (50,50), & \\text{if $a_1 + a_2 &gt; 100$ and $a_1 = a_2$}\n\\end{cases}\\] Find the rationalizable strategies using IEWDS.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html",
    "href": "static-games/correlated-equilibrium.html",
    "title": "2  Correlated equilibrium",
    "section": "",
    "text": "2.1 Correlated equilibrium\nCosider the following “traffic stop” game:\nThere are two pure strategy Nash equilibria: \\((\\mathsf{Stop}, \\mathsf{Go})\\) and \\((\\mathsf{Go}, \\mathsf{Stop})\\). In both equilibria, one player gets a payoff of \\(1\\) and the other gets a payoff of \\(0\\).\nIn addition, there is a mixed strategy Nash equilibrium \\((\\tfrac {100}{101}, \\tfrac{1}{101})\\). The mixed strategy equilibrium seems to be worse off for both players: on average both of them get a payoff of \\(0\\) but risk a huge negative penalty of \\(-100\\).\nThe mixed strategy Nash equilibrium induces the following probability distribution on the action profiles\nA better solution is to do a randomization between the pure Nash equilibrium strategies, i.e., use the following probability distribution on the action profiles:\nThis is consistent with how we resolve the conflict in real-life: by using a traffic light which tells which user should go and which should stop. Once a traffic light makes a joint recommendation to both players, it is in the best interest of the players to follow that recommendation.\nIt is not always possible to achieve such a “coordination” via mixed strategies. The reason is that, in mixed strategies, the players are randomizing independently: so the joint distribution of the form above cannot be achieved.\nOne way to interpret correlated equilibrium is as follows:\nNow consider a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i \\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\). Let \\(\\ALPHABET A = \\prod_{i \\in \\ALPHABET N} \\ALPHABET A_i\\) be the strategy space of all players. Consider a probability distribution \\(π\\) over \\(\\ALPHABET A\\). Define an extensive form game \\(Γ(π)\\) with imperfect information as follows:\nA correlated strategy \\(π\\) is a joint probability distribution on all the pure strategies of the game. For example, consider any \\(2×2\\) two-player game. Then, a correlated strategy is of the form \\[\n  π = \\begin{bmatrix} π_{11} & π_{12} \\\\ π_{21} & π_{22} \\end{bmatrix},\n  \\quad π_{ij} \\ge 0,\n  \\quad \\sum_{i,j} π_{ij} = 1.\n\\]\nTo understand this definition, we restrict attetion to two player games. Consider a correlated strategy \\(π\\). Then the conditional distribution of \\(A_2\\) given \\(A_1 = a_1\\) is \\[\n  \\PR(A_2 = a_2 \\mid A_1 = a_1) =\n  \\frac{π(a_1, a_2)}{\\sum_{b_2 \\in \\ALPHABET A_2} π(a_1, b_2)}.\n\\] Note that the denominator is the same for both sides of the expectation in \\eqref{eq:corr}. So, we can rewrite \\eqref{eq:corr} as \\[\\begin{equation}\\label{eq:corr2}\n  \\sum_{a_j \\in \\ALPHABET A_j} π(a_i, a_j)\n  \\bigl[ u_i(a_i, a_j) - u_i(b_i, a_j) \\bigr] \\ge 0,\n  \\quad \\forall a_i, b_i \\in \\ALPHABET A_i,\n  \\quad \\forall i \\in \\{1,2\\}.\n\\end{equation}\\]\nNote that \\eqref{eq:corr2} are a set of linear inequalities. Therefore, the set of all correlated equilibria is convex and can be obtained by identifying the feasibility region of a linear program.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "href": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "title": "2  Correlated equilibrium",
    "section": "",
    "text": "There is an omniscient observer (who may be viewed as an information designer) who recommends strategies to the players.\nThe observer randomizes to choose his recommendations based on a probability distribution that is known to the players.\nThe recommendations are private, with each player knows only the recommendation addressed to him.\nThe mechanism is common knowledge among the players: each plaoer knows that this mechanism is being used; each player knows that the other players know that this mechanism is being used, and so on.\n\n\n\nAn outside observer (i.e., the information designer) probabilistically chooses an action profile \\(a \\in \\ALPHABET A\\) according to \\(π\\).\nThe observer reveals the coordinate \\(a_i\\) (but not \\(a_{-i}\\)) to each player \\(i \\in \\ALPHABET N\\). We may interpret this as the observer recommending strategy \\(a_i\\) to player \\(i\\).\nThe recommendation of the observer is non-binding. Each player chooses an action \\(b_i \\in \\ALPHABET A_i\\), where \\(b_i\\) may be different from \\(a_i\\).\nThe payoff of each player \\(i\\) is \\(u_i(b_1, \\dots, b_n)\\).\n\n\nDefinition 2.1 A (pure) strategy of player \\(i\\) in game \\(Γ(π)\\) is a function \\(s_i \\colon \\ALPHABET A_i \\to \\ALPHABET A_i\\), mapping every recommendation \\(a_i\\) of the observer to an action \\(s_i(a_i)\\).\n\n\n\nDefinition 2.2 Given a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i\n\\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\), a correlated equilibrium is a is a correlated strategy \\(π\\) such that \\[\\begin{equation}\\label{eq:corr}\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = a_i ]\n   \\ge\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = b_i ]\n   , \\quad\n   \\forall b_i \\in \\ALPHABET A_i,\n   \\forall i \\in \\ALPHABET N.\n\\end{equation}\\]\n\n\n\n\n\n\n\nRemark\n\n\n\nNote that Nash equilibria are special case of correlated equilibria in which the mediator recommends actions via independent randomizations. So, correlated equilibria always exist.\nIt can also be shown that any convex combination of Nash equilibira is a correlated equilibirum.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#examples",
    "href": "static-games/correlated-equilibrium.html#examples",
    "title": "2  Correlated equilibrium",
    "section": "2.2 Examples",
    "text": "2.2 Examples\n\n2.2.1 A Hawk-Dove game\nConsider the following variation of “hawk-dove” game:\n\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(2\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(-10\\)\n\n\n\\(-10\\)\n\n\n\nWe can verify that this game has two pure strategies Nash equilibria \\((\\mathsf{D}, \\mathsf{H})\\) and \\((\\mathsf{H}, \\mathsf{D})\\). In addition, there is a symmetric mixed strategy Nash equilibrium \\((\\tfrac {10}{11},\n\\tfrac{1}{11})\\) which has a payoff of \\((\\tfrac{20}{11}, \\tfrac{20}{11})\\).\n\\[\n\\def\\D{\\mathsf{D}}\n\\def\\H{\\mathsf{H}}\n\\]\nWe claim that the following is a correlated equilibrium for the game: \\[\n  π = \\begin{bmatrix}\n    \\frac {10}{12} & \\frac{1}{12} \\\\ \\frac{1}{12} & 0\n  \\end{bmatrix}\n\\]\nWe first verify the conditions in \\eqref{eq:corr} and then verify the conditions in \\eqref{eq:corr2}.\n\n2.2.1.1 Verification of \\eqref{eq:corr}\nWe consider the analysis from the point of view of player 1. By symmetry, the argument is the same for player 1.\n\nSuppose the mediator recommends strategy \\(\\D\\) to player~\\(1\\). The conditional payoff if player 1 follows the recommendation is \\[\n  \\frac{2 π(\\D, \\D) + 0 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{2 \\frac{10}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] The player’s payoff if they deviate is \\[\n  \\frac{3 π(\\D, \\D) - 10 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{3 \\frac{10}{12} - 10\\frac{1}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] Thus, the player has no incentive to deviate.\nNow suppose the mediator recommends strategy \\(\\H\\) to player \\(1\\). Then the player knows that player \\(2\\) has received a recommendation of \\(\\D\\). Since \\((\\H, \\D)\\) is a Nash equilibrium, there is no incentive to deviate.\n\n\n\n2.2.1.2 Verification of \\eqref{eq:corr2}\nWe consider each case separately:\n\n\\(i = 1\\), \\(a_1 = \\D\\), \\(b_1 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_1(\\D,\\D) - u_1(\\H,\\D) ] +\n    π(\\D,\\H)[ u_1(\\D,\\H) - u_1(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 1\\), \\(a_1 = \\H\\), \\(b_1 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\H,\\D)[ u_1(\\H,\\D) - u_1(\\D,\\D) ] +\n    π(\\H,\\H)[ u_1(\\H,\\H) - u_1(\\D,\\H) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\D\\), \\(b_2 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_2(\\D,\\D) - u_2(\\D,\\H) ] +\n    π(\\H,\\D)[ u_2(\\H,\\D) - u_2(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\H\\), \\(b_2 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\H)[ u_2(\\D,\\H) - u_2(\\D,\\D) ] +\n    π(\\H,\\H)[ u_2(\\H,\\H) - u_2(\\H,\\D) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\nThus in all cases, neither player has an incentive to deviate.\nNote that the calculation for verifying \\eqref{eq:corr2} are the same as the calculations in the numerator of verifying \\eqref{eq:corr}.\n\n\n\n\n\n\nRemark\n\n\n\nThe social payoff of the correlated equilibrium strategy is \\[\n    4 \\frac{10}{12} + 3 \\frac{1}{12} + 3 \\frac{1}{12}\n    = \\frac{46}{12}\n\\] which is higher than the social welfare of \\(40/11\\) for the mixed strategy Nash equilibrium but is worse than the team optimal payoff of \\(4\\).",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#notes",
    "href": "static-games/correlated-equilibrium.html#notes",
    "title": "2  Correlated equilibrium",
    "section": "Notes",
    "text": "Notes\nThe notion of correlated equilibrium is due to Aumann (1974). Also see Aumann (1987). See Amir et al. (2017) for discussion of correlated equilibrium from \\(2×2\\) games. Some of the discussion in this section is adapted from Maschler et al. (2020).\nSee Papadimitriou and Roughgarden (2008) for algorithmic aspects of computing correlated equilibrium.\n\n\n\n\nAmir, R., Belkov, S., and Evstigneev, I.V. 2017. Correlated equilibrium in a nutshell. Theory and Decision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and correlation in randomized strategies. Journal of Mathematical Economics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium as an expression of bayesian rationality. Econometrica 55, 1, 1. DOI: 10.2307/1911154.\n\n\nMaschler, M., Zamir, S., and Solan, E. 2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T. 2008. Computing correlated equilibria in multi-player games. Journal of the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.",
    "crumbs": [
      "Strategic Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amir, R., Belkov, S., and Evstigneev,\nI.V. 2017. Correlated equilibrium in a nutshell. Theory and\nDecision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and\ncorrelation in randomized strategies. Journal of Mathematical\nEconomics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium\nas an expression of bayesian rationality. Econometrica\n55, 1, 1. DOI: 10.2307/1911154.\n\n\nMaschler, M., Zamir, S., and Solan, E.\n2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T.\n2008. Computing correlated equilibria in multi-player games. Journal\nof the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.",
    "crumbs": [
      "References"
    ]
  }
]