[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multi-Agent Systems",
    "section": "",
    "text": "About the course",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#general-information",
    "href": "index.html#general-information",
    "title": "Multi-Agent Systems",
    "section": "General Information (Winter 2025)",
    "text": "General Information (Winter 2025)\n\nInstructor\n\n\nAditya Mahajan\nOffice Hours: TBD\n\n\nTeaching Assistants\n\n\nTBD\n\n\nLectures\n\n\n2:35pm–3:55pm Monday, Wednesday (ENGTR 2120)\n\n\nPrerequisites\n\n\nECSE 205 (Probability and Random Signals I)\nYou are expected to know the following concepts from basic undergraduate probability: Probability of events, independence, random variables, probability distributions (PDFs and CDFs), expectation, conditional probability, and conditional expectation.\n\n\nCommunication\n\nUse the discussion board on myCourses for all questions related to the course. Only personal emails related to medical exceptions for missing a deliverable will be answered.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-content",
    "href": "index.html#course-content",
    "title": "Multi-Agent Systems",
    "section": "Course Content",
    "text": "Course Content\n\nRational decision making; Strategic games and Bayesian games; Solution concepts: iterated elimination of dominated strategies, Nash equilibrium, Correlated equilibrium, Bayesian equilibrium; Common knowledge.\nExtensive form games with perfect information, sub-game perfect equilibrium, Markov perfect equilibrium.\nGames with imperfect information, sequential equilibrium, common information based refinements of sequential equilibrium.\nMechanism design, market equilibrium, pricing, resource allocation; Application to communication networks and power systems\n\nIn the event of extraordinary circumstances beyond the University’s control, the content and/or evaluation scheme in this course is subject to change.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-material",
    "href": "index.html#course-material",
    "title": "Multi-Agent Systems",
    "section": "Course Material",
    "text": "Course Material\n\nReference books\nI will loosely follow the following two books, though I present the material in a different order/style than the books.\n\nZamir, Maschler, Solan, Game Theory, Cambridge University Press, 2013.\nOsborne and Rubinstein, A Course in Game Theory, MIT Press, 1994\n\n\n\nOnline Course Notes\nThis semesmter, I will be attempting to type my notes and make them available on this website. Most definitely, I will fall behind and the notes for the material covered during the end of the term will not be avaiable. Even for the earlier material, the notes are not meant to be exhaustive; rather my focus is to convey the key ideas in their simplest form. For a more exhaustive treatment of the subject, please refer to the reference books mentioned above.\nIf you find any typos/mistakes in the notes, please let me know. Pull requests are welcome.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "Multi-Agent Systems",
    "section": "Evaluation",
    "text": "Evaluation\n\nAssignments (40%) Weekly homework assignments. Typically, each assignment will consist of four questions, out of which one or two randomly selected questions will be grader.\nMid Term (40%) Closed book in-class exam. March 12 (during class time)\nTerm Project (20%) A month long term project to be done in groups of two. Present one paper on any topic of your interest related to the material covered in the class.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#marking-policy",
    "href": "index.html#marking-policy",
    "title": "Multi-Agent Systems",
    "section": "Marking policy",
    "text": "Marking policy\n\nAssignments must be submitted electronically on myCourses as a PDF. You may write the assignments on paper and then scan them as a PDF (there are several such apps available for all phone platforms), or write on a tablet and convert to PDF, or type using a word processor.\nThere will no make-up examination for students who miss a mid-term.\n\nStudent who miss the exam due to a valid reason (see Faculty of Engineering policy) should notify the instructor within a week of the exam and provide necessary documentation.\nIf, and only if, proper documentation for a missed exam is presented, the marks for the missed exam will be shifted to the final exam.\nStudents who miss the mid-term exam for any other reason (e.g., no medical note, going to the exam at the wrong time, or on the wrong day, etc.) will get zero marks on the exam.\n\nAny request for reevaluation of a mid-term or an assignment must be made in writing within a week of its return. Note that requesting a re-grade will mean that you WHOLE assignment or exam will be re-graded.\nDue to paucity of grading hours, only one or two randomly selected questions will be graded in each assignment.\nThe lowest two assignments and labs will be dropped. There will be no make-up for missed assignments and labs, even if it is for a valid reason. The whole point of dropping the lowest two assignments/labs is to reduce the administrative overhead of keeping track of such missed assignments/labs.\n\n\nRight to submit in English or French written work that is to be graded.\n\nIn accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded.\n\nAcademic Integrity\n\nMcGill University values academic integrity. Therefore all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see McGill’s guide to academic honesty for more information).\nL’université McGill attache une haute importance à l’honnêteté académique. Il incombe par conséquent à tous les étudiants de comprendre ce que l’on entend par tricherie, plagiat et autres infractions académiques, ainsi que les conséquences que peuvent avoir de telles actions, selon le Code de conduite de l’étudiant et des procédures disciplinaires (pour de plus amples renseignements, veuillez consulter le guide pour l’honnêteté académique de McGill.)",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#course-delivery",
    "href": "index.html#course-delivery",
    "title": "Multi-Agent Systems",
    "section": "Course delivery",
    "text": "Course delivery\nThe course is taught in a “chalk and board” style; there will be no power point presentations. All students are expected to attend lectures and take notes. Partial notes on some of the material will be provided, but are not a substitute for the material covered in class.\n© Instructor-generated course materials (e.g., handouts, notes, summaries, exam questions) are protected by law and may not be copied or distributed in any form or in any medium without explicit permission of the instructor. Note that infringements of copyright can be subject to follow up by the University under the Code of Student Conduct and Disciplinary Procedures.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "index.html#additional-notes",
    "href": "index.html#additional-notes",
    "title": "Multi-Agent Systems",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nAs the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or contact the office of Student Accessibility and Achievement.\nEnd-of-course evaluations are one of the ways that McGill works towards maintaining and improving the quality of courses and the student’s learning experience. You will be notified by e-mail when the evaluations are available. Please note that a minimum number of responses must be received for results to be available to students.",
    "crumbs": [
      "Multi-Agent Systems",
      "About the course"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html",
    "href": "static-games/strategic-games.html",
    "title": "1  Rationalizable strategies",
    "section": "",
    "text": "1.1 Examples\nMulti-agent decision problems are conceptually different from single agent decision problems. In a single agent decision problem, a decision maker has to choose a strategy \\(s \\in \\ALPHABET S\\) and receives a payoff or utility \\(u(s)\\) (or, equivalently, incurs a cost \\(c(s)\\)). In multi-agent decision problems, the utility received by an agent may depend on the strategies of other agents. Such settings are called games. We start with the simplest setting of two player games.\nConsider a decision problem where there are two players. Player 1 (\\(P_1\\) from now on) chooses an strategy \\(s_1 \\in \\ALPHABET S_1\\) and player 2 (\\(P_2\\) from now on) chooses an strategy \\(s_2 \\in \\ALPHABET S_2\\). Once both players have chosen their strategies, \\(P_1\\) receives a payoff of \\(u_1(s_1, s_2)\\) and \\(P_2\\) receives a payoff of \\(u_2(s_1,s_2)\\). How should the players behave?\nWe start with a few examples.\nThis example can be modeled as a two player game as follow. The strategy sets of both players are \\(\\ALPHABET S_1 = \\ALPHABET S_2 = \\{ \\mathsf{A}, \\mathsf{R} \\}\\), where \\(\\mathsf{A}\\) means that the player accepts the bargain and \\(\\mathsf{R}\\) means that the player rejects the bargain. The utility functions can be represented compactly as follows, which is called the bimatrix representation of the game.\nIn the games described above, there is a conflict between the players. We cannot simply assert that the players should take an strategy which maximizes their utility because the utility of a player depends on the strategies of other players, who have different incentives. The objective of game theory is to understand how to make decisions in such scenarios.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#examples",
    "href": "static-games/strategic-games.html#examples",
    "title": "1  Rationalizable strategies",
    "section": "",
    "text": "Prisoner’s dilemma.\n\n\n\nTwo criminals are arrested for a crime but the prosecutors have evidence to only charge them for a lesser crime but not enough to charge them for the main crime. The prisoners are kept in separate cells with no means to communicate. The prosecutors simultaneously offer the following bargain to both prisoners: serve as a witness that the other criminal committed the crime and walk free; unless the other also confesses in which case both get sentenced. If both criminals confess, both get a reduced sentenced for the main crime (2 years in prison). If only one confesses, the criminal who confessed walks free while the other gets a full sentence for the main crime (10 years in prison). If neither prisoner takes the bargain, then both get charged for the lesser crime (1 year in prison).\n\n\n\n\n\nBimatrix representation of Prisoner’s dilemma game\n\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(-2\\)\n\n\n\\(-2\\)\n\n\n\\(0\\)\n\n\n\\(-3\\)\n\n\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(-3\\)\n\n\n\\(0\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\n\n\n\n\n\n\nBattle of sexes\n\n\n\nA couple wants to go out for the evening and there are two events taking place: a football game and an opera. One person (player 1) prefers to go to the football game while the other player (player 2) prefers to go the opera. But they want to go together and are miserable if they go to separate events.\n\n\nBattle of Sexes Game\n\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(\\mathsf{O}\\)\n\n\n\n\n\\(\\mathsf{F}\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{O}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\n\n\n\n\n\n\nChicken (also called Hawk-Dove)\n\n\n\nTwo drivers are headed for a single lane bridge from opposite directions. The first to swerve away yields the bridge to the other and is called ‘chicken’ (i.e., a coward). If neither swerve, both are involved in a head-on collision.\n\n\nBattle of Hawk-Dove Game\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\\(1\\)\n\n\n\\(10\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(10\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\n\n\n\n\n\n\nMatching pennies\n\n\n\nConsider a parlour game among two players. Each player has a penny and must secretly turn the penny to heads or tails. The players reveal their choices simultaneously. If the pennies match (both heads or both tails), player 1 wins. If they don’t player 2 wins.\n\n\nMatching pennies game\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#modeling-strategic-games",
    "href": "static-games/strategic-games.html#modeling-strategic-games",
    "title": "1  Rationalizable strategies",
    "section": "1.2 Modeling Strategic Games",
    "text": "1.2 Modeling Strategic Games\nThe above examples described games between two players. General \\(n\\)-player games can be modeled as follows.\n\nDefinition 1.1 (Strategic game) A strategic game is described by a tuple \\(\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle\\), where\n\n\\(N\\) is a (finite) set of players\n\\(\\ALPHABET S_i\\) is a non-empty set of strategies for player \\(i\\), \\(i \\in N\\). Define \\(\\ALPHABET S = \\prod_{i \\in N} \\ALPHABET S_i\\) as the strategy space of the game \\(\\mathscr{G}\\).\n\\(u_i \\colon \\ALPHABET S \\to \\reals\\) is the utility function of player \\(i\\), \\(i \\in N\\).\n\n\n\nRemarks\n\n\nThe utlity of player \\(i\\) depends on the strategies of all players and not just the strategy of player \\(i\\). This is the defining feature of a game.\nWhen all \\(\\ALPHABET S_i\\) are finite, the game is called a finite game. Such games are also sometimes called matrix games because they can be described by a matrix, as seen in the above examples.\nTo play the game, each player chooses a (pure) strategy \\(s_i \\in\n\\ALPHABET S_i\\).\nThe collection \\(s = (s_i)_{i \\in N}\\) is called the strategy profile.\nGiven a profile \\(x = (x_i)_{i \\in N}\\) (not necessarily strategy profile, but any list of elements, one for each player), \\(x_{-i}\\) denotes the list \\((x_j)_{j \\in N \\setminus \\{i\\}}\\). We will write \\(x = (x_i, x_{-i})\\).",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominated-strategies",
    "href": "static-games/strategic-games.html#dominated-strategies",
    "title": "1  Rationalizable strategies",
    "section": "1.3 Dominated strategies",
    "text": "1.3 Dominated strategies\nWe now define the notion of dominance, which can be used to provide a solution concept for some games.\n\nDefinition 1.2 (Dominance) Consider a game \\(\\mathscr{G}\\) with standard notation. Let \\(s_i, t_i \\in \\ALPHABET S_i\\) be two strategies of player \\(i\\). We say, strategy \\(s_i\\) strictly dominates \\(t_i\\) if \\[\n  u_i(s_i, s_{-i}) \\mathbin{\\color{red}&gt;} u_i(t_i, s_{-i}),\n  \\quad \\forall s_{-i} \\in \\ALPHABET S_{-i}.\n\\] We say that \\(s_i\\) weakly dominates \\(t_i\\) if \\[\n  u_i(s_i, s_{-i}) \\mathbin{\\color{red}\\ge} u_i(t_i, s_{-i}),\n  \\quad \\forall s_{-i} \\in \\ALPHABET S_{-i}\n\\] and the inequality is strict for at least one \\(s_{-i}\\).\nWe will also use the phrase “\\(t_i\\) is (strongly or weakly) dominated by \\(s_i\\)” to denote the same fact.\n\nA strategy \\(s_i \\in \\ALPHABET S_i\\) is called (strongly or weakly) dominant strategy if it (strongly or weakly) dominates all other strategies \\(t_i \\in \\ALPHABET S_i \\setminus \\{s_i\\}\\).\nWe now impose some assumptions on the players.\n\nAssumption. A rational player will not choose a strictly dominated strategy.\n\nNote that we have not formally defined rationality. That is more of a philosophical discussion, and for the purpose of this course, we will not present a formal definition but rather go with the colloquial meaning of the word.\n\nAssumption. All players in a game are rational.\n\nIrrespective of the definition of rationality, this assumption is often violated in practice. Human decision makers are almost never rational. Even when decisions are made by algorithms, the decisions may not be rational. There is a whole branch of decision theory which considers players with bounded rationality. However, in this course, we will make the simplifying assumption that the players are rational.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "href": "static-games/strategic-games.html#dominant-strategy-equilibrium",
    "title": "1  Rationalizable strategies",
    "section": "1.4 Dominant strategy equilibrium",
    "text": "1.4 Dominant strategy equilibrium\nWe now present the simplest solution concept for a game.\n\n\n\n\n\n\nDominant strategy equilibrium\n\n\n\nDominant Strategy equilibrium is a strategy profile in which each player is playing a dominant strategy.\n\n\nFor example, consider the game of prisoner’s dilemma. Note that, for \\(P_1\\), \\[\\begin{align*}\n  u_1(\\mathsf{A}, \\cdot) &= \\begin{bmatrix} -2 & 0 \\end{bmatrix}, \\\\\n  u_1(\\mathsf{R}, \\cdot) &= \\begin{bmatrix} -3 & -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_1(\\mathsf{A}, ⋅) &gt; u_1(\\mathsf{R}, ⋅). \\] Thus \\(\\mathsf{A}\\) is a dominant strategy for \\(P_1\\).\nSimilarly, for \\(P_2\\), \\[\\begin{align*}\n  u_2(\\cdot, \\mathsf{A}) &= \\begin{bmatrix} -2 \\\\ 0 \\end{bmatrix},\n  &\n  u_2(\\cdot, \\mathsf{R}) &= \\begin{bmatrix} -3 \\\\ -1 \\end{bmatrix}.\n\\end{align*}\\] Note that \\[ u_2(⋅,\\mathsf{A}) &gt; u_2(⋅,\\mathsf{R}). \\] Thus, \\(\\mathsf{A}\\) is a dominant strategy for \\(P_2\\).\nTherefore, \\((\\mathsf{A}, \\mathsf{A})\\) is a dominant strategy equilibrium. Note that both players play \\(\\mathsf{A}\\) even though \\((\\mathsf{R}, \\mathsf{R})\\) gives a better outcome for both of them!\n\nA game may not have a dominant strategy equilibrium. For example, there are no dominant strategies in the battle of sexes and matching pennies. So, dominant strategy equilibrium is not a useful solution concept because it does not always exist. One option is to generalize the notion of dominance as explained next.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#rationalizable-equilibrium",
    "href": "static-games/strategic-games.html#rationalizable-equilibrium",
    "title": "1  Rationalizable strategies",
    "section": "1.5 Rationalizable equilibrium",
    "text": "1.5 Rationalizable equilibrium\nFirst, we return to the assumptions imposed on the players. Consider the following game.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\nStrategy \\(\\mathsf{R}\\) is strictly dominated for player 2 (by strategy \\(\\mathsf{C}\\)). So, if \\(P_2\\) is rational, he will never choose \\(\\mathsf{R}\\). Can we eliminate strategy \\(\\mathsf{R}\\) from consideration?\nThe argument is not so simple. If \\(P_1\\) does not know that \\(P_2\\) is rational, he is liable to believe that \\(P_2\\) might choose strategy \\(\\mathsf{R}\\), in which case it would be in \\(P_1\\)’s interest to player strategy \\(\\mathsf{B}\\).\nHowever, if we postulate that\n\n\\(P_2\\) is rational, and\n\\(P_1\\) knows that \\(P_2\\) is rational.\n\nThen, \\(P_1\\) knows that \\(P_2\\) will not player strategy \\(\\mathsf{R}\\). However, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) is rational. Therefore, \\(P_2\\) doesn’t know that \\(P_1\\) knows that \\(P_2\\) will not play strategy \\(\\mathsf{R}\\). Thus, we need to assume that\n\n\\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\n\nContinuing this way, we can argue that we we need to assume that\n\n\\(P_1\\) knows that \\(P_2\\) knows that \\(P_1\\) knows that \\(P_2\\) is rational.\nand so on.\n\nIf statements of this type hold for infinite depth, we say that the fact that \\(P_2\\) is rational is common knowledge. We will revisit common knowledge later in the course. For now, we assume the following.\n\nAssumption. It is common knowledge that all players are rational.\n\nUnder the assumption of common knowledge of rationality, we can assume that the players will eliminate strictly dominated strategies. For example, in the previous example, both players can eliminate strategy \\(\\mathsf{R}\\) from consideration and simplify the original game \\(\\mathscr{G}\\) to game \\(\\mathscr{G}_1\\) shown below.\n\n\nOriginal game \\(\\mathscr{G}\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\n\n\nReduced game \\(\\mathscr{G}_1\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\nWe can continue this reasoning. In the reduced game \\(\\mathscr{G}_1\\), strategy \\(\\mathsf{B}\\) for \\(P_1\\) is dominated by strategy \\(\\mathsf{T}\\). So, we obtain the reduced game \\(\\mathscr{G}_2\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_2\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nFinally, we can eliminate strategy \\(\\mathsf{L}\\) for \\(P_1\\), which is strictly dominated by \\(\\mathsf{C}\\) to obtain game \\(\\mathscr{G}_3\\) shown below.\n\n\nReduced game \\(\\mathscr{G}_3\\)\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nThis procedure is called IEDS (Iterative elimination of dominated strategies). If the procedure gives a unique strategy, that strategy is called a rationalizable strategy.\n\nRemarks\n\n\nIn general, IEDS may not lead to a solution (i.e., we may be left with a game which is not \\(1 × 1\\) where no strategy is dominated).\nAt each step, there may be more than one strictly dominated strategy. If so, we can simultaneously eliminate all of them.\nIrrespective of the order in which strategies are eliminated, IEDS gives the same simplified game.\n\n\n\nRationalizable equilibrium are derived under the assumption of common knowledge of rationality, which appears to be a benign assumption but is not. To see why common knowledge of rationality is a strong assumption, consider the following example, which is known as the beauty contest game.\n\n\n\n\n\n\nBeauty contest game\n\n\n\nEach player picks a real number between 0 and 100. The person who was closest to the average of the group wins a prize.\n\n\nHow will you play this game?",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "href": "static-games/strategic-games.html#iterative-elimination-of-weakly-dominated-strategies",
    "title": "1  Rationalizable strategies",
    "section": "1.6 Iterative elimination of weakly dominated strategies",
    "text": "1.6 Iterative elimination of weakly dominated strategies\nWe can extend the notion of IEDS to IEWDS (Iterative elimination of weakly dominated strategies) if we make the following assumption.\n\nAssumption. A rational player never plays a weakly dominated strategy.\n\nThe assumption that a player never plays a weakly domainted strategy is less compelling than the assumption of never playing a strictly dominated strategy.\nOne way to justify the assumption of never playing a weakly dominated strategy is the concept of trembling hand principle, which is due to Selten (1975). The key idea of this principle is that the player may make mistakes when executing its strategy (hence the metaphor of trembling hand): thus all possible strategies may be used with positive probability. In such a scenario, it is never optimal to play weakly dominated strategies.\nSimilar to IEDS, we may consider an iterative procedure to eliminate weakly dominated strategies (abbreviated as IEWDS). IEWDS allows us to find solutions of games where IEDS doesn’t work (see the second price auction example below). If IEWDS gives us a unique solution, we call the resulting strategy as a rationalizable strategy\nHowever, unlike IEDS where the order of elimination of strategies does not matter, in IEWDS we can end up with different games depending on the order of elimination of strategies. For example, consider the following game:\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNote that both strategies \\(\\mathsf{L}\\) and \\(\\mathsf{R}\\) are weakly dominated by \\(\\mathsf{C}\\).\n\nCase 1: Eliminate \\(\\mathsf{L}\\)\nIf we eliminate \\(\\mathsf{L}\\), we obtain the following reduction.\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nNow, for \\(P_1\\), strategy \\(\\mathsf{T}\\) is dominated by strategy \\(\\mathsf{B}\\). Eliminating \\(\\mathsf{T}\\) we get\n\n\nGame \\(\\mathscr{G}_L\\)\n\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\n\n\nCase 2: Eliminate \\(\\mathsf{R}\\)\nIf we eliminate \\(\\mathsf{R}\\) in the original game, we get the following reduction.\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\nHere, for \\(P_1\\), strategy \\(\\mathsf{B}\\) is weakly dominated by strategy \\(\\mathsf{T}\\). Eliminating \\(\\mathsf{B}\\), we get\n\n\nGame \\(\\mathscr{G}_R\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\nNote that games \\(\\mathscr{G}_L\\) and \\(\\mathscr{G}_R\\) cannot be reduced further. The resulting payoffs are also different.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#second-price-auction",
    "href": "static-games/strategic-games.html#second-price-auction",
    "title": "1  Rationalizable strategies",
    "section": "1.7 Second price auction",
    "text": "1.7 Second price auction\nWe will study auctions in detail later in the course, but here we use the concept of dominance to identify a rationalizable strategy in what are knows as sealed bid, second price auctions. This is an example of a game with continuous strategy spaces.\n\n\n\n\n\n\nSealed bid auctions\n\n\n\nSealed bid second price auctions work as follows:\n\nAn indivisible object is for sale.\nThe set of buyers is known as \\(N\\). Each buyer \\(i\\) attaches a value \\(v_i\\) to the object, i.e., he is willing to pay at most \\(v_i\\) for the object. The value \\(v_i\\) is the buyer’s internal assessment.\nEach buyer \\(i\\) bids \\(b_i\\), presented to the auctioneer in a sealed envelop.\nThe buyer with the highest bid wins the object. If more than one buyer have the same highest bid, then the object goes to one of them at random.\nThe key feature of second price auction is that, unlike the standard auctions, the winner does not pay what he bid. Instead, he pays the second highest bid offered (and hence the name, second price auctions).\n\n\n\nHow should a rational player act in such an auction.\n\nProposition 1.1 : In sealed bid second price auctions, the bidding strategy \\(b_i = v_i\\) weakly dominates all other strategies.\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nConsider a buyer \\(i\\) with value \\(v_i\\). Given a bid profile \\(b = (b_j)_{j \\in\nN}\\), let\n\n\\(B_{-i}\\) be the highest bid by buyers other than \\(i\\).\n\\(N_{-i}\\) be the number of buyers (excluding \\(i\\)) who bid \\(B_{-i}\\)\n\nThen, the payoff to player \\(i\\) is \\[\nu_i(b) = \\begin{cases}\n  0, & \\text{if $b_i &lt; B_{-i}$} \\\\\n  \\dfrac{v_i - B_{-i}}{N_{-i} + 1}, & \\text{if $b_i = B_{-i}$} \\\\\n  v_i - B_{-i}, & \\text{if $b_i &gt; B_{-i}$}\n\\end{cases}\\]\n\n\n  \n  \n  \n    \n    \n      \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n    \n        \n          $v_i$\n        \n    \n\n    \n\n    \n        \n          $b_i$\n        \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \n        \n          $v_i$\n        \n  \n  \n  \n  \n    bid = \n  \n  \n  \n  Figure: The plot of $u_i(b_i, B_{-i})$ for a fixed value of bid $b_i$ and a function of $B_{-i}$. The blue tick represents $v_i$ and the red veritical line represents the current bid.\n  Move the bid point around to see how utility function changes with \nthe bid.\n\n\n\n\nDivide the set of strategies \\(\\ALPHABET S_i = [0, ∞)\\) into three sets:\n\nUnder bid, i.e., bid less than \\(v_i\\): i.e., the set \\([0, v_i)\\).\nBid truthfully, bid equal to \\(v_i\\): i.e., the set \\(\\{v_i\\}\\).\nOver bid, i.e., bid greater than \\(v_i\\), i.e., the set \\((v_i,∞)\\).\n\nSee the plot in the figure above to see utility (as a function of \\(B_{-i}\\) for different values of \\(b_i\\).\nNote that the curve for truthful bidding (i.e., \\(b_i = v_i\\)) weakly dominates the curves for under bidding as well as over bidding.\n\n\n\nThe rationalizability of truthful bidding holds in many situations. More on that later.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "href": "static-games/strategic-games.html#dominance-by-mixed-strategies",
    "title": "1  Rationalizable strategies",
    "section": "1.8 Dominance by mixed strategies",
    "text": "1.8 Dominance by mixed strategies\nConsider a strategic game \\(\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N},\n(u_i)_{i \\in N} \\rangle\\) where \\(\\ALPHABET S_i = \\{s_{i1}, \\dots, s_{ik}\\}\\). Then a mixed strategy for player \\(i\\) is a probability distribution \\[\n  σ_i = (σ_{i1}, \\dots, σ_{ik}),\n  \\quad\n  σ_{i\\ell} \\in [0,1],\n  \\quad\n  \\sum_{\\ell=1}^k σ_{i\\ell} = 1\n\\] over the (pure) strategies of player \\(i\\).\nFor example, suppose \\(\\ALPHABET A = \\{1,2,3\\}\\) and \\(σ_i = (0.2, 0.3, 0.5)\\). This means that player \\(i\\) chooses strategy \\(1\\) with probability \\(0.2\\), strategy \\(2\\) with probability \\(0.3\\), and strategy \\(3\\) with probability \\(0.5\\).\nWhen other players are playing pure strategies \\(s_{-i}\\) and player \\(i\\) is playing a mixed strategy \\(σ_i\\), then the expected payoff to player \\(i\\) is \\[\n  U_i(σ_i, s_{-i}) = \\sum_{\\ell=1}^k σ_{i\\ell} u_i(s_{i\\ell}, s_{-i}).\n\\]\nFor example, consider the matching pennies game where \\(σ_1 = (p, 1-p)\\). Then,\n\\[\\begin{align*}\nU_1(σ_1, H) &= p - (1-p) = 2p - 1, \\\\\nU_1(σ_1, T) &= -q + (1-p) = 1 - 2p.\n\\end{align*}\\]\nWe can think of a mixed strategy as a virtual row or virtual column in the bimatrix representation of the game as follows:\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\n\n\\(σ_1\\)\n\n\n\\(2q-1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1-2q\\)\n\n\n\\(\\bullet\\)\n\n\n\nWe will revisit mixed strategies later in the course. For now, we will simply use the idea of mixed strategies to extend the notion of IEDS and IEWDS. For example consider the game shown below (where \\(\\bullet\\) means that the value is not specified because it is not important for the discussion)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(\\bullet\\)\n\n\n\\(0\\)\n\n\n\\(\\bullet\\)\n\n\n\\(1\\)\n\n\n\\(\\bullet\\)\n\n\n\\(3\\)\n\n\n\nNote that none of the strategies of \\(P_2\\) are dominated. However, if we consider the mixed strategy \\(σ_2 = (0.5, 0, 0.5)\\), then\n\\[ U_2(\\cdot, σ_2) = \\begin{bmatrix} 1.5 \\\\ 1.5 \\end{bmatrix} \\] which dominates \\(\\mathsf{C}\\). So we can eliminate strategy \\(\\mathsf{C}\\).",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#cournot-competition",
    "href": "static-games/strategic-games.html#cournot-competition",
    "title": "1  Rationalizable strategies",
    "section": "1.9 Cournot competition",
    "text": "1.9 Cournot competition\nThis is a model from economics and we will study it because of its simplicity. It is based on a model proposed by Cournot in 1839. The model describes the strategic interstrategy between firms in an oligopoly market (i.e., a market where a few sellers serve the entire market; both monopoly and duopoly are special cases of oligopoly).\nFormally, the Cournot competition model considers a homogeneous-goods market with \\(n\\) first. A homogeneous-goods market is a market where all firms produce a homogeneous product which are perfect substitutes (e.g., consider a commodities market such as metal or oil or electricity).\nEach firm decides how much to produce. Let \\(s_i \\in \\reals_{\\ge 0}\\) denote the production of firm \\(i\\) and \\(a = \\sum_{i = 1}^n s_i\\) denote aggregate production. The price of the product depends on the aggregate production. We capture this relationship using a generic function \\(p \\colon \\reals_{\\ge 0} \\to \\reals_{\\ge 0}\\), i.e., price of product is \\(p(a)\\) when the aggregate production is \\(a\\).\nFurthermore, there is a cost \\(c\\) to produce one unit of goods. For simplicity, we assume that the cost is the same for all firms, though it is possible to consider the model this cost depends on the firm. Thus, the utility of firm \\(i\\) is \\[\n  u_i(s_i, s_{-i}) = s_i \\cdot p(a) - s_i \\cdot c.\n\\] We will analyze this game in the special case when the price function is \\[\n  p(a) = \\max \\{ M - a, 0 \\}\n\\] where \\(M\\) is the market capacity. Thus, we are assuming that prices are proportional to marginal demand.\n\nCase \\(n = 1\\)\nTo fix ideas, we consider the special case of \\(n=1\\) (i.e., a monopoly). In this case, for \\(s_1 \\in [0, M]\\), \\[\n  u_1(s_1) = s_1(M - s_1) - c s_1 = M - c -s_1) s_1.\n\\] To find the optimal value of \\(s_1\\), note that \\(u_1(s_1)\\) is concave in \\(s_1\\). Thus, we pick \\(s_1\\) such that \\(∂u_1(s_1)/∂s_1 = 0\\), i.e., \\[\n  \\frac{∂u_1(s_1)}{∂s_1} = (M - c -s_1) - s_1 = 0.\n\\] Thus, \\[\n  s_1 = \\frac{M - c}{2}\n  \\quad\\text{and}\\quad\n  u_1(s_1) = \\frac{(M-c)^2}{4}.\n\\]\n\n\nCase \\(n = 2\\)\nNow, let’s consider the case when \\(n = 2\\) (a duopoly). In this case, \\[\n   u_i(s_1, s_2) = s_i( p(s_1 + s_2) - c).\n\\] Again, we can verify that for a fixed \\(s_2\\), \\(u_1(s_1, s_2)\\) is concave in \\(s_1\\) and for a fixed \\(s_1\\), \\(u_2(s_1, s_2)\\) is concave in \\(s_2\\). So, the BR can be obtained by the first order optimality condition \\(∂ u_i(s_1, s_2)/∂ s_i\n= 0\\).\nNote that \\[ p(s_1 + s_2) = \\begin{cases}\n    M - (s_1 + s_2), & \\text{if $s_1 + s_2 \\le M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] Therefore, (ignoring the non-differentiable point \\(s_1 + s_2 = M\\)), we have \\[ \\frac{∂p(s_1 + s_2)}{∂s_i} = \\begin{cases}\n    -1, & \\text{if $s_1 + s_2 &lt; M$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}\\] So, \\[\\begin{align*}\n\\frac{∂ u_i(s_1, s_2)}{∂ s_i}\n&= p(s_1 + s_2) - c + s_i \\frac{∂ p(s_1 + s_2)}{∂ s_i} \\\\\n&= \\begin{cases}\n    M - (s_1 + s_2) - c - s_i,  & \\text{if $s_1 + s_2 \\le M$} \\\\\n    0, & \\text{otherwise}.\n  \\end{cases}\n\\end{align*}\\] So, if \\(s_1 + s_2 &lt; M\\), the BR of firm 1 and firm 2 are: \\[\n  B_1(s_2) = \\frac{M - c -s_2}{2}\n  \\quad\\text{and}\\quad\n  B_2(s_1) = \\frac{M - c - s_1}{2}.\n\\] We plot the BR relationships below.\n\n\n  \n  \n  \n    \n    \n      \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n        \n          $M-c$\n        \n    \n\n    \n        \n          $\\frac{M-c}{2}$\n        \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n        \n          $\\frac{M-c}{2}$\n        \n    \n\n    \n        \n          $M-c$\n        \n    \n\n    \n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n  \n  \n  \n   Iteration = {{ step }}\n   Prev\n   Next\n  \n  \n  \n  Figure: Best response curves for Cournot competition.\n  \n\n\n\n\nNow we show that the game can be simplified using the elimination of never-best response strategies.\n\nAfter first round of elimination, we have \\(\\ALPHABET S_1 = \\ALPHABET S_2 =\n\\left[ 0, \\frac{M-c}{2} \\right]\\).\nAfter second round of elimination, we have \\(\\ALPHABET S_1 = \\ALPHABET S_2 =\n\\left[ \\frac{M-c}{4}, \\frac{M-c}{4} \\right]\\).\n…\n\nContinuing this way, we can show that the process converges to the intersection point \\(\\left( \\frac{M-c}{3}, \\frac{M-c}{3} \\right)\\) with payoff \\(\\left( \\frac{(M-c)^2}{9}, \\frac{(M-c)^2}{9}\\right)\\).\nThis example shows that we can find a rationalizable strategy for continuous strategy games as well.\n\n\n\n\n\n\nBeware of the model\n\n\n\nNote that if the firms collude and fix production to \\((M-c)/4\\) (which ensures that the total production is the same as the monopoly level), it will result in a higher price and increased profits. However, this feature depends on the assumptions of the model, some of which are unrealistic. For a more realistic market model, consider the later example of Bertrand competition, where players set prices rather than production levels.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#beyond-rationalizable-strategies-maxmin-strategies",
    "href": "static-games/strategic-games.html#beyond-rationalizable-strategies-maxmin-strategies",
    "title": "1  Rationalizable strategies",
    "section": "1.10 Beyond rationalizable strategies: Maxmin strategies",
    "text": "1.10 Beyond rationalizable strategies: Maxmin strategies\nThe concept of rationalizable strategies is attractive ut it makes strong assumption about the common knowledge of rationality of all players and even then does not always precribe a solution.\nWe now describe a notation of rationality of a player that does not rely on the rationality of other others; in fact, it makes the most pessimistic assessment of their potential behavior.\nAs an example, consider the following game.\n\n\nAn illustrative game\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(-20\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(-10\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(-100\\)\n\n\n\\(2\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\nIn this game, the row player may prefer the strategy \\(\\mathsf{T}\\) because it gaurantees a payoff of \\(2\\) and also ensures that the “risky” payoffs of \\(-10\\) and \\(-100\\) are avoided.\nSimilarly, the column player may prefer the strategy \\(\\mathsf{L}\\) because it gaurantees a payoff of \\(1\\) and avoids the “risky” outcome of \\(-20\\).\nThis motivates the following question: What is the minimum payoff that player \\(i\\) can guarantee for himself?\nIf player \\(i\\) chooses strategy \\(s_i\\), the worst payoff that he can get is \\[\n\\min_{s_{-i} \\in \\ALPHABET S_{-i}} u_i(s_i, s_{-i}).\n\\] Player \\(i\\) can then choose the strategy \\(s_i\\) to maximize the above value. In other words, risregarding the possible rationality (or irrationality) of other players, \\(P_i\\) can gurantee for himself a payoff of \\[\n\\underline v_i = \\max_{s_i \\in \\ALPHABET S_i}\n\\min_{s_{-i} \\in \\ALPHABET S_{-i}} u_i(s_i, s_{-i}).\n\\] This quantity is called the maxmin value of player \\(i\\) (sometimes also called the security level). The strategy \\(s_i^*\\) that gurantees this value is called a maxmin strategy.\nThe maxmin strategy satisfies \\[\n\\min_{s_{-i} \\in \\ALPHABET S_{-i}} u_i(s^*_i, s_{-i})\n\\ge\n\\min_{s_{-i} \\in \\ALPHABET S_{-i}} u_i(s_i, s_{-i})\n, \\quad \\forall s_i \\in \\ALPHABET S_i\n\\] which is equivalent to \\[\n  u_i(s_i^*, s_{-i}) \\ge \\underline v_i,\n\\quad \\forall s_{-i} \\in \\ALPHABET S_{-i}.\n\\] Thus, if a player plays his maxmin strategy, his minimum guaranteed payoff equals to his maxmin value, irrespective of what the other players do.\nReturning to our example, we have\n\n\nMaxmin payoffs for the illustrative example\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(\\min_{s_2 \\in \\ALPHABET S_2} u_1(s_1, s_2)\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(-20\\)\n\n\n\\(2\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(-10\\)\n\n\n\\(1\\)\n\n\n\\(-10\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(-100\\)\n\n\n\\(2\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\\(-100\\)\n\n\n\n\n\\(\\min_{s_1 \\in \\ALPHABET S_1} u_2(s_1,s_2)\\)\n\n\n\n\n\\(0\\)\n\n\n\n\n\\(-20\\)\n\n\n\\(2, 0\\)\n\n\n\n\nSome remarks\n\n\nThe maxmin value of \\(P_1\\) is \\(2\\) (guaranteed by strategy \\(\\mathsf{T}\\))\n\n\n\n\nThe maxmin value of \\(P_2\\) is \\(0\\) (guaranteed by strategy \\(\\mathsf{L}\\)).\nIf both players play their maxmin strategies, the outcome is \\((\\mathsf{T}, \\mathsf{L})\\) which gives a payoff of \\((2,1)\\), in which player 2’s payoff is greater than her maxmin value.\n\nIn general, a player may have several maxmin strategies. In such a case, when the players play thier maxmin strategies, the payoff depends on which strategy they choose.\nAs an example consider the following game.\n\n\nAn example illustrating that the maxmin payoff is not unique\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(\\min_{s_2 \\in \\ALPHABET S_2} u_1(s_1, s_2)\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(3\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(4\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(2\\)\n\n\n\\(3\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\min_{s_1 \\in \\ALPHABET S_1} u_2(s_1,s_2)\\)\n\n\n\n\n\\(1\\)\n\n\n\n\n\\(1\\)\n\n\n\\(1, 1\\)\n\n\n\n\nSome remarks\n\n\nThe maxmin value of \\(P_1\\) is \\(1\\) (guaranteed by strategy \\(\\mathsf{B}\\))\n\n\n\n\nThe maxmin value of \\(P_2\\) is \\(1\\) (guaranteed by either strategy \\(\\mathsf{L}\\) or \\(\\mathsf{R}\\)).\nWhen both players play their maxmin strategies, the outcome is either \\((\\mathsf{B}, \\mathsf{L})\\) with a payoff of \\((2,3)\\) or is \\((\\mathsf{B}, \\mathsf{R})\\) with a payoff of \\((1,1)\\). Thus, the payoff depends on the strategy chosen by player 2.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#relation-between-maxmin-strategies-and-dominant-strategies",
    "href": "static-games/strategic-games.html#relation-between-maxmin-strategies-and-dominant-strategies",
    "title": "1  Rationalizable strategies",
    "section": "1.11 Relation between maxmin strategies and dominant strategies",
    "text": "1.11 Relation between maxmin strategies and dominant strategies\n\nTheorem 1.1 A (strict or weak) dominant strategy of a player is also a maxmin strategy.\n\n\n\n\n\n\n\nProof\n\n\n\nA dominant strategy of a player is his best respose to any strategy of the other player.\n\n\nAs an example, consider sealed bid second price autions. We had shown that truthful bidding is a weakly dominant strategy of each player. It can also be obsereved that truthful bidding guarantees a payoff of \\(0\\), which is equal to the maxmin value of each player.\n\n\n\n\n\n\nStrategies obtained by iterative elimination\n\n\n\nStrategies obtained by iterative elimination are not maxmin strategies. Construct an example to show that.\n\n\n\nTheorem 1.2 A strictly dominant strategy equilibrium is the unique vector of maxmin strategies.\n\n\n\n\n\n\n\nProof\n\n\n\nA dominant strategy of a player is his best respose to any strategy of the other player.\n\n\nAs an example, consider prisoner’s dilemma.\n\n\nMaxmin strategies in prisoner’s dilemma\n\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(\\min_{s_2 \\in \\ALPHABET S_2} u_1(s_1, s_2)\\)\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(-2\\)\n\n\n\\(-2\\)\n\n\n\\(0\\)\n\n\n\\(-3\\)\n\n\n\\(-2\\)\n\n\n\n\n\\(\\mathsf{R}\\)\n\n\n\\(-3\\)\n\n\n\\(0\\)\n\n\n\\(-1\\)\n\n\n\\(-1\\)\n\n\n\\(-3\\)\n\n\n\n\n\\(\\min_{s_1 \\in \\ALPHABET S_1} u_2(s_1,s_2)\\)\n\n\n\n\n\\(-2\\)\n\n\n\n\n\\(-3\\)\n\n\n\\(-2, -2\\)\n\n\n\nAs we can see, the maxmin strategy is \\((\\mathsf{A}, \\mathsf{A})\\), which is the same as the dominant strategy equilibrium.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/strategic-games.html#exercises",
    "href": "static-games/strategic-games.html#exercises",
    "title": "1  Rationalizable strategies",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.1 Find the solution of the following games using iterative elimitation of strongly dominated strategies. Explicitly state the strategy that you are eliminating at each step and write the corresponding reduced game.\n\nGame \\(\\mathscr{G}_a\\)\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(73\\)\n\n\n\\(30\\)\n\n\n\\(57\\)\n\n\n\\(36\\)\n\n\n\\(66\\)\n\n\n\\(32\\)\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(80\\)\n\n\n\\(26\\)\n\n\n\\(35\\)\n\n\n\\(12\\)\n\n\n\\(32\\)\n\n\n\\(54\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(28\\)\n\n\n\\(27\\)\n\n\n\\(63\\)\n\n\n\\(31\\)\n\n\n\\(54\\)\n\n\n\\(29\\)\n\n\n\n\nGame \\(\\mathscr{G}_b\\)\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-5\\)\n\n\n\\(-1\\)\n\n\n\\(2\\)\n\n\n\\(2\\)\n\n\n\\(3\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(1\\)\n\n\n\\(-3\\)\n\n\n\\(1\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(0\\)\n\n\n\\(10\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\n\n\nExercise 1.2 Find the solution of the following games using iterative elimitation of weakly dominated strategies. Explicitly state the strategy that you are eliminating at each step and write the corresponding reduced game. At each step, eliminate all weakly dominated strategies for a player.\n\nGame \\(\\mathscr{G}_a\\)\n\n\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{D}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(6\\)\n\n\n\\(2\\)\n\n\n\\(6\\)\n\n\n\\(3\\)\n\n\n\\(7\\)\n\n\n\\(6\\)\n\n\n\\(2\\)\n\n\n\\(8\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(8\\)\n\n\n\\(5\\)\n\n\n\\(6\\)\n\n\n\\(9\\)\n\n\n\\(4\\)\n\n\n\\(6\\)\n\n\n\\(4\\)\n\n\n\\(7\\)\n\n\n\n\nGame \\(\\mathscr{G}_b\\)\n\n\n\n\n\n\n\\(\\mathsf{W}\\)\n\n\n\\(\\mathsf{X}\\)\n\n\n\\(\\mathsf{Y}\\)\n\n\n\\(\\mathsf{Z}\\)\n\n\n\n\n\\(\\mathsf{A}\\)\n\n\n\\(3\\)\n\n\n\\(7\\)\n\n\n\\(0\\)\n\n\n\\(13\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(5\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(5\\)\n\n\n\\(3\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(3\\)\n\n\n\\(7\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(3\\)\n\n\n\\(7\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(5\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\\(4\\)\n\n\n\\(5\\)\n\n\n\n\n\nExercise 1.3 Find the solution of the following games using iterative elimitation of strongly dominated mixed strategies. Explicitly state the strategy that you are eliminating at each step and write the corresponding reduced game.\n\nGame \\(\\mathscr{G}_a\\)\n\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(2\\)\n\n\n\\(5\\)\n\n\n\\(4\\)\n\n\n\\(3\\)\n\n\n\\(6\\)\n\n\n\\(0\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(1\\)\n\n\n\\(1\\)\n\n\n\\(5\\)\n\n\n\\(2\\)\n\n\n\\(1\\)\n\n\n\\(4\\)\n\n\n\n\n\nExercise 1.4 For each of the games in Exercise 1.1, Exercise 1.2, and Exercise 1.3, find the maxmin strategies and the maxmin value of both players.\n\n\nExercise 1.5 Consider the following two player game: \\(\\ALPHABET S_1 = \\ALPHABET S_2 = \\{1, \\dots, 100 \\}\\) and \\[\n  u(s_1, s_2) = \\begin{cases}\n  (s_1, s_2), & \\text{if $s_1 + s_2 &lt; 100$} \\\\\n  (s_1, 100-s_1), & \\text{if $s_1 + s_2 &gt; 100$ and $s_1 &lt; s_2$}\\\\\n  (100-s_2, s_2), & \\text{if $s_1 + s_2 &gt; 100$ and $s_2 &lt; s_1$}\\\\\n  (50,50), & \\text{if $s_1 + s_2 &gt; 100$ and $s_1 = s_2$}\n\\end{cases}\\] Find the rationalizable strategies using IEWDS.\n\n\n\n\n\n\nSelten, R. 1975. Reexamination of the perfectness concept for equilibrium points in extensive games. International Journal of Game Theory 4, 1, 25–55. DOI: 10.1007/bf01766400.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rationalizable strategies</span>"
    ]
  },
  {
    "objectID": "static-games/zero-sum-games.html",
    "href": "static-games/zero-sum-games.html",
    "title": "2  Zero-sum games",
    "section": "",
    "text": "2.1 Simplified notation\nRecall the game of matching pennies.\nThis game has the property that for any strategy profile \\((s_1, s_2) \\in \\ALPHABET S\\), \\[\nu_1(s_1, s_2) + u_2(s_1, s_2) = 0.\n\\] Games with such property are called zero-sum games. In this course, we will focus on two player zero sum games (ZSG).\nFor two player ZSGs, we can simplify the notation. Since \\(u_2(s_1, s_2) = -u_1(s_1, s_2)\\), we can just specify the payoff of player 1 instead of specifying the payoff of both players. For instance, the matching pennies game can be represented as\nHere we can think of \\(P_1\\) as the maximizing player and \\(P_2\\) as the minimizing player. Thus, instead of a bimatrix representation, we will specify the payoffs by a matrix and assume that the row player is the maximizer and the column player is the minimizer.\nMoreover, we will use \\(u(s_1, s_2)\\) to denote \\(u_1(s_1, s_2)\\) and \\(-u_2(s_1, s_2)\\).\nNow recall that the maxmin levels of the two players: \\[\\begin{align*}\n  \\underline v_1\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2}\n     u_1(s_1, s_2)\n  = \\textcolor{red}{\n    \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2}\n     u(s_1, s_2)}\n  \\\\\n  \\underline v_2\n  &= \\max_{s_2 \\in \\ALPHABET S_2} \\min_{s_1 \\in \\ALPHABET S_1}\n     u_2(s_1, s_2)\n  = \\textcolor{red}{\n    - \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)}\n\\end{align*}\\]\nFor ZSGs we use a simpler notation and define \\[\\begin{align*}\n  \\text{Maxmin value:} && \\underline v\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2}\n     u(s_1, s_2)\n  \\\\\n  \\text{Minmax value:} && \\bar v\n  &= \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n\\end{align*}\\]\nAs shown in Example 2.1, in general the inequality is strict. However, for some games, the maxmin value is equal to the minmax value as seen from the following example.\nAs we have seen earlier, a two player ZSG may not have a value in pure strategies. In the sequel, we will show that if we allow mixed strategies1, then every finite two player ZSG has a value!",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Zero-sum games</span>"
    ]
  },
  {
    "objectID": "static-games/zero-sum-games.html#simplified-notation",
    "href": "static-games/zero-sum-games.html#simplified-notation",
    "title": "2  Zero-sum games",
    "section": "",
    "text": "Simplified notation for ZSGs\n\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(\\mathsf{T}\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(1\\)\n\n\n\\(-1\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(-1\\)\n\n\n\\(1\\)\n\n\n\n\n\n\n\n\nExample 2.1 Find the maxmin and minmax value of matching pennies.\n\n\nTheorem 2.1 In a two player ZSG, \\[\\underline v \\le \\bar v.\\]\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nLet \\(s_1^*\\) be a maxmin strategy for \\(P_1\\) and \\(s_2^*\\) be a minmax strategy for \\(P_2\\). Then, by definition of maxmin strategy, we have \\[\n\\underline v\n  = \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2}\n     u(s_1, s_2)\n  = \\min_{s_2 \\in \\ALPHABET S_2} u(\\textcolor{red}{s^*_1}, s_2).\n\\] Thus, for any \\(s_2 \\in \\ALPHABET S_2\\), we have \\[ \\underline v \\le u(s_1^*, s_2). \\] Hence, by taking \\(s_2 = s_2^*\\), we get \\[\\begin{equation}\\label{eq:maxmin-bound}\n\\underline v \\le u(s_1^*, s_2^*).\n\\end{equation}\\]\nSimilarly, by the definition of minmax strategy, we have \\[\n\\bar v\n  = \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n  = \\max_{s_1 \\in \\ALPHABET S_1} u(s_1, \\textcolor{red}{s^*_2})\n\\] Thus, for any \\(s_1 \\in \\ALPHABET S_1\\), we have \\[ \\bar v \\ge u(s_1, s_2^*). \\] Hence, by taking \\(s_1 = s_1^*\\), we get \\[\\begin{equation}\\label{eq:minmax-bound}\n\\bar v \\ge u(s_1^*, s_2^*).\n\\end{equation}\\]\nCombining \\(\\eqref{eq:maxmin-bound}\\) and \\(\\eqref{eq:minmax-bound}\\), we get \\[\n\\underline v \\ge u(s_1^*, s_2^*) \\le \\bar v.\n\\]\n\n\n\n\n\nExample 2.2 Find the maxmin and minmax value of the following game.\n\n\nAn game where \\(\\underline v = \\bar v\\)\n\n\n\n\n\n\\(\\mathsf{L}\\)\n\n\n\\(\\mathsf{M}\\)\n\n\n\\(\\mathsf{R}\\)\n\n\n\n\n\\(\\mathsf{T}\\)\n\n\n\\(2\\)\n\n\n\\(-1\\)\n\n\n\\(-2\\)\n\n\n\n\n\\(\\mathsf{C}\\)\n\n\n\\(1\\)\n\n\n\\(0\\)\n\n\n\\(1\\)\n\n\n\n\n\\(\\mathsf{B}\\)\n\n\n\\(-2\\)\n\n\n\\(-1\\)\n\n\n\\(2\\)\n\n\n\n\n\nDefinition 2.1 In a two player ZSG if \\(\\underline v = \\bar v\\), then the quantity \\[\nv \\coloneqq \\underline v = \\bar v\n\\] is called the value of the game. Any \\((\\text{maxmin}, \\text{minmax})\\) strategy of the players is called the optimal strategy.\n\n\n1 We have already seen mixed strategies in the previous section. We will formally define them below.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Zero-sum games</span>"
    ]
  },
  {
    "objectID": "static-games/zero-sum-games.html#zero-sum-games-on-the-unit-square",
    "href": "static-games/zero-sum-games.html#zero-sum-games-on-the-unit-square",
    "title": "2  Zero-sum games",
    "section": "2.2 Zero sum games on the unit square",
    "text": "2.2 Zero sum games on the unit square\nAs an intermediate step to mixed strategies, we consider two player ZSGs on the unit square, i.e., games on which \\(\\ALPHABET S_1 = \\ALPHABET S_2 = [0,1]\\).\nFor the ease of notation, we will use \\(\\ALPHABET X = [0, 1]\\) and \\(\\ALPHABET Y = [0, 1]\\) to denote the strategy spaces of the player.\n\nExample 2.3 Consider a two player ZSG on the unit square with \\[\nu(x,y) = 4xy - 2x - y + 3, \\quad \\forall x \\in \\ALPHABET X, y \\in \\ALPHABET Y.\n\\] Does this game have a value? If so, find all optimal strategies.\n\n\n\n\n\n\n\nSolution\n\n\n\nTo check if the game has a value, we will compute the maxmin value \\[\n\\underline v = \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} u(x,y)\n\\] and the minmax value \\[\n\\bar v = \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} u(x,y)\n\\] and check if they are equal.\nConsider, \\[\\begin{align*}\n  \\min_{y \\in \\ALPHABET Y} u(x,y)\n  &= \\min_{y \\in [0,1]} \\bigl[ 4xy - 2x - y - 4 \\bigr] \\\\\n  &= \\min_{y \\in [0,1]} \\bigl[ (4x -1) y - 2x + 3 \\bigr].\n\\end{align*}\\] For a fixed \\(x\\), this is a linear function in \\(y\\) and the minimizer depends on the slope.\n\nIf the slope is positive, then the function is inreasing in \\(y\\) and the miniizer is \\(0\\).\nIf the slope is negative, then the function is decreasing in \\(y\\) and the minimizer is \\(1\\).\n\nTherefore, we have the following: \\[\n  \\min_{y \\in [0,1]} u(x,y) =\n  \\begin{cases}\n    2x + 2, & \\text{if } x &lt; \\tfrac 14 \\\\\n    2.5, & \\text{if } x = \\tfrac 14 \\\\\n   -2x + 3, & \\text{if } x &gt; \\tfrac 14\n  \\end{cases}\n\\]\nThe plot of \\(\\min_{y \\in [0,1]} u(x,y)\\) is shown below.\n\nAs we can see from the plot, \\[\n\\bbox[5pt,border: 1px solid]{\n  \\underline v =\n  \\max_{x \\in [0,1]} \\min_{y \\in [0,1]} u(x,y) = 2.5.\n}\n\\]\nNow consider \\[\\begin{align*}\n  \\max_{x \\in \\ALPHABET X} u(x,y)\n  &= \\max_{x \\in [0,1]} \\bigl[ 4xy - 2x - y + 3 \\bigr] \\\\\n  &= \\max_{x \\in [0,1]} \\bigl[ (4y - 2) x - y + 3 \\bigr]\n\\end{align*}\\]\nBy the same argument as before, we have \\[\n  \\max_{x \\in [0,1]} u(x,y) =\n  \\begin{cases}\n    -y + 3, & \\text{if } y &lt; \\tfrac 12 \\\\\n    2.5, & \\text{if } y = \\tfrac 12 \\\\\n    3y + 1, & \\text{if } y &gt; \\tfrac 12\n  \\end{cases}\n\\]\nThe plot of \\(\\max_{x \\in [0,1]} u(x,y)\\) is shown below.\n\nAs we can see from the plot, \\[\n\\bbox[5pt,border: 1px solid]{\n  \\bar v =\n  \\min_{y \\in [0,1]} \\max_{x \\in [0,1]} u(x,y) = 2.5.\n}\n\\]\nSince \\(\\underline v = \\bar v = 2.5\\), the game has a value of \\(2.5\\). The unique optimal strategy is \\((\\tfrac 14, \\tfrac 12)\\).\n\n\nThe previous example is an illustration of what is known as the :Minimax Theorem. One of the foundational results of Game Theory is the von Neumann minimax theorem (von Neumann 1928).\nRecall that a function \\(f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals\\) is called bilinear if it is linear in each argument separately, i.e.,\n\n$\\(f(x_1 + x_2, y) = f(x_1,y) + f(x_2, y)\\) and \\(f(α x, y) = α f(x,y)\\);\n$\\(f(x, y_1 + y_2) = f(x, y_1) + f(x, y_2)\\) and \\(f(x, αy) = α f(x,y)\\).\n\nNote that the utility function in Example 2.3 is bilinear.\n\nTheorem 2.2 (von Neumann’s Minimax Theorem) Let \\(\\ALPHABET X\\) and \\(\\ALPHABET Y\\) be compact (i.e., closed and bounded) subsets of Eucledian spaces and \\(f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals\\) be a bilinear function. Then, \\[\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n\\]\n\nFor a facinating historial discussion of this result, see Kjeldsen (2001).\nIn Example 2.3, since the utility function is bilinear, we could have simply used Theorem 2.2 to conclude that the game has a value, without doing any calculations.\nA useful generalization of von Neumann’s minimax theorem is the following.\n\nTheorem 2.3 Let \\(\\ALPHABET X\\) and \\(\\ALPHABET Y\\) be compact subsets of Eucledian space. If \\(f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals\\) is concave-convex, i.e.,\n\nfor any fixed \\(y\\), \\(f(⋅, y) \\colon \\ALPHABET X \\to \\reals\\) is concave;\nfor any fixed \\(x\\), \\(f(x, ⋅) \\colon \\ALPHABET Y \\to \\reals\\) is convex.\n\nThen, \\[\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n\\]\n\nFor a generalization that removes the compactness assumption, see Sion (1958).\n\n\n\n\nKjeldsen, T.H. 2001. John von neumann’s conception of the minimax theorem: A journey through different mathematical contexts. Archive for History of Exact Sciences 56, 1, 39–68. Available at: http://www.jstor.org/stable/41134130 (Accessed: January 5, 2025).\n\n\nSion, M. 1958. On general minimax theorems. Pacific Journal of Mathematics 8, 1, 171–176. DOI: 10.2140/pjm.1958.8.171.\n\n\nvon Neumann, J. 1928. Zur theorie der gesellschaftsspiele. Mathematische Annalen 100, 1, 295–320. DOI: 10.1007/bf01448847.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Zero-sum games</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html",
    "href": "static-games/correlated-equilibrium.html",
    "title": "5  Correlated equilibrium",
    "section": "",
    "text": "5.1 Correlated equilibrium\nCosider the following “traffic stop” game:\nThere are two pure strategy Nash equilibria: \\((\\mathsf{Stop}, \\mathsf{Go})\\) and \\((\\mathsf{Go}, \\mathsf{Stop})\\). In both equilibria, one player gets a payoff of \\(1\\) and the other gets a payoff of \\(0\\).\nIn addition, there is a mixed strategy Nash equilibrium \\((\\tfrac {100}{101}, \\tfrac{1}{101})\\). The mixed strategy equilibrium seems to be worse off for both players: on average both of them get a payoff of \\(0\\) but risk a huge negative penalty of \\(-100\\).\nThe mixed strategy Nash equilibrium induces the following probability distribution on the action profiles\nA better solution is to do a randomization between the pure Nash equilibrium strategies, i.e., use the following probability distribution on the action profiles:\nThis is consistent with how we resolve the conflict in real-life: by using a traffic light which tells which user should go and which should stop. Once a traffic light makes a joint recommendation to both players, it is in the best interest of the players to follow that recommendation.\nIt is not always possible to achieve such a “coordination” via mixed strategies. The reason is that, in mixed strategies, the players are randomizing independently: so the joint distribution of the form above cannot be achieved.\nOne way to interpret correlated equilibrium is as follows:\nNow consider a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i \\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\). Let \\(\\ALPHABET A = \\prod_{i \\in \\ALPHABET N} \\ALPHABET A_i\\) be the strategy space of all players. Consider a probability distribution \\(π\\) over \\(\\ALPHABET A\\). Define an extensive form game \\(Γ(π)\\) with imperfect information as follows:\nA correlated strategy \\(π\\) is a joint probability distribution on all the pure strategies of the game. For example, consider any \\(2×2\\) two-player game. Then, a correlated strategy is of the form \\[\n  π = \\begin{bmatrix} π_{11} & π_{12} \\\\ π_{21} & π_{22} \\end{bmatrix},\n  \\quad π_{ij} \\ge 0,\n  \\quad \\sum_{i,j} π_{ij} = 1.\n\\]\nTo understand this definition, we restrict attetion to two player games. Consider a correlated strategy \\(π\\). Then the conditional distribution of \\(A_2\\) given \\(A_1 = a_1\\) is \\[\n  \\PR(A_2 = a_2 \\mid A_1 = a_1) =\n  \\frac{π(a_1, a_2)}{\\sum_{b_2 \\in \\ALPHABET A_2} π(a_1, b_2)}.\n\\] Note that the denominator is the same for both sides of the expectation in \\eqref{eq:corr}. So, we can rewrite \\eqref{eq:corr} as \\[\\begin{equation}\\label{eq:corr2}\n  \\sum_{a_j \\in \\ALPHABET A_j} π(a_i, a_j)\n  \\bigl[ u_i(a_i, a_j) - u_i(b_i, a_j) \\bigr] \\ge 0,\n  \\quad \\forall a_i, b_i \\in \\ALPHABET A_i,\n  \\quad \\forall i \\in \\{1,2\\}.\n\\end{equation}\\]\nNote that \\eqref{eq:corr2} are a set of linear inequalities. Therefore, the set of all correlated equilibria is convex and can be obtained by identifying the feasibility region of a linear program.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "href": "static-games/correlated-equilibrium.html#correlated-equilibrium",
    "title": "5  Correlated equilibrium",
    "section": "",
    "text": "There is an omniscient observer (who may be viewed as an information designer) who recommends strategies to the players.\nThe observer randomizes to choose his recommendations based on a probability distribution that is known to the players.\nThe recommendations are private, with each player knows only the recommendation addressed to him.\nThe mechanism is common knowledge among the players: each plaoer knows that this mechanism is being used; each player knows that the other players know that this mechanism is being used, and so on.\n\n\n\nAn outside observer (i.e., the information designer) probabilistically chooses an action profile \\(a \\in \\ALPHABET A\\) according to \\(π\\).\nThe observer reveals the coordinate \\(a_i\\) (but not \\(a_{-i}\\)) to each player \\(i \\in \\ALPHABET N\\). We may interpret this as the observer recommending strategy \\(a_i\\) to player \\(i\\).\nThe recommendation of the observer is non-binding. Each player chooses an action \\(b_i \\in \\ALPHABET A_i\\), where \\(b_i\\) may be different from \\(a_i\\).\nThe payoff of each player \\(i\\) is \\(u_i(b_1, \\dots, b_n)\\).\n\n\nDefinition 5.1 A (pure) strategy of player \\(i\\) in game \\(Γ(π)\\) is a function \\(s_i \\colon \\ALPHABET A_i \\to \\ALPHABET A_i\\), mapping every recommendation \\(a_i\\) of the observer to an action \\(s_i(a_i)\\).\n\n\n\nDefinition 5.2 Given a strategic game \\(\\mathscr{G} = \\langle \\ALPHABET N, (\\ALPHABET A_i)_{i\n\\in \\ALPHABET N}, (u_i)_{i \\in \\ALPHABET N} \\rangle\\), a correlated equilibrium is a is a correlated strategy \\(π\\) such that \\[\\begin{equation}\\label{eq:corr}\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = a_i ]\n   \\ge\n   \\EXP^{π}[ u(a_i, A_{-i}) \\mid A_i = b_i ]\n   , \\quad\n   \\forall b_i \\in \\ALPHABET A_i,\n   \\forall i \\in \\ALPHABET N.\n\\end{equation}\\]\n\n\n\n\n\n\n\nRemark\n\n\n\nNote that Nash equilibria are special case of correlated equilibria in which the mediator recommends actions via independent randomizations. So, correlated equilibria always exist.\nIt can also be shown that any convex combination of Nash equilibira is a correlated equilibirum.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#examples",
    "href": "static-games/correlated-equilibrium.html#examples",
    "title": "5  Correlated equilibrium",
    "section": "5.2 Examples",
    "text": "5.2 Examples\n\n5.2.1 A Hawk-Dove game\nConsider the following variation of “hawk-dove” game:\n\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(\\mathsf{H}\\)\n\n\n\n\n\\(\\mathsf{D}\\)\n\n\n\\(2\\)\n\n\n\\(2\\)\n\n\n\\(0\\)\n\n\n\\(3\\)\n\n\n\n\n\\(\\mathsf{H}\\)\n\n\n\\(3\\)\n\n\n\\(0\\)\n\n\n\\(-10\\)\n\n\n\\(-10\\)\n\n\n\nWe can verify that this game has two pure strategies Nash equilibria \\((\\mathsf{D}, \\mathsf{H})\\) and \\((\\mathsf{H}, \\mathsf{D})\\). In addition, there is a symmetric mixed strategy Nash equilibrium \\((\\tfrac {10}{11},\n\\tfrac{1}{11})\\) which has a payoff of \\((\\tfrac{20}{11}, \\tfrac{20}{11})\\).\n\\[\n\\def\\D{\\mathsf{D}}\n\\def\\H{\\mathsf{H}}\n\\]\nWe claim that the following is a correlated equilibrium for the game: \\[\n  π = \\begin{bmatrix}\n    \\frac {10}{12} & \\frac{1}{12} \\\\ \\frac{1}{12} & 0\n  \\end{bmatrix}\n\\]\nWe first verify the conditions in \\eqref{eq:corr} and then verify the conditions in \\eqref{eq:corr2}.\n\n5.2.1.1 Verification of \\eqref{eq:corr}\nWe consider the analysis from the point of view of player 1. By symmetry, the argument is the same for player 1.\n\nSuppose the mediator recommends strategy \\(\\D\\) to player~\\(1\\). The conditional payoff if player 1 follows the recommendation is \\[\n  \\frac{2 π(\\D, \\D) + 0 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{2 \\frac{10}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] The player’s payoff if they deviate is \\[\n  \\frac{3 π(\\D, \\D) - 10 π(\\D, \\H)}{ π(\\D, \\D) + π(\\D, \\H) }\n  = \\frac{3 \\frac{10}{12} - 10\\frac{1}{12}}{\\frac{11}{12}}\n  = \\frac{20}{11}.\n\\] Thus, the player has no incentive to deviate.\nNow suppose the mediator recommends strategy \\(\\H\\) to player \\(1\\). Then the player knows that player \\(2\\) has received a recommendation of \\(\\D\\). Since \\((\\H, \\D)\\) is a Nash equilibrium, there is no incentive to deviate.\n\n\n\n5.2.1.2 Verification of \\eqref{eq:corr2}\nWe consider each case separately:\n\n\\(i = 1\\), \\(a_1 = \\D\\), \\(b_1 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_1(\\D,\\D) - u_1(\\H,\\D) ] +\n    π(\\D,\\H)[ u_1(\\D,\\H) - u_1(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 1\\), \\(a_1 = \\H\\), \\(b_1 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\H,\\D)[ u_1(\\H,\\D) - u_1(\\D,\\D) ] +\n    π(\\H,\\H)[ u_1(\\H,\\H) - u_1(\\D,\\H) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\D\\), \\(b_2 = \\H\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\D)[ u_2(\\D,\\D) - u_2(\\D,\\H) ] +\n    π(\\H,\\D)[ u_2(\\H,\\D) - u_2(\\H,\\H) ]\n    \\\\\n    &=\n    \\frac{10}{12}[ 2 - 3 ] + \\frac{1}{12}[ 0 + 10]\n    \\\\\n    &= 0 \\ge 0.\n\\end{align*}\\]\n\\(i = 2\\), \\(a_2 = \\H\\), \\(b_2 = \\D\\): \\[\\begin{align*}\n    \\hskip 2em & \\hskip -2em\n    π(\\D,\\H)[ u_2(\\D,\\H) - u_2(\\D,\\D) ] +\n    π(\\H,\\H)[ u_2(\\H,\\H) - u_2(\\H,\\D) ]\n    \\\\\n    &=\n    \\frac{1}{12}[ 3 - 2 ] + 0 [ -10 + 0]\n    \\\\\n    &= \\frac{1}{12} \\ge 0.\n\\end{align*}\\]\n\nThus in all cases, neither player has an incentive to deviate.\nNote that the calculation for verifying \\eqref{eq:corr2} are the same as the calculations in the numerator of verifying \\eqref{eq:corr}.\n\n\n\n\n\n\nRemark\n\n\n\nThe social payoff of the correlated equilibrium strategy is \\[\n    4 \\frac{10}{12} + 3 \\frac{1}{12} + 3 \\frac{1}{12}\n    = \\frac{46}{12}\n\\] which is higher than the social welfare of \\(40/11\\) for the mixed strategy Nash equilibrium but is worse than the team optimal payoff of \\(4\\).",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "static-games/correlated-equilibrium.html#notes",
    "href": "static-games/correlated-equilibrium.html#notes",
    "title": "5  Correlated equilibrium",
    "section": "Notes",
    "text": "Notes\nThe notion of correlated equilibrium is due to Aumann (1974). Also see Aumann (1987). See Amir et al. (2017) for discussion of correlated equilibrium from \\(2×2\\) games. Some of the discussion in this section is adapted from Maschler et al. (2020).\nSee Papadimitriou and Roughgarden (2008) for algorithmic aspects of computing correlated equilibrium.\n\n\n\n\nAmir, R., Belkov, S., and Evstigneev, I.V. 2017. Correlated equilibrium in a nutshell. Theory and Decision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and correlation in randomized strategies. Journal of Mathematical Economics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium as an expression of bayesian rationality. Econometrica 55, 1, 1. DOI: 10.2307/1911154.\n\n\nMaschler, M., Zamir, S., and Solan, E. 2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T. 2008. Computing correlated equilibria in multi-player games. Journal of the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.",
    "crumbs": [
      "Multi-Agent Systems",
      "Static Games",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Correlated equilibrium</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amir, R., Belkov, S., and Evstigneev,\nI.V. 2017. Correlated equilibrium in a nutshell. Theory and\nDecision 83, 4, 457–468. DOI: 10.1007/s11238-017-9609-9.\n\n\nAumann, R.J. 1974. Subjectivity and\ncorrelation in randomized strategies. Journal of Mathematical\nEconomics 1, 1, 67–96. DOI: 10.1016/0304-4068(74)90037-8.\n\n\nAumann, R.J. 1987. Correlated equilibrium\nas an expression of bayesian rationality. Econometrica\n55, 1, 1. DOI: 10.2307/1911154.\n\n\nKjeldsen, T.H. 2001. John von neumann’s\nconception of the minimax theorem: A journey through different\nmathematical contexts. Archive for History of Exact Sciences\n56, 1, 39–68. Available at: http://www.jstor.org/stable/41134130\n(Accessed: January 5, 2025).\n\n\nMaschler, M., Zamir, S., and Solan, E.\n2020. Game theory. Cambridge University Press.\n\n\nPapadimitriou, C.H. and Roughgarden, T.\n2008. Computing correlated equilibria in multi-player games. Journal\nof the ACM 55, 3, 1–29. DOI: 10.1145/1379759.1379762.\n\n\nSelten, R. 1975. Reexamination of the\nperfectness concept for equilibrium points in extensive games.\nInternational Journal of Game Theory 4, 1, 25–55. DOI:\n10.1007/bf01766400.\n\n\nSion, M. 1958. On general minimax\ntheorems. Pacific Journal of Mathematics 8, 1,\n171–176. DOI: 10.2140/pjm.1958.8.171.\n\n\nvon Neumann, J. 1928. Zur theorie der\ngesellschaftsspiele. Mathematische Annalen 100, 1,\n295–320. DOI: 10.1007/bf01448847.",
    "crumbs": [
      "Multi-Agent Systems",
      "References"
    ]
  }
]