{
  "hash": "1aecd8896ecb971bc2f15e7b881b689c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Zero-sum games\nformat:\n  html:\n    include-in-header: \n     - ../static/html/vue.html\n\nexecute:\n  echo: false\n  freeze: true\n  cache: true\n---\n\nRecall the game of matching pennies.\n\n\n\n<table class=\"game\" align=\"center\">\n<caption>Matching pennies game</caption>\n  <tr>\n    <td></td>\n    <td colspan=\"2\">$\\mathsf{H}$</td>\n    <td colspan=\"2\">$\\mathsf{T}$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{H}$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{T}$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n  </tr>\n</table>\n\nThis game has the property that for any strategy profile $(s_1, s_2) \\in \\ALPHABET S$,\n$$\nu_1(s_1, s_2) + u_2(s_1, s_2) = 0.\n$$\nGames with such property are called **zero-sum games**. In this course, we will focus on two player zero sum games (ZSG). \n\nSome remarks\n\n: - Many classical games such sa chess, checkers, Go, etc. are two player ZSGs.\n\n- ZSGs are a highly restrictive and are, therefore, much easier to analyze as compared to general-sum games.\n\n- ZSGs emerge in many engineering applications when we consider worst case performance. Such scenarios can be considered as games against nature. \n\n- When we consider the maxmin value (or the security level) of player in general-sum game, we are effectively doing worst case analysis. This means that each player is considering an auxiliary ZSG in which all other players collude and act as a single opponnet who try to minimize the payff of the player. Thus, ZSGs can be useful even when analyzing non-zero-sum games. \n\n## Simplified notation\n\nFor two player ZSGs, we can simplify the notation. Since $u_2(s_1, s_2) = -u_1(s_1, s_2)$, we can just specify the payoff of player 1 instead of specifying the payoff of both players. For instance, the matching pennies game can be represented as\n\n<table class=\"game1\" align=\"center\">\n<caption>Simplified notation for ZSGs</caption>\n  <tr>\n    <td></td>\n    <td>$\\mathsf{H}$</td>\n    <td>$\\mathsf{T}$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{H}$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{T}$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n  </tr>\n</table>\n\nHere we can think of $P_1$ as the **maximizing player** and $P_2$ as the **minimizing player**. Thus, instead of a bimatrix representation, we will specify the payoffs by a matrix and assume that the row player is the maximizer and the column player is the minimizer. \n\nMoreover, we will use $u(s_1, s_2)$ to denote $u_1(s_1, s_2)$ and $-u_2(s_1, s_2)$. \n\nNow recall that the maxmin levels of the two players:\n\\begin{align*}\n  \\underline v_1\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u_1(s_1, s_2)\n  = \\textcolor{red}{\n    \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)}\n  \\\\\n  \\underline v_2\n  &= \\max_{s_2 \\in \\ALPHABET S_2} \\min_{s_1 \\in \\ALPHABET S_1} \n     u_2(s_1, s_2)\n  = \\textcolor{red}{\n    - \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1} \n     u(s_1, s_2)}\n\\end{align*}\n\nFor ZSGs we use a simpler notation and define\n\\begin{align*}\n  \\text{Maxmin value:} && \\underline v\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)\n  \\\\\n  \\text{Minmax value:} && \\bar v\n  &= \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n\\end{align*}\n\n:::{#exm-matching-pennies}\nFind the maxmin and minmax value of matching pennies.\n:::\n\n:::{#thm-maxmin-zsg}\nIn a two player ZSG, $$\\underline v \\le \\bar v.$$\n:::\n\n:::{.callout-note collapse=\"true\"}\n#### Proof\n\nLet $s_1^*$ be a maxmin strategy for $P_1$ and $s_2^*$ be a minmax strategy for $P_2$. Then, by definition of maxmin strategy, we have\n$$\n\\underline v \n  = \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)\n  = \\min_{s_2 \\in \\ALPHABET S_2} u(\\textcolor{red}{s^*_1}, s_2).\n$$\nThus, for any $s_2 \\in \\ALPHABET S_2$, we have\n$$ \\underline v \\le u(s_1^*, s_2). $$\nHence, by taking $s_2 = s_2^*$, we get\n\\begin{equation}\\label{eq:maxmin-bound}\n\\underline v \\le u(s_1^*, s_2^*).\n\\end{equation}\n\nSimilarly, by the definition of minmax strategy, we have\n$$\n\\bar v\n  = \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n  = \\max_{s_1 \\in \\ALPHABET S_1} u(s_1, \\textcolor{red}{s^*_2})\n$$\nThus, for any $s_1 \\in \\ALPHABET S_1$, we have\n$$ \\bar v \\ge u(s_1, s_2^*). $$\nHence, by taking $s_1 = s_1^*$, we get\n\\begin{equation}\\label{eq:minmax-bound}\n\\bar v \\ge u(s_1^*, s_2^*).\n\\end{equation}\n\nCombining \\eqref{eq:maxmin-bound} and \\eqref{eq:minmax-bound}, we get\n$$\n\\underline v \\le u(s_1^*, s_2^*) \\le \\bar v.\n$$\n:::\n\nAs shown in @exm-matching-pennies, in general the inequality is strict. However, for some games, the maxmin value is equal to the minmax value as seen from the following example.\n\n:::{#exm-value-zsg}\nFind the maxmin and minmax value of the following game.\n\n::: {#2a0177be .cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>A game where &#36;\\underline v &#61; \\bar v&#36;.</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;2&#36;</td><td>&#36;-1&#36;</td><td>&#36;-2&#36;</td></tr><tr><td>&#36;\\mathsf&#123;M&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;0&#36;</td><td>&#36;1&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;-2&#36;</td><td>&#36;-1&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n\n:::{#def-value-zsg}\nIn a two player ZSG if $\\underline v = \\bar v$, then the quantity\n$$\nv \\coloneqq \\underline v = \\bar v\n$$ \nis called the **value** of the game. Any $(\\text{maxmin}, \\text{minmax})$ strategy of the players is called the **optimal strategy profile.**\n:::\n\nAs we have seen earlier, a two player ZSG may not have a value _in pure strategies_. In the sequel, we will show that if we allow mixed strategies, then every finite two player ZSG has a value!\n\n\n## Zero sum games on the unit square\n\nAs an intermediate step to mixed strategies, we consider two player ZSGs on the unit square, i.e., games on which $\\ALPHABET S_1 = \\ALPHABET S_2 = [0,1]$. \n\nFor the ease of notation, we will use $\\ALPHABET X = [0, 1]$ and $\\ALPHABET Y = [0, 1]$ to denote the strategy spaces of the player. \n\n:::{#exm-unit-square}\nConsider a two player ZSG on the unit square with \n$$\nu(x,y) = 4xy - 2x - y + 3, \\quad \\forall x \\in \\ALPHABET X, y \\in \\ALPHABET Y.\n$$\nDoes this game have a value? If so, find all optimal strategy profiles \n:::\n\n:::{.callout-note}\n#### Solution\nTo check if the game has a value, we will compute the maxmin value\n$$\n\\underline v = \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} u(x,y)\n$$\nand the minmax value\n$$\n\\bar v = \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} u(x,y)\n$$\nand check if they are equal.\n\nConsider,\n\\begin{align*}\n  \\min_{y \\in \\ALPHABET Y} u(x,y) \n  &= \\min_{y \\in [0,1]} \\bigl[ 4xy - 2x - y - 4 \\bigr] \\\\\n  &= \\min_{y \\in [0,1]} \\bigl[ (4x -1) y - 2x + 3 \\bigr].\n\\end{align*}\nFor a fixed $x$, this is a linear function in $y$ and the minimizer depends on the slope. \n\n- If the slope is positive, then the function is inreasing in $y$ and the miniizer is $0$.\n- If the slope is negative, then the function is decreasing in $y$ and the minimizer is $1$. \n\n::::{layout-ncol=2}\n:::{.fig-1}\n![Minimizing a linear function with positive slope](figures/svg/games-on-unit-square1.svg)\n:::\n\n:::{.fig-2}\n![Minimizing a linear function with negative slope](figures/svg/games-on-unit-square2.svg)\n:::\n::::\n\nTherefore, we have the following:\n$$\n  \\min_{y \\in [0,1]} u(x,y) = \n  \\begin{cases}\n    2x + 2, & \\text{if } x < \\tfrac 14 \\\\\n    2.5, & \\text{if } x = \\tfrac 14 \\\\\n   -2x + 3, & \\text{if } x > \\tfrac 14 \n  \\end{cases}\n$$\n\nThe plot of $\\min_{y \\in [0,1]} u(x,y)$ is shown below in @fig-maxmin-p1.\n\n![Plot of $\\min_{y \\in [0,1]} u(x,y)$](figures/svg/games-on-unit-square3.svg){#fig-maxmin-p1}\n\nAs we can see from the plot, \n$$\n\\bbox[5pt,border: 1px solid]{\n  \\underline v =\n  \\max_{x \\in [0,1]} \\min_{y \\in [0,1]} u(x,y) = 2.5.\n}\n$$\n\nNow consider \n\\begin{align*}\n  \\max_{x \\in \\ALPHABET X} u(x,y) \n  &= \\max_{x \\in [0,1]} \\bigl[ 4xy - 2x - y + 3 \\bigr] \\\\\n  &= \\max_{x \\in [0,1]} \\bigl[ (4y - 2) x - y + 3 \\bigr]\n\\end{align*}\n\nBy the same argument as before, we have\n$$\n  \\max_{x \\in [0,1]} u(x,y) = \n  \\begin{cases} \n    -y + 3, & \\text{if } y < \\tfrac 12 \\\\\n    2.5, & \\text{if } y = \\tfrac 12 \\\\\n    3y + 1, & \\text{if } y > \\tfrac 12\n  \\end{cases}\n$$\n\nThe plot of $\\max_{x \\in [0,1]} u(x,y)$ is shown below @fig-maxmin-p2.\n\n![Plot of $\\max_{x \\in [0,1]} u(x,y)$](figures/svg/games-on-unit-square4.svg){#fig-maxmin-p2}\n\nAs we can see from the plot, \n$$\n\\bbox[5pt,border: 1px solid]{\n  \\bar v =\n  \\min_{y \\in [0,1]} \\max_{x \\in [0,1]} u(x,y) = 2.5.\n}\n$$\n\nSince $\\underline v = \\bar v = 2.5$, the game has a value of $2.5$. The unique optimal strategy profile is $(\\tfrac 14, \\tfrac 12)$. \n\n:::\n\nThe previous example is an illustration of what is known as the [:Minimax Theorem](https://en.wikipedia.org/wiki/Minimax_theorem). One of the foundational results of Game Theory is the von Neumann minimax theorem [@vonNeumann1928].\n\nRecall that a function $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ is called **bilinear** if it is linear in each argument separately, i.e.,\n\n- $f(x_1 + x_2, y) = f(x_1,y) + f(x_2, y)$ and $f(α x, y) = α f(x,y)$;\n- $f(x, y_1 + y_2) = f(x, y_1) + f(x, y_2)$ and $f(x, αy) = α f(x,y)$. \n\nNote that the utility function in @exm-unit-square is bilinear. \n\n:::{#thm-von-Neumann}\n#### von Neumann's Minimax Theorem\n\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be compact (i.e., closed and bounded) subsets of Eucledian spaces and $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ be a bilinear function. Then,\n$$\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n$$\n:::\n\nSome remarks:\n\n- For a facinating historial discussion of this result, see @Kjeldsen2001. \n\n- For a self contained proof of the result using elementary ideas from convex analysis, see @vonNeumann1944, Chapter 3 and @Hespanha2017, Chapter 5.\n\n- For a short proof based on [:Brouwer's fixed point theorem](https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem), see @Raghavan1994.\n\n- The minmax theorem is equivalent to the duality theorem of linear programming. See @Dantzig1951 and @vonStengel2024. \n\nIn @exm-unit-square, since the utility function is bilinear, we could have simply used @thm-von-Neumann to conclude that the game has a value, without doing any calculations. \n\nA useful generalization of von Neumann's minimax theorem is the following.\n\n:::{#thm-minmax}\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be compact subsets of Eucledian space. If $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ is concave-convex, i.e., \n\n- for any fixed $y$, $f(⋅, y) \\colon \\ALPHABET X \\to \\reals$ is concave;\n- for any fixed $x$, $f(x, ⋅) \\colon \\ALPHABET Y \\to \\reals$ is convex.\n\nThen,\n$$\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n$$\n:::\n\nFor a generalization that removes the compactness assumption, see @Sion1958. For a general discussion of various fixed point theorems and their relevance to zero sum games, see @Raghavan1994.\n\n## Mixed strategies in finite games\n\nWe now revist the notion of mixed strategies in finite games. Recall that given a finite game $\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle$ and mixed strategies $σ = (σ_i)_{i \\in N}$ for the players, the expected utility is defined as\n\\begin{equation} \\label{eq:expected-utility}\n  U_i(σ) = \\sum_{s_1 \\in \\ALPHABET S_1} \\cdots \\sum_{s_N \\in \\ALPHABET S_N} \n  σ_1(s_1) \\cdots σ_N(s_N) u_i(s_1, \\dots, s_N)\n\\end{equation}\nor more compactly for two player games\n$$\n  U_i(σ_1, σ_2) = \\sum_{s_1 \\in \\ALPHABET S_1} \\sum_{s_2 \\in \\ALPHABET S_2}\n  σ_1(s_1) σ_2(s_2) u_i(s_1, s_2).\n$$\n\nA game in which players are playing mixed strategies may be viewed as another game, called the **mixed extension**, in which all players have continuous action spaces and are playing pure strategies.\n\n:::{#def-mixed-extension}\n#### Mixed extension\n\nGiven a game $\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle$, its **mixed extension** is a game $\\mathscr{G}^* = \\langle N, ( Δ(\\ALPHABET S_i) )_{i \\in N}, (U_i)_{i \\in N} \\rangle$ where\n\n- $Δ(\\ALPHABET S_i)$ denotes the set of probability distributions over $\\ALPHABET S_i$\n- $U_i \\colon \\prod_{j \\in N} Δ(\\ALPHABET S_j) \\to \\reals$ is the expected utility function defined in \\eqref{eq:expected-utility}.\n:::\n\nFor a discussion of different interpretations of mixed strategies, see @Osborne1994 [Sec 3.2]. \n\nObserve that if the original game $\\mathscr{G}$ is a two player ZSG, then its mixed extension $\\mathscr{G}^*$ is also a two player ZSG because for any mixed strategy $(σ_1, σ_2)$\n\\begin{align*}\nU_1(σ_1, σ_2) + U_2(σ_1, σ_2) \n&= \\sum_{s_1 \\in \\ALPHABET S_1} \\sum_{s_2 \\in \\ALPHABET S_2}\nσ_1(s_1) σ_2(s_2) \\underbrace{\\bigl[ u_1(s_1,s_2) + u_2(s_1, s_2) \\bigr]}_{=0} \\\\\n&= 0.\n\\end{align*}\nThus, we may simply use $U$ to denote the expected utility of $P_1$ with the understanding that the expected utility of $P_2$ is $-U$. \n\nFurthermore, observe that $U$ is bilinear. Thus, we can conclude the following from @thm-von-Neumann.\n\n:::{#thm-ZSG-value}\nFor any finite game $\\mathscr{G}$, its mixed extesion $\\mathscr{G}^*$ has a value, which is called **value of $\\mathscr{G}$ in mixed strategies.**\n::::\n\nThus, we finally have a solution concept that always exists, albeit for a special subclass of games. \n\n## Properties of optimal strategy profiles\n\nThe value of a game has a nice geometric interpretation. \n\n:::{#def-saddle-point}\n\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be sets and $f \\colon \\ALPHABET X × \\ALPHABET  Y \\to \\reals$. A point $(x^*, y^*) \\in \\ALPHABET X × \\ALPHABET  Y$ is said to be a **saddle point** of $f$ if\n\\begin{align*}\n    f(x^*, y^*) &\\ge f(x, y^*), & \\forall x &\\in \\ALPHABET X \\\\\n    f(x^*, y^*) &\\le f(x^*, y), & \\forall y &\\in \\ALPHABET Y\n\\end{align*}\n:::\n\n:::{.column-margin}\n![A function with a saddle point, image taken from Wikimedia](https://upload.wikimedia.org/wikipedia/commons/1/1e/Saddle_point.svg)\n:::\nThe term saddle point comes from the fact that the typical two dimensional example of a function with a saddle point looks like a saddle of a horse (curves up in one direction and curves down in the other). \n\nA key property of an optimal strategy profile is the following.\n\n:::{#thm-saddle-point}\nIn a two player zero sum game, $(σ_1^*, σ_2^*)$ is a saddle point of the expected utility function $U$ if and only if $σ_1^*$ is an optimal strategy for player 1 and $σ_2^*$ is an optimal strategy for player 2. \n\nIn this case $U(σ_1^*, σ_2^*)$ is the value of the game. \n:::\n\n:::{.callout-note}\n#### Proof\nThis follows immediately from the definition of saddle point and that of the value of a game.\n:::\n\nIn general, a ZSG can have more than one optimal strategy profile. Suppose $(σ_1^*, σ_2^*)$ and $(τ_1^*, τ_2^*)$ where $σ_1^* \\neq τ_1^*$ and $σ_2^* \\neq τ_2^*$ both satisfy\n$$\n  \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)}\n  U(σ_1, σ_2) =\n  \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \\max_{σ_1 \\in Δ(\\ALPHABET S_1)}\n  U(σ_1, σ_2) = v.\n$$\nThen, \n\n- $U(σ_1^*, σ_2^*) = U(τ_1^*, τ_2^*)$\n\n    Hence, if a game has a value and multiple optimal strategy profiles, then each optimal strategy profiles gives the value of the game.\n\n- $U(σ_1^*, τ_2^*) = U(τ_1^*, σ_2^*) = v$\n\n    Hence, it does not matter which optimal strategy is chosen by players 1 and 2. Every combination of optimal strategies is an optimal strategy profile.\n\nThe proof of this statement is left as an exercise (see @exr-switched-zsg).\n\n## Computing the value of ZSG\n\nWe now consider how to compute the value of ZSG in mixed strategies. The key simplification is as follows. When computing the maxmin value\n$$\n  \\underline v = \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} U(σ_1, σ_2),\n$$\nconsider the inner minimization problem for a fixed $σ_1 \\in Δ(\\ALPHABET S_1)$. In this case, the set of best resposes of $P_2$ will always include pure strategies. This is because, we can write\n$$\n  U(σ_1, σ_2) = \\sum_{s_2 \\in \\ALPHABET S_2} σ_2(s_2) U(σ_1, s_2).\n$$\nThus, if the minimizer $σ_2$ gives positive weights to pure strategies $s_{2,i}, s_{2,j}, s_{2,k}$, etc., each of them must have the same $U(σ_1, s_2)$; otherwise, we can omit putting positive weight on the pure strategy which has strictly large payoff and reduce the expected utility, which is not possible because $σ_2$ is a minimizer. \n\nTherefore, when computing the maxmin value, we may consider\n$$\n\\underline v = \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \n\\textcolor{red}{ \\min_{s_2 \\in \\ALPHABET S_2} } U(σ_1, \\textcolor{red}{s_2}).\n$$\n\nBy a similar argument, for minmax value, we may consider\n$$\n\\bar v = \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \n\\textcolor{red}{ \\max_{s_1 \\in \\ALPHABET S_1} } U(\\textcolor{red}{s_1}, σ_2).\n$$\n\nTo illustrate how this simplification helps, we start with an example of a $2 × 2$ game. In this case, the mixed extension is similar to the game on the unit square, which we have considered earlier. \n\n:::{#exm-value-2x2}\nFind the value in mixed strategies of the game below:\n\n::: {#a2afbb7f .cell execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;3&#36;</td><td>&#36;0&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n\n:::{.callout-note}\n#### Solution\n\n#### Strategy for row player {-}\n\nWe first consider the row player. Suppose the row player is playing $σ_1 = (p, 1-p)$, i.e., it chooses action $\\mathsf{T}$ with probability $p$ and action $\\mathsf{B}$ with probability $1-p$. Then,\n\n\\begin{alignat*}{2}\n  U_1(σ_1, \\mathsf{L}) &= 3p + (1-p) &&= 2p + 1, \\\\\n  U_1(σ_1, \\mathsf{R}) &= 2(1-p) &&= -2p + 2.\n\\end{alignat*}\n\nThe two payoffs are shown in @fig-2x2-payoffs-p1.\n\n![The payoffs for @exm-value-2x2](figures/svg/ZSG1.svg){#fig-2x2-payoffs-p1}\n\nWe now consider\n$$\n  \\underline v = \\max_{p \\in [0, 1]} \\min \\bigl{ 2p + 1, -2p + 2 \\bigr\\}.\n$$\nNote that the inner minimization can be easily carried out graphically. The minimization of the two curves is what is called a **lower envelop** which is shown in red in @fig-2x2-lower.\n\n![The lower envelop of the two curves of @fig-2x2-payoffs-p1](figures/svg/ZSG2.svg){#fig-2x2-lower}\n\nSince each curve is linear, the lower envelop is convex and its maximum value is the peak point, which is also the point of intersection of the two curves and is given by\n$$\n  2p + 1 - -2p + 2 \\implies \n  \\bbox[5pt,border: 1px solid]{ p = \\tfrac{1}{4} }.\n$$\n\nThus, $σ_1^* = (\\frac 14, \\frac 34)$ and \n$$\n  \\underline v = U(σ_1^*, \\mathsf{L}) = U(σ_1^*, \\mathsf{R}) = \\tfrac 32.\n$$\n\n#### Strategy for column player {-}\n\nNow, let's repeat the calculations for the column player. Suppose the column player is playing $σ_2 = (q, 1-q)$, i.e., it chooses action $\\mathsf{L}$ with probability $q$ and action $\\mathsf{R}$ with probability $1-q$. Then,\n\\begin{alig*}\n  U_1(\\mathsf{T}, σ_2) &= 3q , \\\\\n  U_1(\\mathsf{B}, σ_2) &= q + 2 (1-q) = -q + 2.\n\\end{alig*}\n\nThe two payoffs are shown in @fig-2x2-payoffs-p2.\n\n![The payoffs for @exm-value-2x2](figures/svg/ZSG3.svg){#fig-2x2-payoffs-p2}\n\nWe now consider\n$$\n  \\bar v = \\min_{q \\in [0, 1]} \\max \\bigl\\{3q, -q + 2 \\bigr\\}.\n$$\nAs before, the inner maximization can be easily carried out graphically. The maximization of the two curves is called an **upper envelop** which is shown in red in @fig-2x2-upper.\n\n![The upper envelop of the two curves of @fig-2x2-payoffs-p2](figures/svg/ZSG4.svg){#fig-2x2-upper}\n\nSince each curve is linear, the upper envelop is concave and its minimum value is the lowest point, which is also the point of intersection of the two curves and is given by\n$$\n  3q = -q + 2 \\implies\n  \\bbox[5pt,border: 1px solid]{ q = \\tfrac{1}{2} }.\n$$\n\nThus, $σ_2^* = (\\frac 12, \\frac 12)$ and \n$$\n  \\bar v = U(\\mathsf{T}, σ_2^*) = U(\\mathsf{B}, σ_2^*) = \\tfrac 32.\n$$\n\nNote that, as expected, $\\bar v = \\underline v$. \n:::\n\nThe above idea works for general $2 × 2$ games. See @exr-zsg-mixed for some examples. We now show that the idea also be extended to general $2 × n$ games as well.\n\n:::{#exm-value-2x3}\nFind the value in mixed strategies of the game below:\n\n::: {#17c7715d .cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;2&#36;</td><td>&#36;5&#36;</td><td>&#36;-1&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;0&#36;</td><td>&#36;-2&#36;</td><td>&#36;5&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.callout-note}\n#### Solution\n\n#### Strategy for row player {-}\n\nThe row player has two pure strategies, so we use the same idea as before. Suppose the row player is playing $σ_1 = (p, 1-p)$, i.e., it chooses action $\\mathsf{T}$ with probability $p$ and action $\\mathsf{B}$ with probability $1-p$. Then,\n\n\\begin{alignat*}{2}\n  U_1(σ_1, \\mathsf{L}) &= 2p + (1-p) &&= 2p, \\\\\n  U_1(σ_1, \\mathsf{C}) &= 5p - 2(1-p) &&= 7p - 2, \\\\\n  U_1(σ_1, \\mathsf{R}) &= -p + 5(1-p) &&= -6p + 5.\n\\end{alignat*}\n\nAs before, we can plot these functions as shown in @fig-2x3-lower, where the lower concave envelop is shown in red. \n\n![The lower envelop of the three payoff curves](figures/svg/ZSG5.svg){#fig-2x3-lower}\n\nNote that the maximum of the lower convex envelop is the intersection of $U(σ_1, \\mathsf{L})$ and $U(σ_1, \\mathsf{R})$ which happens when\n$$\n  2p = -6p + 5 \\implies\n  \\bbox[5pt,border: 1px solid]{ p = \\tfrac{5}{8} }.\n$$\nThus, $σ_1^* = (\\tfrac 58, \\tfrac 38)$ and \n$$\n  v = \\underline v = U(σ_1^*, \\mathsf{L}) = U(σ_1^*, \\mathsf{R}) = \\tfrac 54.\n$$\n\nObserve that $U(σ_1^*, \\mathsf{C}) = \\tfrac{19}{8} > v$. Thus, if the row player plays $σ_1^*$, then the column player will either play $\\mathsf{L}$ or $\\mathsf{R}$, but not $\\mathsf{C}$. \n\n#### Strategy for column player {-}\n\nWe now consider the column player. We cannot follow the previous procedure because we will need to construct $U(⋅, σ_2)$, where $σ_2$ lies in a subset of $\\reals^2$. So, we take an alternative approach.\n\nSuppose $σ_1 = (p, 1-p)$ and $σ_2$ are mixed strategies. For the ease of notation, we will write $U(σ_1, σ_2)$ as $U(p, σ_2)$. By construction, $U(p, σ_2)$ is linear in $p$. Thus, if $σ_2^*$ is optimal strategy for the column player, then \n$$\n  U(p, σ_2^*) \\le v = \\tfrac 54, \\quad \\forall p \\in [0, 1].\n$$\nNow, consider the graph in @fig-2x3-lower. As we have previously seen, at $p^* = \\tfrac 58$, \n$$\nU(p^*, \\mathsf{L}) = U(p^*, \\mathsf{R}) = \\tfrac 54 = v\n\\quad\\text{but}\\quad\nU(p^*, \\mathsf{C}) > \\tfrac 54 = v.\n$$\nSo, $σ_2^*$ must give zero weight to $\\mathsf{C}$; otherwise $U(p^*, σ_2^*)$ cannot be equal to $\\tfrac 54$. Thus, we know that\n$$\n  σ_2^* = (q, 0, 1-q).\n$$\nHence, we effectively have a $2 × 2$ game. For find $q$, we can solve \n$$\n  U(\\mathsf{T}, σ_2^*) = U(\\mathsf{B}, σ_2^*) = v = \\tfrac 54.\n$$\nWe know that these equations will have a consistent solution, so we only need to solve one of these. Let's take\n$$\n  U(\\mathsf{T}, σ_2^*) = 2q - (1-q) = 3q - 1 = v = \\tfrac{5}{4}.\n$$\nThus,\n$$\n  \\bbox[5pt,border: 1px solid]{ q = \\tfrac{3}{4} }.\n$$\n\n#### Final solution {-}\nThus, the optimal strategy is \n$$\n  σ_1^* = (\\tfrac 58, \\tfrac 38)\n  \\quad\\text{and}\\quad\n  σ_2^* = (\\tfrac 34, 0, \\tfrac 14)\n$$\nand the value is $v = \\tfrac 54$. \n\n:::\n\nIn @exm-value-2x3, the column player had three strategies but the optimal strategy randomizes between only two of them. This is an instance of the following general result. \n\n:::{#thm-zsg-support}\nIn a two player zero-sum game where player 1 has $m_1$ pure strategies and player 2 has $m_2$ pure strategies, with $m_1 < m_2$, then player 2 has an optimal strategy that puts positive weight on at most $m_1$ pure strategies.\n:::\n\nNote that @thm-zsg-support means that there exists an optimal strategy with the above feature; not that all optimal strategies have this feature. \n\nAn implication of @thm-zsg-support is that in a two player ZSG where one player, say the row player, has $2$ pure strategies and the other player, the column player, has $m$ pure strategies with $m > 2$, there is an optimal strategy for the column player that puts positive weight on at most two pure strategies. We can find the solution of such $2 × m$ games using the procedure described above. In particular, we have the following:\n\n- **STEP 1:** Consider $σ_1 = (p, 1-p)$ and for each pure strategy $s_2$ of player 2, compute $U(σ_1, s_2)$. In general, we can have six possibilities as shown in @fig-zsg-2xm. \n\n  ![Different possibilities for $2 × m$ games](figures/svg/ZSG6.svg){#fig-zsg-2xm}\n  \n    Observe the following:\n\n    - In cases (a) and (f), the optimal strategy is attained on an internal point $p^*$\n\n    - In cases (b) and (c), the optimal strategy is a boundary point and corresponds to a pure strategy.\n\n    - In case (d) and (e), the maximum is attained in an interval; hence every point in this interval is an optimal strategy. \n\n- **STEP 2:** It can be shown that for player 2:\n\n    - case (a) implies that the optimal strategy is an internal point\n\n    - case (b)--(e) implies thta the optimal strategy is a pure strategy\n\n    - case (f) implies that there is an interval of randomization probabilities that are optimal.\n\n## Computing optimal strategy profile using linear programming\n\nThe graphical method described in the previous section does not work if both players have more than two actions. In general, the optimal solution can be obtained using linear programming. \n\nLet $(σ_1, σ_2)$ be a candidate optimal strategy profile. Then, it must satisfy\n\\begin{align}\n  U(σ_1, s_2) &\\ge v, & \\forall s_2 &\\in \\ALPHABET S_2 \n  \\label{eq:constraint-1}\n  \\\\\n  U(s_1, σ_2) &\\le v, & \\forall s_1 &\\in \\ALPHABET S_1.\n  \\label{eq:constraint-2}\n\\end{align}\n\nWe can write \\eqref{eq:constraint-1}--\\eqref{eq:constraint-2} as two linear programs. Suppose $\\ABS{\\ALPHABET S_1} = n$ and $\\ABS{\\ALPHABET S_2} = m$. For the ease of notation, we assume that $\\ALPHABET S_1 = \\{1, \\dots, n\\}$ and $\\ALPHABET S_2 = \\{1, \\dots, m\\}$ and use $u(i,j)$ to denote the utility of player 1 (the maximizer) when player 1 plays $i \\in \\ALPHABET S_1$ and player 2 plays $j \\in \\ALPHABET S_2$. \n\nLet \n$$\n  σ_1 = (p_1, \\dots, p_n)\n  \\quad\\text{and}\\quad\n  σ_2 = (q_1, \\dots, q_m)\n$$\nbe an optimal strategy profile of the game and $v$ be the value. Then, \\eqref{eq:constraint-1} and \\eqref{eq:constraint-2} are equalent to the following linear programs.\n\n\n$$\n\\bbox[5pt,border: 1px solid]{\n  \\begin{gathered}\n    \\max v \\\\\n    \\text{s.t. } \n    \\begin{aligned}[t] \n      & \\sum_{i=1}^n p_i u(i,j) \\ge v, \\quad \\forall j \\in \\ALPHABET S_2 \\\\\n      & p_i \\ge 0, \\quad \\forall i \\in \\{1, \\dots, n\\} \\\\\n      & \\sum_{i=1}^n p_i = 1\n   \\end{aligned}\n  \\end{gathered}}\n  \\qquad \n\\bbox[5pt,border: 1px solid]{\n  \\begin{gathered}\n    \\min v \\\\\n    \\text{s.t. } \n    \\begin{aligned}[t] \n      & \\sum_{j=1}^m q_j u(i,j) \\le v, \\quad \\forall i \\in \\ALPHABET S_1 \\\\\n      & q_j \\ge 0, \\quad \\forall j \\in \\{1, \\dots, m\\} \\\\\n      & \\sum_{j=1}^m q_j = 1\n   \\end{aligned}\n  \\end{gathered}}\n$$ \n\nA naive implementation of the above LP is given below:\n\n::: {#19bbcdaa .cell execution_count=5}\n``` {.julia .cell-code}\nusing JuMP, GLPK\n\nfunction solve_ZSG_naive(u)\n    n, m = size(u)\n\n    ## Primal LP to find strategies of row player\n    primal = Model(GLPK.Optimizer)\n\n    @variable(primal, v_lower)\n    @variable(primal, p[1:n] >= 0)\n\n    @objective(primal, Max, v_lower)\n\n    @constraint(primal, sum(p[i] for i ∈ 1:n) == 1)\n    for j ∈ 1:m\n        @constraint(primal, sum(p[i]*u[i,j] for i ∈ 1:n) >= v_lower)\n    end\n\n    ## Dual LP to find strategies for column player\n    dual = Model(GLPK.Optimizer)\n\n    @variable(dual, v_upper)\n    @variable(dual, q[1:m] >= 0)\n\n    @objective(dual, Min, v_upper)\n    \n    @constraint(dual, sum(q[j] for j ∈ 1:m) == 1)\n    for i ∈ 1:n\n        @constraint(dual, sum(q[j]*u[i,j] for j ∈ 1:m) <= v_upper)\n    end\n    \n    JuMP.optimize!(primal)\n    JuMP.optimize!(dual)\n\n    row_strategy = JuMP.value.(p)\n    col_strategy = JuMP.value.(q)\n    game_value   = JuMP.value(v_lower) # Same as v_upper\n\n    return row_strategy, col_strategy, game_value\nend\n```\n:::\n\n\nHowever, from LP duality, we know that the primal and the dual linear programs have the same solution. So, a more efficient implementation is the following, where we compute the strategies of the column player from the dual variables of the primal LP.\n\n::: {#f1641c8e .cell execution_count=6}\n``` {.julia .cell-code}\nfunction solve_ZSG(u)\n    n, m = size(u)\n\n    lp = Model(GLPK.Optimizer)\n\n    @variable(lp, v)\n    @variable(lp, p[1:n] >= 0)\n\n    @objective(lp, Max, v)\n\n    q = Vector{JuMP.ConstraintRef}(undef, m)\n\n    @constraint(lp, sum(p[i] for i ∈ 1:n) == 1)\n    for j ∈ 1:m\n        q[j] = @constraint(lp, sum(p[i]*u[i,j] for i ∈ 1:n) >= v)\n    end\n    JuMP.optimize!(lp)\n\n    row_strategy = JuMP.value.(p)\n    col_strategy = JuMP.dual.(q)\n    game_value   = JuMP.value(v) \n\n    return row_strategy, col_strategy, game_value\nend\n```\n:::\n\n\n:::{#exr-2x3-LP}\n\nSolve @exm-value-2x3 using linear programming\n:::\n\n:::{.callout-note}\n#### Solution\nWe first use the naive solution presented above:\n\n::: {#95edfa05 .cell execution_count=7}\n``` {.julia .cell-code}\nu = [2 5 -1; 0 -2 5]\np, q, v = solve_ZSG_naive(u)\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\n([0.6249999999999998, 0.375], [0.75, 0.0, 0.25], 1.2500000000000002)\n```\n:::\n:::\n\n\nNext, we use the efficient solution that uses the dual variables\n\n::: {#000963e8 .cell execution_count=8}\n``` {.julia .cell-code}\nu = [2 5 -1; 0 -2 5]\np, q, v = solve_ZSG(u)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n([0.6249999999999998, 0.375], [0.75, -0.0, 0.25], 1.2500000000000002)\n```\n:::\n:::\n\n\nNote that both solutions give the same answer (up to numerical precision) that we obtained \"by hand\".\n:::\n\nSee @exr-LP for larger examples.\n\n\n## Exercises {-}\n\n:::{#exr-zsg-mixed}\nFor each of the following games, find the value of the game and the optimal strategy profile.\n\n::::{layout-ncol=2}\n:::{.game-1}\n\n::: {#545cfcda .cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=48}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 1</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;6&#36;</td><td>&#36;0&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;3&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.game-2}\n\n::: {#9ad05055 .cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 2</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;8&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;4&#36;</td><td>&#36;4&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n::::\n:::\n\n:::{#exr-zsg-ieds}\nFind the optimal strategy profile and the value of the following game.\n\n::: {#98d767cd .cell execution_count=11}\n\n::: {.cell-output .cell-output-display execution_count=50}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;0&#36;</td><td>&#36;4&#36;</td><td>&#36;6&#36;</td></tr><tr><td>&#36;\\mathsf&#123;M&#125;&#36;</td><td>&#36;5&#36;</td><td>&#36;7&#36;</td><td>&#36;4&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;9&#36;</td><td>&#36;6&#36;</td><td>&#36;3&#36;</td></tr></table>\n```\n:::\n:::\n\n\n_Hint_: Use iterative elimination of strongly dominated strategies to first reduce the above to a $2 × 2$ game and then simplify the resulting game. \n\n:::\n\n:::{#exr-switched-zsg}\nSuppose $(σ_1^*, σ_2^*)$ and $(τ_1^*, τ_2^*)$ both satisfy\n$$\n  \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)}\n  U(σ_1, σ_2) =\n  \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \\max_{σ_1 \\in Δ(\\ALPHABET S_1)}\n  U(σ_1, σ_2) = v.\n$$\nProve that\n$$\n  U(σ_1^*, τ_2^*) = U(τ_1^*, σ_2^*) = v.\n$$\n\n_Hint_: Use @thm-saddle-point to argue that\n$$\n  U(τ_1^*, τ_2^*) \\le U(τ_1^*, σ_2^*) \\le U(σ_1^*, σ_2^*)\n  \\quad\\text{and}\\quad\n  U(σ_1^*, σ_2^*) \\le U(σ_1^*, τ_2^*) \\le U(τ_1^*, τ_2^*).\n$$\n\n:::\n\n:::{#exr-symmetric-games}\nA zero-sum game with $\\ALPHABET S_1 = \\ALPHABET S_2$ is called **symmetric** if the utlity function is skew-symmetric, i.e.,\n$$\n  u(s_1, s_2) = - u(s_2, s_1), \\quad \\forall s_1, s_2 \\in \\ALPHABET S_1.\n$$\nAn example of a symmetric game is rock-paper-scissors. \n\nLet $\\mathscr{G}$ be a symmetric game. Show that:\n\na. The value of $\\mathscr{G}$ in mixed strategies is zero.\n\nb. If $(σ_1^*, σ_2^*)$ is an optimal (mixed) strategy for $\\mathscr{G}$, then $(σ_2^*, σ_1^*)$ is also an optimal (mixed) strategy. \n\nc. Use part b and @exr-switched-zsg to argue that a symmetric zero-sum game always has a _symmetric_ optimal (mixed) strategy of the form $(σ^*, σ^*)$, where both players are playing the same mixed strategy.\n\n:::\n\n:::{#exr-LP}\nUse the LP formulation to find optimal strategy profile of the following games.\n\n::::{layout-ncol=2}\n:::{.game-1}\n\n::: {#75c92162 .cell execution_count=12}\n\n::: {.cell-output .cell-output-display execution_count=51}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 1</caption><tr><td></td><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;\\mathsf&#123;3&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;3&#36;</td><td>&#36;-1&#36;</td><td>&#36;2&#36;</td></tr><tr><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td><td>&#36;-2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.game-2}\n\n::: {#f3afb27f .cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=52}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 2</caption><tr><td></td><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;\\mathsf&#123;3&#125;&#36;</td><td>&#36;\\mathsf&#123;4&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;6&#36;</td><td>&#36;0&#36;</td><td>&#36;5&#36;</td><td>&#36;6&#36;</td></tr><tr><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;3&#36;</td><td>&#36;-4&#36;</td><td>&#36;3&#36;</td></tr><tr><td>&#36;\\mathsf&#123;3&#125;&#36;</td><td>&#36;8&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n::::\n\nNote that part of the objective of this exercise is for you to learn how to use a linear programming solver. So, instead of blindly copy pasting the code provided above, implement the solution from the equations using the programming language of your choice.\n:::\n\n",
    "supporting": [
      "zero-sum-games_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}