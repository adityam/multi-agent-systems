{
  "hash": "e2ca23556e59010fa1fed4cae2aa3107",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Zero-sum games\nformat:\n  html:\n    include-in-header: \n     - ../static/html/vue.html\n\nexecute:\n  echo: false\n  freeze: true\n  cache: true\n---\n\nRecall the game of matching pennies.\n\n\n\n<table class=\"game\" align=\"center\">\n<caption>Matching pennies game</caption>\n  <tr>\n    <td></td>\n    <td colspan=\"2\">$\\mathsf{H}$</td>\n    <td colspan=\"2\">$\\mathsf{T}$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{H}$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{T}$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n  </tr>\n</table>\n\nThis game has the property that for any strategy profile $(s_1, s_2) \\in \\ALPHABET S$,\n$$\nu_1(s_1, s_2) + u_2(s_1, s_2) = 0.\n$$\nGames with such property are called **zero-sum games**. In this course, we will focus on two player zero sum games (ZSG). \n\nSome remarks\n\n: - Many classical games such sa chess, checkers, Go, etc. are two player ZSGs.\n\n- ZSGs are a highly restrictive and are, therefore, much easier to analyze as compared to general-sum games.\n\n- ZSGs emerge in many engineering applications when we consider worst case performance. Such scenarios can be considered as games against nature. \n\n- When we consider the maxmin value (or the security level) of player in general-sum game, we are effectively doing worst case analysis. This means that each player is considering an auxiliary ZSG in which all other players collude and act as a single opponnet who try to minimize the payff of the player. Thus, ZSGs can be useful even when analyzing non-zero-sum games. \n\n## Simplified notation\n\nFor two player ZSGs, we can simplify the notation. Since $u_2(s_1, s_2) = -u_1(s_1, s_2)$, we can just specify the payoff of player 1 instead of specifying the payoff of both players. For instance, the matching pennies game can be represented as\n\n<table class=\"game1\" align=\"center\">\n<caption>Simplified notation for ZSGs</caption>\n  <tr>\n    <td></td>\n    <td>$\\mathsf{H}$</td>\n    <td>$\\mathsf{T}$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{H}$</td>\n    <td>$1$</td>\n    <td>$-1$</td>\n  </tr>\n  <tr>\n    <td>$\\mathsf{T}$</td>\n    <td>$-1$</td>\n    <td>$1$</td>\n  </tr>\n</table>\n\nHere we can think of $P_1$ as the **maximizing player** and $P_2$ as the **minimizing player**. Thus, instead of a bimatrix representation, we will specify the payoffs by a matrix and assume that the row player is the maximizer and the column player is the minimizer. \n\nMoreover, we will use $u(s_1, s_2)$ to denote $u_1(s_1, s_2)$ and $-u_2(s_1, s_2)$. \n\nNow recall that the maxmin levels of the two players:\n\\begin{align*}\n  \\underline v_1\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u_1(s_1, s_2)\n  = \\textcolor{red}{\n    \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)}\n  \\\\\n  \\underline v_2\n  &= \\max_{s_2 \\in \\ALPHABET S_2} \\min_{s_1 \\in \\ALPHABET S_1} \n     u_2(s_1, s_2)\n  = \\textcolor{red}{\n    - \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1} \n     u(s_1, s_2)}\n\\end{align*}\n\nFor ZSGs we use a simpler notation and define\n\\begin{align*}\n  \\text{Maxmin value:} && \\underline v\n  &= \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)\n  \\\\\n  \\text{Minmax value:} && \\bar v\n  &= \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n\\end{align*}\n\n:::{#exm-matching-pennies}\nFind the maxmin and minmax value of matching pennies.\n:::\n\n:::{#thm-maxmin-zsg}\nIn a two player ZSG, $$\\underline v \\le \\bar v.$$\n:::\n\n:::{.callout-note collapse=\"true\"}\n#### Proof\n\nLet $s_1^*$ be a maxmin strategy for $P_1$ and $s_2^*$ be a minmax strategy for $P_2$. Then, by definition of maxmin strategy, we have\n$$\n\\underline v \n  = \\max_{s_1 \\in \\ALPHABET S_1} \\min_{s_2 \\in \\ALPHABET S_2} \n     u(s_1, s_2)\n  = \\min_{s_2 \\in \\ALPHABET S_2} u(\\textcolor{red}{s^*_1}, s_2).\n$$\nThus, for any $s_2 \\in \\ALPHABET S_2$, we have\n$$ \\underline v \\le u(s_1^*, s_2). $$\nHence, by taking $s_2 = s_2^*$, we get\n\\begin{equation}\\label{eq:maxmin-bound}\n\\underline v \\le u(s_1^*, s_2^*).\n\\end{equation}\n\nSimilarly, by the definition of minmax strategy, we have\n$$\n\\bar v\n  = \\min_{s_2 \\in \\ALPHABET S_2} \\max_{s_1 \\in \\ALPHABET S_1}\n     u(s_1, s_2)\n  = \\max_{s_1 \\in \\ALPHABET S_1} u(s_1, \\textcolor{red}{s^*_2})\n$$\nThus, for any $s_1 \\in \\ALPHABET S_1$, we have\n$$ \\bar v \\ge u(s_1, s_2^*). $$\nHence, by taking $s_1 = s_1^*$, we get\n\\begin{equation}\\label{eq:minmax-bound}\n\\bar v \\ge u(s_1^*, s_2^*).\n\\end{equation}\n\nCombining \\eqref{eq:maxmin-bound} and \\eqref{eq:minmax-bound}, we get\n$$\n\\underline v \\le u(s_1^*, s_2^*) \\le \\bar v.\n$$\n:::\n\nAs shown in @exm-matching-pennies, in general the inequality is strict. However, for some games, the maxmin value is equal to the minmax value as seen from the following example.\n\n:::{#exm-value-zsg}\nFind the maxmin and minmax value of the following game.\n\n::: {#ed1b537b .cell execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>A game where &#36;\\underline v &#61; \\bar v&#36;.</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;2&#36;</td><td>&#36;-1&#36;</td><td>&#36;-2&#36;</td></tr><tr><td>&#36;\\mathsf&#123;M&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;0&#36;</td><td>&#36;1&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;-2&#36;</td><td>&#36;-1&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n\n:::{#def-value-zsg}\nIn a two player ZSG if $\\underline v = \\bar v$, then the quantity\n$$\nv \\coloneqq \\underline v = \\bar v\n$$ \nis called the **value** of the game. Any $(\\text{maxmin}, \\text{minmax})$ strategy of the players is called the **optimal strategy profile.**\n:::\n\nAs we have seen earlier, a two player ZSG may not have a value _in pure strategies_. In the sequel, we will show that if we allow mixed strategies, then every finite two player ZSG has a value!\n\n\n## Zero sum games on the unit square\n\nAs an intermediate step to mixed strategies, we consider two player ZSGs on the unit square, i.e., games on which $\\ALPHABET S_1 = \\ALPHABET S_2 = [0,1]$. \n\nFor the ease of notation, we will use $\\ALPHABET X = [0, 1]$ and $\\ALPHABET Y = [0, 1]$ to denote the strategy spaces of the player. \n\n:::{#exm-unit-square}\nConsider a two player ZSG on the unit square with \n$$\nu(x,y) = 4xy - 2x - y + 3, \\quad \\forall x \\in \\ALPHABET X, y \\in \\ALPHABET Y.\n$$\nDoes this game have a value? If so, find all optimal strategy profiles \n:::\n\n:::{.callout-note}\n#### Solution\nTo check if the game has a value, we will compute the maxmin value\n$$\n\\underline v = \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} u(x,y)\n$$\nand the minmax value\n$$\n\\bar v = \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} u(x,y)\n$$\nand check if they are equal.\n\nConsider,\n\\begin{align*}\n  \\min_{y \\in \\ALPHABET Y} u(x,y) \n  &= \\min_{y \\in [0,1]} \\bigl[ 4xy - 2x - y - 4 \\bigr] \\\\\n  &= \\min_{y \\in [0,1]} \\bigl[ (4x -1) y - 2x + 3 \\bigr].\n\\end{align*}\nFor a fixed $x$, this is a linear function in $y$ and the minimizer depends on the slope. \n\n- If the slope is positive, then the function is inreasing in $y$ and the miniizer is $0$.\n- If the slope is negative, then the function is decreasing in $y$ and the minimizer is $1$. \n\n::::{layout-ncol=2}\n:::{.fig-1}\n![Minimizing a linear function with positive slope](figures/svg/games-on-unit-square1.svg)\n:::\n\n:::{.fig-2}\n![Minimizing a linear function with negative slope](figures/svg/games-on-unit-square2.svg)\n:::\n::::\n\nTherefore, we have the following:\n$$\n  \\min_{y \\in [0,1]} u(x,y) = \n  \\begin{cases}\n    2x + 2, & \\text{if } x < \\tfrac 14 \\\\\n    2.5, & \\text{if } x = \\tfrac 14 \\\\\n   -2x + 3, & \\text{if } x > \\tfrac 14 \n  \\end{cases}\n$$\n\nThe plot of $\\min_{y \\in [0,1]} u(x,y)$ is shown below in @fig-maxmin-p1.\n\n![Plot of $\\min_{y \\in [0,1]} u(x,y)$](figures/svg/games-on-unit-square3.svg){#fig-maxmin-p1}\n\nAs we can see from the plot, \n$$\n\\bbox[5pt,border: 1px solid]{\n  \\underline v =\n  \\max_{x \\in [0,1]} \\min_{y \\in [0,1]} u(x,y) = 2.5.\n}\n$$\n\nNow consider \n\\begin{align*}\n  \\max_{x \\in \\ALPHABET X} u(x,y) \n  &= \\max_{x \\in [0,1]} \\bigl[ 4xy - 2x - y + 3 \\bigr] \\\\\n  &= \\max_{x \\in [0,1]} \\bigl[ (4y - 2) x - y + 3 \\bigr]\n\\end{align*}\n\nBy the same argument as before, we have\n$$\n  \\max_{x \\in [0,1]} u(x,y) = \n  \\begin{cases} \n    -y + 3, & \\text{if } y < \\tfrac 12 \\\\\n    2.5, & \\text{if } y = \\tfrac 12 \\\\\n    3y + 1, & \\text{if } y > \\tfrac 12\n  \\end{cases}\n$$\n\nThe plot of $\\max_{x \\in [0,1]} u(x,y)$ is shown below @fig-maxmin-p2.\n\n![Plot of $\\max_{x \\in [0,1]} u(x,y)$](figures/svg/games-on-unit-square4.svg){#fig-maxmin-p2}\n\nAs we can see from the plot, \n$$\n\\bbox[5pt,border: 1px solid]{\n  \\bar v =\n  \\min_{y \\in [0,1]} \\max_{x \\in [0,1]} u(x,y) = 2.5.\n}\n$$\n\nSince $\\underline v = \\bar v = 2.5$, the game has a value of $2.5$. The unique optimal strategy profile is $(\\tfrac 14, \\tfrac 12)$. \n\n:::\n\nThe previous example is an illustration of what is known as the [:Minimax Theorem](https://en.wikipedia.org/wiki/Minimax_theorem). One of the foundational results of Game Theory is the von Neumann minimax theorem [@vonNeumann1928].\n\nRecall that a function $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ is called **bilinear** if it is linear in each argument separately, i.e.,\n\n- $f(x_1 + x_2, y) = f(x_1,y) + f(x_2, y)$ and $f(α x, y) = α f(x,y)$;\n- $f(x, y_1 + y_2) = f(x, y_1) + f(x, y_2)$ and $f(x, αy) = α f(x,y)$. \n\nNote that the utility function in @exm-unit-square is bilinear. \n\n:::{#thm-von-Neumann}\n#### von Neumann's Minimax Theorem\n\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be compact (i.e., closed and bounded) subsets of Eucledian spaces and $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ be a bilinear function. Then,\n$$\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n$$\n:::\n\nSome remarks:\n\n- For a facinating historial discussion of this result, see @Kjeldsen2001. \n\n- For a self contained proof of the result using elementary ideas from convex analysis, see @vonNeumann1944, Chapter 3 and @Hespanha2017, Chapter 5.\n\n- For a short proof based on [:Brouwer's fixed point theorem](https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem), see @Raghavan1994.\n\n- The minmax theorem is equivalent to the duality theorem of linear programming. See @Dantzig1951 and @vonStengel2024. \n\nIn @exm-unit-square, since the utility function is bilinear, we could have simply used @thm-von-Neumann to conclude that the game has a value, without doing any calculations. \n\nA useful generalization of von Neumann's minimax theorem is the following.\n\n:::{#thm-minmax}\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be compact subsets of Eucledian space. If $f \\colon \\ALPHABET X × \\ALPHABET Y \\to \\reals$ is concave-convex, i.e., \n\n- for any fixed $y$, $f(⋅, y) \\colon \\ALPHABET X \\to \\reals$ is concave;\n- for any fixed $x$, $f(x, ⋅) \\colon \\ALPHABET Y \\to \\reals$ is convex.\n\nThen,\n$$\n  \\max_{x \\in \\ALPHABET X} \\min_{y \\in \\ALPHABET Y} f(x,y) =\n  \\min_{y \\in \\ALPHABET Y} \\max_{x \\in \\ALPHABET X} f(x,y).\n$$\n:::\n\nFor a generalization that removes the compactness assumption, see @Sion1958. For a general discussion of various fixed point theorems and their relevance to zero sum games, see @Raghavan1994.\n\n## Mixed strategies in finite games\n\nWe now revist the notion of mixed strategies in finite games. Recall that given a finite game $\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle$ and mixed strategies $σ = (σ_i)_{i \\in N}$ for the players, the expected utility is defined as\n\\begin{equation} \\label{eq:expected-utility}\n  U_i(σ) = \\sum_{s_1 \\in \\ALPHABET S_1} \\cdots \\sum_{s_N \\in \\ALPHABET S_N} \n  σ_1(s_1) \\cdots σ_N(s_N) u_i(s_1, \\dots, s_N)\n\\end{equation}\nor more compactly for two player games\n$$\n  U_i(σ_1, σ_2) = \\sum_{s_1 \\in \\ALPHABET S_1} \\sum_{s_2 \\in \\ALPHABET S_2}\n  σ_1(s_1) σ_2(s_2) u_i(s_1, s_2).\n$$\n\nA game in which players are playing mixed strategies may be viewed as another game, called the **mixed extension**, in which all players have continuous action spaces and are playing pure strategies.\n\n:::{#def-mixed-extension}\n#### Mixed extension\n\nGiven a game $\\mathscr{G} = \\langle N, (\\ALPHABET S_i)_{i \\in N}, (u_i)_{i \\in N} \\rangle$, its **mixed extension** is a game $\\mathscr{G}^* = \\langle N, ( Δ(\\ALPHABET S_i) )_{i \\in N}, (U_i)_{i \\in N} \\rangle$ where\n\n- $Δ(\\ALPHABET S_i)$ denotes the set of probability distributions over $\\ALPHABET S_i$\n- $U_i \\colon \\prod_{j \\in N} Δ(\\ALPHABET S_j) \\to \\reals$ is the expected utility function defined in \\eqref{eq:expected-utility}.\n:::\n\nFor a discussion of different interpretations of mixed strategies, see @Osborne1994 [Sec 3.2]. \n\nObserve that if the original game $\\mathscr{G}$ is a two player ZSG, then its mixed extension $\\mathscr{G}^*$ is also a two player ZSG because for any mixed strategy $(σ_1, σ_2)$\n\\begin{align*}\nU_1(σ_1, σ_2) + U_2(σ_1, σ_2) \n&= \\sum_{s_1 \\in \\ALPHABET S_1} \\sum_{s_2 \\in \\ALPHABET S_2}\nσ_1(s_1) σ_2(s_2) \\underbrace{\\bigl[ u_1(s_1,s_2) + u_2(s_1, s_2) \\bigr]}_{=0} \\\\\n&= 0.\n\\end{align*}\nThus, we may simply use $U$ to denote the expected utility of $P_1$ with the understanding that the expected utility of $P_2$ is $-U$. \n\nFurthermore, observe that $U$ is bilinear. Thus, we can conclude the following from @thm-von-Neumann.\n\n:::{#thm-ZSG-value}\nFor any finite game $\\mathscr{G}$, its mixed extesion $\\mathscr{G}^*$ has a value, which is called **value of $\\mathscr{G}$ in mixed strategies.**\n::::\n\nThus, we finally have a solution concept that always exists, albeit for a special subclass of games. \n\n## Properties of optimal strategy profiles\n\nThe value of a game has a nice geometric interpretation. \n\n:::{#def-saddle-point}\n\nLet $\\ALPHABET X$ and $\\ALPHABET Y$ be sets and $f \\colon \\ALPHABET X × \\ALPHABET  Y \\to \\reals$. A point $(x^*, y^*) \\in \\ALPHABET X × \\ALPHABET  Y$ is said to be a **saddle point** of $f$ if\n\\begin{align*}\n    f(x^*, y^*) &\\ge f(x, y^*), & \\forall x &\\in \\ALPHABET X \\\\\n    f(x^*, y^*) &\\le f(x^*, y), & \\forall y &\\in \\ALPHABET Y\n\\end{align*}\n:::\n\n:::{.column-margin}\n![A function with a saddle point, image taken from Wikimedia](https://upload.wikimedia.org/wikipedia/commons/1/1e/Saddle_point.svg)\n:::\nThe term saddle point comes from the fact that the typical two dimensional example of a function with a saddle point looks like a saddle of a horse (curves up in one direction and curves down in the other). \n\nA key property of an optimal strategy profile is the following.\n\n:::{#thm-saddle-point}\nIn a two player zero sum game, $(σ_1^*, σ_2^*)$ is a saddle point of the expected utility function $U$ if and only if $σ_1^*$ is an optimal strategy for player 1 and $σ_2^*$ is an optimal strategy for player 2. \n\nIn this case $U(σ_1^*, σ_2^*)$ is the value of the game. \n:::\n\n:::{.callout-note}\n#### Proof\nThis follows immediately from the definition of saddle point and that of the value of a game.\n:::\n\nIn general, a ZSG can have more than one optimal strategy profile. Suppose $(σ_1^*, σ_2^*)$ and $(τ_1^*, τ_2^*)$ where $σ_1^* \\neq τ_1^*$ and $σ_2^* \\neq τ_2^*$ both satisfy\n$$\n  \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)}\n  U(σ_1, σ_2) =\n  \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \\max_{σ_1 \\in Δ(\\ALPHABET S_1)}\n  U(σ_1, σ_2) = v.\n$$\nThen, \n\n- $U(σ_1^*, σ_2^*) = U(τ_1^*, τ_2^*)$\n\n    Hence, if a game has a value and multiple optimal strategy profiles, then each optimal strategy profiles gives the value of the game.\n\n- $U(σ_1^*, τ_2^*) = U(τ_1^*, σ_2^*) = v$\n\n    Hence, it does not matter which optimal strategy is chosen by players 1 and 2. Every combination of optimal strategies is an optimal strategy profile.\n\nThe proof of this statement is left as an exercise (see @exr-switched-zsg).\n\n## Computing the value of ZSG\n\nWe now consider how to compute the value of ZSG in mixed strategies. The key simplification is as follows. When computing the maxmin value\n$$\n  \\underline v = \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} U(σ_1, σ_2),\n$$\nconsider the inner minimization problem for a fixed $σ_1 \\in Δ(\\ALPHABET S_1)$. In this case, the set of best resposes of $P_2$ will always include pure strategies. This is because, we can write\n$$\n  U(σ_1, σ_2) = \\sum_{s_2 \\in \\ALPHABET S_2} σ_2(s_2) U(σ_1, s_2).\n$$\nThus, if the minimizer $σ_2$ gives positive weights to pure strategies $s_{2,i}, s_{2,j}, s_{2,k}$, etc., each of them must have the same $U(σ_1, s_2)$; otherwise, we can omit putting positive weight on the pure strategy which has strictly large payoff and reduce the expected utility, which is not possible because $σ_2$ is a minimizer. \n\nTherefore, when computing the maxmin value, we may consider\n$$\n\\underline v = \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \n\\textcolor{red}{ \\min_{s_2 \\in \\ALPHABET S_2} } U(σ_1, \\textcolor{red}{s_2}).\n$$\n\nBy a similar argument, for minmax value, we may consider\n$$\n\\bar v = \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \n\\textcolor{red}{ \\max_{s_1 \\in \\ALPHABET S_1} } U(\\textcolor{red}{s_1}, σ_2).\n$$\n\nTo illustrate how this simplification helps, we start with an example of a $2 × 2$ game. In this case, the mixed extension is similar to the game on the unit square, which we have considered earlier. \n\n:::{#exm-value-2x2}\nFind the value in mixed strategies of the game below:\n\n::: {#3089520f .cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;3&#36;</td><td>&#36;0&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n\n:::{.callout-note}\n#### Solution\n\n#### Strategy for row player {-}\n\nWe first consider the row player. Suppose the row player is playing $σ_1 = (p, 1-p)$, i.e., it chooses action $\\mathsf{T}$ with probability $p$ and action $\\mathsf{B}$ with probability $1-p$. Then,\n\n\\begin{alignat*}{2}\n  U_1(σ_1, \\mathsf{L}) &= 3p + (1-p) &&= 2p + 1, \\\\\n  U_1(σ_1, \\mathsf{R}) &= 2(1-p) &&= -2p + 2.\n\\end{alignat*}\n\nThe two payoffs are shown in @fig-2x2-payoffs-p1.\n\n![The payoffs for @exm-value-2x2](figures/svg/ZSG1.svg){#fig-2x2-payoffs-p1}\n\nWe now consider\n$$\n  \\underline v = \\max_{p \\in [0, 1]} \\min \\bigl{ 2p + 1, -2p + 2 \\bigr\\}.\n$$\nNote that the inner minimization can be easily carried out graphically. The minimization of the two curves is what is called a **lower envelop** which is shown in red in @fig-2x2-lower.\n\n![The lower envelop of the two curves of @fig-2x2-payoffs-p1](figures/svg/ZSG2.svg){#fig-2x2-lower}\n\nSince each curve is linear, the lower envelop is convex and its maximum value is the peak point, which is also the point of intersection of the two curves and is given by\n$$\n  2p + 1 - -2p + 2 \\implies \n  \\bbox[5pt,border: 1px solid]{ p = \\tfrac{1}{4} }.\n$$\n\nThus, $σ_1^* = (\\frac 14, \\frac 34)$ and \n$$\n  \\underline v = U(σ_1^*, \\mathsf{L}) = U(σ_1^*, \\mathsf{R}) = \\tfrac 32.\n$$\n\n#### Strategy for column player {-}\n\nNow, let's repeat the calculations for the column player. Suppose the column player is playing $σ_2 = (q, 1-q)$, i.e., it chooses action $\\mathsf{L}$ with probability $q$ and action $\\mathsf{R}$ with probability $1-q$. Then,\n\\begin{alig*}\n  U_1(\\mathsf{T}, σ_2) &= 3q , \\\\\n  U_1(\\mathsf{B}, σ_2) &= q + 2 (1-q) = -q + 2.\n\\end{alig*}\n\nThe two payoffs are shown in @fig-2x2-payoffs-p2.\n\n![The payoffs for @exm-value-2x2](figures/svg/ZSG3.svg){#fig-2x2-payoffs-p2}\n\nWe now consider\n$$\n  \\bar v = \\min_{q \\in [0, 1]} \\max \\bigl\\{3q, -q + 2 \\bigr\\}.\n$$\nAs before, the inner maximization can be easily carried out graphically. The maximization of the two curves is called an **upper envelop** which is shown in red in @fig-2x2-upper.\n\n![The upper envelop of the two curves of @fig-2x2-payoffs-p2](figures/svg/ZSG4.svg){#fig-2x2-upper}\n\nSince each curve is linear, the upper envelop is concave and its minimum value is the lowest point, which is also the point of intersection of the two curves and is given by\n$$\n  3q = -q + 2 \\implies\n  \\bbox[5pt,border: 1px solid]{ q = \\tfrac{1}{2} }.\n$$\n\nThus, $σ_2^* = (\\frac 12, \\frac 12)$ and \n$$\n  \\bar v = U(\\mathsf{T}, σ_2^*) = U(\\mathsf{B}, σ_2^*) = \\tfrac 32.\n$$\n\nNote that, as expected, $\\bar v = \\underline v$. \n:::\n\nThe above idea works for general $2 × 2$ games. See @exr-zsg-mixed for some examples. We now show that the idea also be extended to general $2 × n$ games as well.\n\n:::{#exm-value-2x3}\nFind the value in mixed strategies of the game below:\n\n::: {#39d7e122 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;2&#36;</td><td>&#36;5&#36;</td><td>&#36;-1&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;0&#36;</td><td>&#36;-2&#36;</td><td>&#36;5&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.callout-note}\n#### Solution\n\n#### Strategy for row player {-}\n\nThe row player has two pure strategies, so we use the same idea as before. Suppose the row player is playing $σ_1 = (p, 1-p)$, i.e., it chooses action $\\mathsf{T}$ with probability $p$ and action $\\mathsf{B}$ with probability $1-p$. Then,\n\n\\begin{alignat*}{2}\n  U_1(σ_1, \\mathsf{L}) &= 2p + (1-p) &&= 2p, \\\\\n  U_1(σ_1, \\mathsf{C}) &= 5p - 2(1-p) &&= 7p - 2, \\\\\n  U_1(σ_1, \\mathsf{R}) &= -p + 5(1-p) &&= -6p + 5.\n\\end{alignat*}\n\nAs before, we can plot these functions as shown in @fig-2x3-lower, where the lower concave envelop is shown in red. \n\n![The lower envelop of the three payoff curves](figures/svg/ZSG5.svg){#fig-2x3-lower}\n\nNote that the maximum of the lower convex envelop is the intersection of $U(σ_1, \\mathsf{L})$ and $U(σ_1, \\mathsf{R})$ which happens when\n$$\n  2p = -6p + 5 \\implies\n  \\bbox[5pt,border: 1px solid]{ p = \\tfrac{5}{8} }.\n$$\nThus, $σ_1^* = (\\tfrac 58, \\tfrac 38)$ and \n$$\n  v = \\underline v = U(σ_1^*, \\mathsf{L}) = U(σ_1^*, \\mathsf{R}) = \\tfrac 54.\n$$\n\nObserve that $U(σ_1^*, \\mathsf{C}) = \\tfrac{19}{8} > v$. Thus, if the row player plays $σ_1^*$, then the column player will either play $\\mathsf{L}$ or $\\mathsf{R}$, but not $\\mathsf{C}$. \n\n#### Strategy for column player {-}\n\nWe now consider the column player. We cannot follow the previous procedure because we will need to construct $U(⋅, σ_2)$, where $σ_2$ lies in a subset of $\\reals^2$. So, we take an alternative approach.\n\nSuppose $σ_1 = (p, 1-p)$ and $σ_2$ are mixed strategies. For the ease of notation, we will write $U(σ_1, σ_2)$ as $U(p, σ_2)$. By construction, $U(p, σ_2)$ is linear in $p$. Thus, if $σ_2^*$ is optimal strategy for the column player, then \n$$\n  U(p, σ_2^*) \\le v = \\tfrac 54, \\quad \\forall p \\in [0, 1].\n$$\nNow, consider the graph in @fig-2x3-lower. As we have previously seen, at $p^* = \\tfrac 58$, \n$$\nU(p^*, \\mathsf{L}) = U(p^*, \\mathsf{R}) = \\tfrac 54 = v\n\\quad\\text{but}\\quad\nU(p^*, \\mathsf{C}) > \\tfrac 54 = v.\n$$\nSo, $σ_2^*$ must give zero weight to $\\mathsf{C}$; otherwise $U(p^*, σ_2^*)$ cannot be equal to $\\tfrac 54$. Thus, we know that\n$$\n  σ_2^* = (q, 0, 1-q).\n$$\nHence, we effectively have a $2 × 2$ game. For find $q$, we can solve \n$$\n  U(\\mathsf{T}, σ_2^*) = U(\\mathsf{B}, σ_2^*) = v = \\tfrac 54.\n$$\nWe know that these equations will have a consistent solution, so we only need to solve one of these. Let's take\n$$\n  U(\\mathsf{T}, σ_2^*) = 2q - (1-q) = 3q - 1 = v = \\tfrac{5}{4}.\n$$\nThus,\n$$\n  \\bbox[5pt,border: 1px solid]{ q = \\tfrac{3}{4} }.\n$$\n\n#### Final solution {-}\nThus, the optimal strategy is \n$$\n  σ_1^* = (\\tfrac 58, \\tfrac 38)\n  \\quad\\text{and}\\quad\n  σ_2^* = (\\tfrac 34, 0, \\tfrac 14)\n$$\nand the value is $v = \\tfrac 54$. \n\n:::\n\nIn @exm-value-2x3, the column player had three strategies but the optimal strategy randomizes between only two of them. This is an instance of the following general result. \n\n:::{#thm-zsg-support}\nIn a two player zero-sum game where player 1 has $m_1$ pure strategies and player 2 has $m_2$ pure strategies, with $m_1 < m_2$, then player 2 has an optimal strategy that puts positive weight on at most $m_1$ pure strategies.\n:::\n\nNote that @thm-zsg-support means that there exists an optimal strategy with the above feature; not that all optimal strategies have this feature. \n\nAn implication of @thm-zsg-support is that in a two player ZSG where one player, say the row player, has $2$ pure strategies and the other player, the column player, has $m$ pure strategies with $m > 2$, there is an optimal strategy for the column player that puts positive weight on at most two pure strategies. We can find the solution of such $2 × m$ games using the procedure described above. In particular, we have the following:\n\n- **STEP 1:** Consider $σ_1 = (p, 1-p)$ and for each pure strategy $s_2$ of player 2, compute $U(σ_1, s_2)$. In general, we can have six possibilities as shown in @fig-zsg-2xm. \n\n  ![Different possibilities for $2 × m$ games](figures/svg/ZSG6.svg){#fig-zsg-2xm}\n  \n    Observe the following:\n\n    - In cases (a) and (f), the optimal strategy is attained on an internal point $p^*$\n\n    - In cases (b) and (c), the optimal strategy is a boundary point and corresponds to a pure strategy.\n\n    - In case (d) and (e), the maximum is attained in an interval; hence every point in this interval is an optimal strategy. \n\n- **STEP 2:** It can be shown that for player 2:\n\n    - case (a) implies that the optimal strategy is an internal point\n\n    - case (b)--(e) implies thta the optimal strategy is a pure strategy\n\n    - case (f) implies that there is an interval of randomization probabilities that are optimal.\n\n## Computing optimal strategy profile using linear programming\n\nThe graphical method described in the previous section does not work if both players have more than two actions. In general, the optimal solution can be obtained using linear programming. \n\nLet $(σ_1, σ_2)$ be a candidate optimal strategy profile. Then, it must satisfy\n\\begin{align}\n  U(σ_1, s_2) &\\ge v, & \\forall s_2 &\\in \\ALPHABET S_2 \n  \\label{eq:constraint-1}\n  \\\\\n  U(s_1, σ_2) &\\le v, & \\forall s_1 &\\in \\ALPHABET S_1.\n  \\label{eq:constraint-2}\n\\end{align}\n\nWe can write \\eqref{eq:constraint-1}--\\eqref{eq:constraint-2} as two linear programs. Suppose $\\ABS{\\ALPHABET S_1} = n$ and $\\ABS{\\ALPHABET S_2} = m$. For the ease of notation, we assume that $\\ALPHABET S_1 = \\{1, \\dots, n\\}$ and $\\ALPHABET S_2 = \\{1, \\dots, m\\}$ and use $u(i,j)$ to denote the utility of player 1 (the maximizer) when player 1 plays $i \\in \\ALPHABET S_1$ and player 2 plays $j \\in \\ALPHABET S_2$. \n\nLet \n$$\n  σ_1 = (p_1, \\dots, p_n)\n  \\quad\\text{and}\\quad\n  σ_2 = (q_1, \\dots, q_m)\n$$\nbe an optimal strategy profile of the game and $v$ be the value. Then, \\eqref{eq:constraint-1} and \\eqref{eq:constraint-2} are equalent to the following linear programs.\n\n\n$$\n\\bbox[5pt,border: 1px solid]{\n  \\begin{gathered}\n    \\max v \\\\\n    \\text{s.t. } \n    \\begin{aligned}[t] \n      & \\sum_{i=1}^n p_i u(i,j) \\ge v, \\quad \\forall j \\in \\ALPHABET S_2 \\\\\n      & p_i \\ge 0, \\quad \\forall i \\in \\{1, \\dots, n\\} \\\\\n      & \\sum_{i=1}^n p_i = 1\n   \\end{aligned}\n  \\end{gathered}}\n  \\qquad \n\\bbox[5pt,border: 1px solid]{\n  \\begin{gathered}\n    \\min v \\\\\n    \\text{s.t. } \n    \\begin{aligned}[t] \n      & \\sum_{j=1}^m q_j u(i,j) \\le v, \\quad \\forall i \\in \\ALPHABET S_1 \\\\\n      & q_j \\ge 0, \\quad \\forall j \\in \\{1, \\dots, m\\} \\\\\n      & \\sum_{j=1}^m q_j = 1\n   \\end{aligned}\n  \\end{gathered}}\n$$ \n\nA naive implementation of the above LP is given below:\n\n::: {#a2ec4cea .cell execution_count=6}\n``` {.julia .cell-code}\nusing JuMP, GLPK\n\nfunction solve_ZSG_naive(u)\n    n, m = size(u)\n\n    ## Primal LP to find strategies of row player\n    primal = Model(GLPK.Optimizer)\n\n    @variable(primal, v_lower)\n    @variable(primal, p[1:n] >= 0)\n\n    @objective(primal, Max, v_lower)\n\n    @constraint(primal, sum(p[i] for i ∈ 1:n) == 1)\n    for j ∈ 1:m\n        @constraint(primal, sum(p[i]*u[i,j] for i ∈ 1:n) >= v_lower)\n    end\n\n    ## Dual LP to find strategies for column player\n    dual = Model(GLPK.Optimizer)\n\n    @variable(dual, v_upper)\n    @variable(dual, q[1:m] >= 0)\n\n    @objective(dual, Min, v_upper)\n    \n    @constraint(dual, sum(q[j] for j ∈ 1:m) == 1)\n    for i ∈ 1:n\n        @constraint(dual, sum(q[j]*u[i,j] for j ∈ 1:m) <= v_upper)\n    end\n    \n    JuMP.optimize!(primal)\n    JuMP.optimize!(dual)\n\n    row_strategy = JuMP.value.(p)\n    col_strategy = JuMP.value.(q)\n    game_value   = JuMP.value(v_lower) # Same as v_upper\n\n    return row_strategy, col_strategy, game_value\nend\n```\n:::\n\n\nHowever, from LP duality, we know that the primal and the dual linear programs have the same solution. So, a more efficient implementation is the following, where we compute the strategies of the column player from the dual variables of the primal LP.\n\n::: {#df30408f .cell execution_count=7}\n``` {.julia .cell-code}\nfunction solve_ZSG(u)\n    n, m = size(u)\n\n    lp = Model(GLPK.Optimizer)\n\n    @variable(lp, v)\n    @variable(lp, p[1:n] >= 0)\n\n    @objective(lp, Max, v)\n\n    q = Vector{JuMP.ConstraintRef}(undef, m)\n\n    @constraint(lp, sum(p[i] for i ∈ 1:n) == 1)\n    for j ∈ 1:m\n        q[j] = @constraint(lp, sum(p[i]*u[i,j] for i ∈ 1:n) >= v)\n    end\n    JuMP.optimize!(lp)\n\n    row_strategy = JuMP.value.(p)\n    col_strategy = JuMP.dual.(q)\n    game_value   = JuMP.value(v) \n\n    return row_strategy, col_strategy, game_value\nend\n```\n:::\n\n\n:::{#exm-2x3-LP}\n\nSolve @exm-value-2x3 using linear programming\n:::\n\n:::{.callout-note}\n#### Solution\nWe first use the naive solution presented above:\n\n::: {#e01126aa .cell execution_count=8}\n``` {.julia .cell-code}\nu = [2 5 -1; 0 -2 5]\np, q, v = solve_ZSG_naive(u)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n([0.6249999999999998, 0.375], [0.75, 0.0, 0.25], 1.2500000000000002)\n```\n:::\n:::\n\n\nNext, we use the efficient solution that uses the dual variables\n\n::: {#bc7c4c92 .cell execution_count=9}\n``` {.julia .cell-code}\nu = [2 5 -1; 0 -2 5]\np, q, v = solve_ZSG(u)\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n([0.6249999999999998, 0.375], [0.75, -0.0, 0.25], 1.2500000000000002)\n```\n:::\n:::\n\n\nNote that both solutions give the same answer (up to numerical precision) that we obtained \"by hand\".\n:::\n\nSee @exr-LP for larger examples.\n\n## Games with non-compact action spaces\n\nSo far, we have restricted the discussion to finite games and shown that the game has a value in mixed strategies and there exist optimal strategies that achieve the value. We now present an example to show that this result is not always true if the game is not finite. \n\nConsider a $∞ × 2$ game with the following payoff matrix:\n\n::: {#fa812997 .cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;2&#36;</td><td>&#36;0&#36;</td></tr><tr><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;\\tfrac 12&#36;</td><td>&#36;\\tfrac 12&#36;</td></tr><tr><td>&#36;\\mathsf&#123;3&#125;&#36;</td><td>&#36;\\tfrac 13&#36;</td><td>&#36;\\tfrac 23&#36;</td></tr><tr><td>&#36;\\mathsf&#123;4&#125;&#36;</td><td>&#36;\\tfrac 14&#36;</td><td>&#36;\\tfrac 34&#36;</td></tr><tr><td>&#36;\\mathsf&#123;5&#125;&#36;</td><td>&#36;\\tfrac 15&#36;</td><td>&#36;\\tfrac 45&#36;</td></tr><tr><td>&#36;\\mathsf&#123;\\cdot&#125;&#36;</td><td>&#36;\\cdot&#36;</td><td>&#36;\\cdot&#36;</td></tr><tr><td>&#36;\\mathsf&#123;\\cdot&#125;&#36;</td><td>&#36;\\cdot&#36;</td><td>&#36;\\cdot&#36;</td></tr><tr><td>&#36;\\mathsf&#123;\\cdot&#125;&#36;</td><td>&#36;\\cdot&#36;</td><td>&#36;\\cdot&#36;</td></tr></table>\n```\n:::\n:::\n\n\nwhere the payoffs for $k > 1$ are\n$$\n  U(k, \\mathsf{L}) = \\frac{1}{k}\n  \\quad \\text{and} \\quad\n  U(k, \\mathsf{R}) = \\frac{k-1}{k}.\n$$\n\nNote that the row player has countable infinite number of strategies. A natural solution approach in this case is to truncate the strategy space of the row player to $K$ strategies and then solve the resulting finite game. Since the column player has two strategies, we use the graphical method presented above. \n\nIn particular, suppose the column player is playering a mixed srtategy $σ_2 = (q_K, 1-q_K)$,\nwhere we use subscript $K$ to empahsize the fact that this is the strategy for the $K × 2$ truncated game.\n\nThen, we have\n$$\n  U(1, σ_2) = 2q_K,\n  \\quad\\text{and}\\quad\n  U(k, σ_2) = \\frac{q_K}{k} + \\left(1 - \\frac 1k\\right)(1-q_K),\n  \\quad \\forall k > 1.\n$$\n\nThe payoffs for $K = 4$ are shown in @fig-zsg-infx2, where the upper convex envelop is shown in red. \n\n![Payoff profile for $∞ × 2$ game](figures/svg/ZSG7.svg){#fig-zsg-infx2}\n  \nObserve that the upper convex envelop consists of $U(1, σ_2)$ and and $U(K, σ_2)$. We find the maxmin strategy (for the truncated game) by solving \n$$\n  U(1,σ_2) = U(K, σ_2)\n  \\implies\n  2q_K = \\frac{q_K}{K} + \\left(1 - \\frac 1K\\right)(1-q_K).\n$$\nSolving the above, we have\n$$\n  q_K = \\frac{K-1}{3K -2}\n  \\quad\\text{and}\\quad\n  v_K = \\frac{2(K-1)}{3K-2}\n$$\n\nNow consider the row player. When the column player is randomizing according to $q_K$, the row player gets the same payoff when playing strategies $1$ and $K$ and gets a lower payoff when playing any other strategy. So, the row player will choose a strategy\n$$\n  σ_1 = (p_K, 0, 0, \\dots, 0, 1-p_K)\n$$\nwhere $p_K$ can be computed by solving\n$$\n  U(σ_1, \\mathsf{L}) = U(σ_1, \\mathsf{R}) = v_K\n  \\implies\n  2 p_K + \\frac{1-p}{K} = \\left(1 - \\frac 1K\\right) (1 - p_K) \n  = \\frac{2(K-1)}{3K - 2}\n$$\nSolving this, we get\n$$\n  p_K = \\frac{K-2}{3K-2}.\n$$\n\nObserve that \n$$\n  \\lim_{K \\to ∞} v_K = \\tfrac{2}{3},\n$$\nSo, the original game has a value. However, to achieve this value, the row player has to randomize between strategies $1$ and $K \\to ∞$; so there is no strategy for the row player which actually achieves this value. \n\nThus, **when action sets are not compact, the existence of a value does not imply that there is a strategy that will achieve that value.** \n\nIn some sense, finding a strategy that achieves a value is equivalent to maximizing \n$$\n  f(k) = 1 - \\frac 1k, \\quad k \\in \\naturalnumbers.\n$$\nClearly, $\\sup_{k \\in \\naturalnumbers} f(k) = 1$, but there is no value of $k \\in \\naturalnumbers$ which achieves $f(k) = 1$. \n\nNonetheless, we can talk about an $ε$-optimal strategy. In the above example, pick \n$$\n  σ_1 = (\\tfrac 13, 0, \\dots, 0, \\tfrac 23, 0, 0, \\dots)\n$$\nwhere player is randomizing between strategy $1$ and strategy $k$. Then,\n$$\n  U(σ_1, \\mathsf{L}) = \\frac 23 + \\frac{2}{3k}\n  \\quad\\text{and}\\quad\n  U(σ_1, \\mathsf{R}) = \\frac 23 \\left(1 - \\frac 1k\\right) = \n  \\frac{2}{3} - \\frac{2}{3k}.\n$$\nThus, for any $ε > 0$, we can guarantee a value of $\\frac 23 - ε$ by choosing $k > 2/(3 ε)$.\n\n## Sufficient conditions for existence of optimal strategies for general strategy spaces\n\nWe now present a general theorem that guarantees the existence of optimal strategies for a two player zero sum game with continuous action spaces.\n\n:::{#thm-zsg-existence}\n\nConsider a two player ZSG where $\\ALPHABET S_1$ and $\\ALPHABET S_2$ are convex sets and $u(s_1, s_2)$ is a continuous function and:\n\n- $u(⋅, s_2)$ is strictly concave for each $s_2$\n- $u(s_1, ⋅)$ is strictly convex for each $s_1$.\n\nFurthermore, either\n\na) $\\ALPHABET S_1$ and $\\ALPHABET S_2$ are closed and bounded\n\nb) $\\ALPHABET S_i = \\reals^{m_i}$, $i \\in \\{1,2\\}$ and \n    \n    - $\\displaystyle \\lim_{\\NORM{s_1} \\to ∞} u(s_1, s_2) = -∞$, for all $s_2 \\in \\ALPHABET S_2$\n\n    - $\\displaystyle \\lim_{\\NORM{s_2} \\to ∞} u(s_1, s_2) = ∞$, for all $s_1 \\in \\ALPHABET S_1$\n\nThen the game has a **unique** optimal pure strategy.\n:::\n\nWhen strategy spaces are compact, a solution in mixed strategies exist under very weak conditions. This result is know as [:Glicksberg Theorem](https://en.wikipedia.org/wiki/Glicksberg's_theorem). We present a simplified version of it below (in the more general setting we can relax continuity of the utility with semi-continuity). \n\n:::{#thm-zsg-Glicksberg}\nA two player zero sum game with compact strategy spaces and continuous utility function has a value in mixed strategies.\n:::\n\nWe conclude this section by presenting an example to show that a game with continuous strategy spaces may **not** have a solution in pure strategies. \n\n:::{#exm-zsg-cts-mixed}\n  Consider a ZSG game with both players guess a number in the interval $[0, 1]$. Player 1 wants to be close to player while player 2 wants to be far from player 1. We model this game as follows:\n\n  We take $\\ALPHABET S_1 = \\ALPHABET S_2 = [0, 1]$ and \n  $$\n    u(s_1, s_2) = - (s_1 - s_2)^2.\n  $$\n:::\n\nObserve that the utility function is concave in both $s_1$ and $s_2$. So, the above example does not satisfy the sufficient conditions of @thm-zsg-existence. We check if a value exists from first principles.\n\n:::{.callout-note}\n#### Solution\n\n#### Strategy for row player {-}\n\nConsider the optimization problem\n$$\n  \\underline v = \\max_{s_1 \\in [0,1]} \\min_{s_2 \\in [0,1]} u(s_1, s_2).\n$$\nIn the inner optimization problem, player 2 is minimizing a concave function. So the minima is attached at the boundary. Thus, the above optimization problem is same as one where player 2 is choosing from the discrete set $\\{0, 1\\}$, that is\n\\begin{align*}\n  \\max_{s_1 \\in [0,1]} \\min_{s_2 \\in [0,1]} u(s_1, s_2)\n  &= \\max_{s_1 \\in [0,1]} \\min_{s_2 \\in \\{0,1\\}} u(s_1, s_2)\n  \\\\ \\max_{s_1 \\in [0,1]} \\min \\{ -s_1^2, -(1-s_1)^2 \\}.\n\\end{align*}\nAlthough the utility functions are not linear, we can follow the same argument as before: we plot both functions, find the lower envelop, and the find the maxmin value $s_1$. See @fig-zsg-cts.\n\n![Payoff profile for @exm-zsg-cts-mixed](figures/svg/ZSG8.svg){#fig-zsg-cts}\n\nThus, we have that \n$$\n  s_1^* = \\tfrac 12\n  \\quad\\text{and}\\quad\n  \\underline v = - \\tfrac{1}{4}.\n$$\n\n#### Strategy for column player {-}\n\n\nWe know that player 2 only chooses among the actions in $\\{0, 1\\}$. Suppose player 2 is playing a randomized strategy $σ_2$ where it picks strategy $0$ with probability $q$ and strategy $1$ with probability $1$.\n\nThen, player 2 wants to solve:\n$$\n  \\bar v = \\min_{q \\in [0, 1]} \\max_{s_1 \\in [0, 1]} u(s_1, s_2).\n$$\n\nConsider the inner optimization problem for player 1:\n$$\n  max_{s_1 \\in [0, 1]} u(s_1, σ_2)\n  = \\max_{s_1 \\in [0, 1]} \\bigl[\n      - q s_1^2 - (1-q) (1 - s_1)^2 \n    \\bigr]\n$$\nwhich is concave in $s_1$. So, we look at the first order optimality conditions to find the optima:\n$$\n  \\frac{∂u}{∂ s_1} = 0 \n  \\implies\n  -2q s_1 + 2(1-q)(1-s_1) = 0\n  \\implies s_1 = 1 - q.\n$$\nThus, we have\n$$\n  \\max_{s_1 \\in [0, 1]} \\min_{s_2 \\in \\ALPHABET S_2} \n  = - q (1-q)^2 - (1-q)q^2 = -q(1-q).\n$$\n\nSubstituting this back in the equation for the minmax, we have\n$$\n  \\bar v = \\min_{q \\in [0, 1]} - q(1-q).\n$$\nBy the [:AM-GM inequality](https://en.wikipedia.org/wiki/AM%E2%80%93GM_inequality), we know that the minima is achieved at $q = \\tfrac 12$. Therefore, \n$$\n  \\bar v = - \\tfrac 14.\n$$\n\nTherefore, we have that $\\underline v = \\bar v = -\\tfrac 14$; thus, the game has a value, where player 1 plays a pure strategy of $s_1 = \\tfrac 12$ and player 2 randomizes between $0$ and $1$ with equal probability (this makes sense from the description of the problem). \n:::\n\nIn the above example, the utility function was not convex in $s_2$. The game does not have a value in pure strategies, but it still has a value in mixed strategies. There are general sufficient conditions to verify the existence of value in mixed strategies for games with continuous strategy spaces, but we will not discuss them in the course. \n\n\n## Exercises {-}\n\n:::{#exr-zsg-mixed}\nFor each of the following games, find the value of the game and the optimal strategy profile.\n\n::::{layout-ncol=2}\n:::{.game-1}\n\n::: {#7503dbf6 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 1</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;6&#36;</td><td>&#36;0&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;3&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.game-2}\n\n::: {#035d413f .cell execution_count=12}\n\n::: {.cell-output .cell-output-display execution_count=22}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 2</caption><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;8&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;4&#36;</td><td>&#36;4&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n::::\n:::\n\n:::{#exr-zsg-ieds}\nFind the optimal strategy profile and the value of the following game.\n\n::: {#ab57d811 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><tr><td></td><td>&#36;\\mathsf&#123;L&#125;&#36;</td><td>&#36;\\mathsf&#123;C&#125;&#36;</td><td>&#36;\\mathsf&#123;R&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;T&#125;&#36;</td><td>&#36;0&#36;</td><td>&#36;4&#36;</td><td>&#36;6&#36;</td></tr><tr><td>&#36;\\mathsf&#123;M&#125;&#36;</td><td>&#36;5&#36;</td><td>&#36;7&#36;</td><td>&#36;4&#36;</td></tr><tr><td>&#36;\\mathsf&#123;B&#125;&#36;</td><td>&#36;9&#36;</td><td>&#36;6&#36;</td><td>&#36;3&#36;</td></tr></table>\n```\n:::\n:::\n\n\n_Hint_: Use iterative elimination of strongly dominated strategies to first reduce the above to a $2 × 2$ game and then simplify the resulting game. \n\n:::\n\n:::{#exr-switched-zsg}\nSuppose $(σ_1^*, σ_2^*)$ and $(τ_1^*, τ_2^*)$ both satisfy\n$$\n  \\max_{σ_1 \\in Δ(\\ALPHABET S_1)} \\min_{σ_2 \\in Δ(\\ALPHABET S_2)}\n  U(σ_1, σ_2) =\n  \\min_{σ_2 \\in Δ(\\ALPHABET S_2)} \\max_{σ_1 \\in Δ(\\ALPHABET S_1)}\n  U(σ_1, σ_2) = v.\n$$\nProve that\n$$\n  U(σ_1^*, τ_2^*) = U(τ_1^*, σ_2^*) = v.\n$$\n\n_Hint_: Use @thm-saddle-point to argue that\n$$\n  U(τ_1^*, τ_2^*) \\le U(τ_1^*, σ_2^*) \\le U(σ_1^*, σ_2^*)\n  \\quad\\text{and}\\quad\n  U(σ_1^*, σ_2^*) \\le U(σ_1^*, τ_2^*) \\le U(τ_1^*, τ_2^*).\n$$\n\n:::\n\n:::{#exr-symmetric-games}\nA zero-sum game with $\\ALPHABET S_1 = \\ALPHABET S_2$ is called **symmetric** if the utlity function is skew-symmetric, i.e.,\n$$\n  u(s_1, s_2) = - u(s_2, s_1), \\quad \\forall s_1, s_2 \\in \\ALPHABET S_1.\n$$\nAn example of a symmetric game is rock-paper-scissors. \n\nLet $\\mathscr{G}$ be a finite symmetric game. Show that:\n\na. The value of $\\mathscr{G}$ in mixed strategies is zero.\n\nb. If $(σ_1^*, σ_2^*)$ is an optimal (mixed) strategy for $\\mathscr{G}$, then $(σ_2^*, σ_1^*)$ is also an optimal (mixed) strategy. \n\nc. Use part b and @exr-switched-zsg to argue that a symmetric zero-sum game always has a _symmetric_ optimal (mixed) strategy of the form $(σ^*, σ^*)$, where both players are playing the same mixed strategy.\n\n:::\n\n:::{#exr-LP}\nUse the LP formulation to find optimal strategy profile of the following games.\n\n::::{layout-ncol=2}\n:::{.game-1}\n\n::: {#5bf118cd .cell execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 1</caption><tr><td></td><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;\\mathsf&#123;3&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;3&#36;</td><td>&#36;-1&#36;</td><td>&#36;2&#36;</td></tr><tr><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td><td>&#36;-2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n\n:::{.game-2}\n\n::: {#05405d85 .cell execution_count=15}\n\n::: {.cell-output .cell-output-display execution_count=25}\n```{=html}\n<table class=\"game1\" data-quarto-disable-processing=\"true\" align=\"center\"><caption>Game 2</caption><tr><td></td><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;\\mathsf&#123;3&#125;&#36;</td><td>&#36;\\mathsf&#123;4&#125;&#36;</td></tr><tr><td>&#36;\\mathsf&#123;1&#125;&#36;</td><td>&#36;6&#36;</td><td>&#36;0&#36;</td><td>&#36;5&#36;</td><td>&#36;6&#36;</td></tr><tr><td>&#36;\\mathsf&#123;2&#125;&#36;</td><td>&#36;-3&#36;</td><td>&#36;3&#36;</td><td>&#36;-4&#36;</td><td>&#36;3&#36;</td></tr><tr><td>&#36;\\mathsf&#123;3&#125;&#36;</td><td>&#36;8&#36;</td><td>&#36;1&#36;</td><td>&#36;2&#36;</td><td>&#36;2&#36;</td></tr></table>\n```\n:::\n:::\n\n\n:::\n::::\n\nNote that part of the objective of this exercise is for you to learn how to use a linear programming solver. So, instead of blindly copy pasting the code provided above, implement the solution from the equations using the programming language of your choice.\n:::\n\n:::{#exr-zsg-lgr}\nConsider a two player zero-sum game with $\\ALPHABET S_1 = \\ALPHABET S_2 = \\reals$.\n\n$$\n  u(s_1, s_2) = - s_1^2 + s_2^2 - 2 s_1 s_2 - s_1 + 2 s_2.\n$$\n\na. Show that the game satisfies the sufficient conditions of @thm-zsg-existence. Therefore, the game has a value and a unique optimal strategy.\n\nb. Find the maxmin strategy of player 1 and the maxmin value of the game by solving the following:\n$$\n  \\underline v = \\sup_{s_1 \\in \\reals} \\inf_{s_2 \\in \\reals} u(s_1, s_2).\n$$\n\nc. Find the minmax strategy of player 2 and the minmax value of the game by solving the following:\n$$\n  \\bar v = \\inf_{s_2 \\in \\reals} \\sup_{s_1 \\in \\reals} u(s_1, s_2).\n$$\n\nd. Is the maxmin value same as the minmax value?\n:::\n\n",
    "supporting": [
      "zero-sum-games_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}